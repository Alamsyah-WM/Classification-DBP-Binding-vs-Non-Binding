{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CSeNMcA9NFXh",
        "aq60Rh6VOfXi",
        "a4V6hNEsQrBZ",
        "4d6I9Kcqaj8k"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alamsyah-WM/Classification-DBP-Binding-vs-Non-Binding/blob/Minggu3/Minggu3_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Installing packages pandas, numpy, tqdm, sckit-learn, and pretrain model"
      ],
      "metadata": {
        "id": "rQ8iMSCo-UVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqRBZi8YRMRj",
        "outputId": "b4b85f57-097d-4aaf-969c-7a39f78df164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: fair-esm in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fair-esm -q\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install fair-esm scikit-learn pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Importing Library from installed setup"
      ],
      "metadata": {
        "id": "jEBwmrq--hdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import esm\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import time\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score,\n",
        "    accuracy_score, precision_score, recall_score, f1_score, classification_report,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_8jjo-5GRd6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "2JC6OH9FrYGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset\n",
        "---\n",
        "Load both PDB1063 and UniSwiss dataset.\n",
        "\n",
        "> df_pdb = pd.read_csv(pdb_dataset_path) <p> df_uni = pd.read_csv(uni_dataset_path) </p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rDKR1Ao5-zmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pdb = pd.read_csv('/content/PDB1063-186.csv')\n",
        "df_uni = pd.read_csv('/content/UniSwiss.csv')\n",
        "\n",
        "\n",
        "print(f'Total sequence PDB: {len(df_pdb)}')\n",
        "print(f'Total sequence UniSwiss: {len(df_uni)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUteaG4NRf-t",
        "outputId": "eb1d0fe6-cfe6-4414-8d0c-a750552ff237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequence PDB: 1249\n",
            "Total sequence UniSwiss: 9762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess Dataset\n",
        "---\n",
        "Cleaning duplicate sequence (cleaning_dataset)\n",
        "\n",
        "> df_clean = df.drop_duplicates(subset='sequence')\n",
        "\n",
        "Split test and train dataset (split_dataset)\n",
        "\n",
        "\n",
        "> train_df = df[df['set'] == 'train'] <p>\n",
        "        test_df = df[df['set'] == 'test']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1cUVzWDkBia5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_dataset (df, dataset_name= None):\n",
        "    if df is None or df.empty:\n",
        "        print(f'Dataset {dataset_name} is empty. No clean required')\n",
        "        return df\n",
        "\n",
        "    # Check if 'set' column exists\n",
        "    if 'set' in df.columns:\n",
        "        df_sorted = df.sort_values(by='set', ascending=True)  # 'test' > 'train' alphabetically\n",
        "        df_clean = df_sorted.drop_duplicates(subset='sequence', keep='first')\n",
        "\n",
        "        # Reset index\n",
        "        df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "        # Show statistics\n",
        "        train_before = len(df[df['set'] == 'train'])\n",
        "        test_before = len(df[df['set'] == 'test'])\n",
        "        train_after = len(df_clean[df_clean['set'] == 'train'])\n",
        "        test_after = len(df_clean[df_clean['set'] == 'test'])\n",
        "\n",
        "        print(f'Dataset {dataset_name}:')\n",
        "        print(f'  Train: {train_before} -> {train_after} (removed {train_before - train_after})')\n",
        "        print(f'  Test: {test_before} -> {test_after} (removed {test_before - test_after})')\n",
        "        print(f'  Total: {len(df)} -> {len(df_clean)} (removed {len(df) - len(df_clean)})')\n",
        "    else:\n",
        "        # If no 'set' column, just remove duplicates normally\n",
        "        df_clean = df.drop_duplicates(subset='sequence', keep='first')\n",
        "        print(f'Total protein dataset {dataset_name} after cleaning: {len(df_clean)}')\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "df_pdb = cleaning_dataset(df_pdb, \"PDB\")\n",
        "df_uni = cleaning_dataset(df_uni, \"UniSwiss\")\n",
        "\n",
        "\n",
        "def split_dataset (df, dataset_name= None):\n",
        "    if 'set' in df.columns:\n",
        "        train_df = df[df['set'] == 'train']\n",
        "        test_df = df[df['set'] == 'test']\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "    # Extract seq and labels for both dataset\n",
        "    x_train = train_df['sequence'].tolist()\n",
        "    y_train = train_df['label'].values\n",
        "\n",
        "    x_test = test_df['sequence'].tolist()\n",
        "    y_test = test_df['label'].values\n",
        "\n",
        "    print(f\"\\nTraining sequence {dataset_name}: {len(x_train)}\")\n",
        "    print(f\"Training label {dataset_name}: {len(y_train)}\")\n",
        "\n",
        "    print(f\"Test sequence {dataset_name}: {len(x_test)}\")\n",
        "    print(f\"Test label {dataset_name}: {len(y_test)}\")\n",
        "\n",
        "    return train_df, test_df, x_train, y_train, x_test, y_test\n",
        "\n",
        "df_pdb_train, df_pdb_test, x_pdb_train, y_pdb_train, x_pdb_test, y_pdb_test = split_dataset(df_pdb, 'PDB')\n",
        "df_uni_train, df_uni_test, x_uni_train, y_uni_train, x_uni_test, y_uni_test = split_dataset(df_uni, 'UniSwiss')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT-uPqRdBi5B",
        "outputId": "f0ad9ab6-592c-443d-d639-21a903859a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset PDB:\n",
            "  Train: 1063 -> 985 (removed 78)\n",
            "  Test: 186 -> 186 (removed 0)\n",
            "  Total: 1249 -> 1171 (removed 78)\n",
            "Dataset UniSwiss:\n",
            "  Train: 9000 -> 8937 (removed 63)\n",
            "  Test: 762 -> 759 (removed 3)\n",
            "  Total: 9762 -> 9696 (removed 66)\n",
            "\n",
            "Training sequence PDB: 985\n",
            "Training label PDB: 985\n",
            "Test sequence PDB: 186\n",
            "Test label PDB: 186\n",
            "\n",
            "Training sequence UniSwiss: 8937\n",
            "Training label UniSwiss: 8937\n",
            "Test sequence UniSwiss: 759\n",
            "Test label UniSwiss: 759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load pretrain model\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Check device processor for running\n",
        ">device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "Load model ESM-1b\n",
        "> model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
        "\n",
        "call converter/formatter for raw protein sequence into format can be processed by model\n",
        "> batch_converter = alphabet.get_batch_converter()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CSeNMcA9NFXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model = model.eval().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s1W8y4UTD_m",
        "outputId": "c218a55b-985a-4279-ab19-f900bc55c4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt\" to /root/.cache/torch/hub/checkpoints/esm1b_t33_650M_UR50S.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm1b_t33_650M_UR50S-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm1b_t33_650M_UR50S-contact-regression.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sequence Handling\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Add window sliding for split long protein sequence into overlapping windows. (window_sliding)\n",
        "\n",
        "If protein sequence length > 1022, split into overlap window (chunks)"
      ],
      "metadata": {
        "id": "aq60Rh6VOfXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_sliding(seq, max_len=1022, stride=512):\n",
        "    if len(seq) <= max_len:\n",
        "        return [seq]\n",
        "    chunks = []\n",
        "    for i in range(0, len(seq), stride):\n",
        "        chunk = seq[i:i + max_len]\n",
        "        if len(chunk) < 50:   # skip fragments too short to be meaningful\n",
        "            continue\n",
        "        chunks.append(chunk)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "S-bqi9-1SG5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embeddings\n",
        "\n",
        "---\n",
        "Extract mean ESM-1b embeddings for a list of protein sequences (extract_esm_embeddings)."
      ],
      "metadata": {
        "id": "a4V6hNEsQrBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_esm_embeddings(sequences, batch_size=8):\n",
        "    \"\"\"Extract mean ESM-1b embeddings with automatic windowing for long proteins.\"\"\"\n",
        "    all_embeddings = []\n",
        "    truncated_count = 0\n",
        "\n",
        "    for seq in tqdm(sequences, desc=\"Extracting ESM embeddings\"):\n",
        "        subseqs = window_sliding(seq)\n",
        "        if len(seq) > 1022 :\n",
        "            truncated_count += 1\n",
        "\n",
        "        subseq_embeddings = []\n",
        "        for i in range(0, len(subseqs), batch_size):\n",
        "            batch = subseqs[i:i + batch_size]\n",
        "            batch_data = [(\"\", s) for s in batch]\n",
        "            batch_labels, batch_strs, batch_tokens = batch_converter(batch_data)\n",
        "            batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                results = model(batch_tokens, repr_layers=[33])\n",
        "                reps = results[\"representations\"][33]\n",
        "\n",
        "            for j, s in enumerate(batch):\n",
        "                emb = reps[j, 1:len(s)+1].mean(0).cpu().numpy()\n",
        "                subseq_embeddings.append(emb)\n",
        "\n",
        "            del batch_tokens, results, reps\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Average all windows for this protein\n",
        "        mean_embedding = np.mean(subseq_embeddings, axis=0)\n",
        "        all_embeddings.append(mean_embedding)\n",
        "\n",
        "    print(f\"Total sequences processed: {len(sequences)}\")\n",
        "    print(f\"Sequences truncated (>1022 aa): {truncated_count} ({truncated_count/len(sequences)*100:.2f}%)\")\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "x_pdb_train_emb = extract_esm_embeddings(x_pdb_train, batch_size=8)\n",
        "x_pdb_test_emb  = extract_esm_embeddings(x_pdb_test, batch_size=8)\n",
        "\n",
        "x_uni_train_emb = extract_esm_embeddings(x_uni_train, batch_size=8)\n",
        "x_uni_test_emb  = extract_esm_embeddings(x_uni_test, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9WxeeZfPVRx",
        "outputId": "2745390b-6563-4334-ec1a-a452d8f070e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting ESM embeddings: 100%|██████████| 985/985 [01:59<00:00,  8.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences processed: 985\n",
            "Sequences truncated (>1022 aa): 5 (0.51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting ESM embeddings: 100%|██████████| 186/186 [00:27<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences processed: 186\n",
            "Sequences truncated (>1022 aa): 4 (2.15%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting ESM embeddings: 100%|██████████| 8937/8937 [46:31<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences processed: 8937\n",
            "Sequences truncated (>1022 aa): 735 (8.22%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting ESM embeddings: 100%|██████████| 759/759 [03:54<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences processed: 759\n",
            "Sequences truncated (>1022 aa): 64 (8.43%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checkpoints DL\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Saving embedding output from pretrained model. <P>\n",
        "Create directory for Deep Learning model\n",
        "> os.makedirs(\"esm_embed/DL\", exist_ok=True)\n",
        "\n",
        "Save sequence train and test (PDB)\n",
        ">torch.save(torch.tensor(x_pdb_train_emb), \"esm_embed/DL/PDB/x_pdb_train.pt\")<p>torch.save(torch.tensor(x_pdb_test_emb),  \"esm_embed/DL/PDB/x__pdb_test.pt\")\n",
        "\n",
        "Save label train and test (PDB)\n",
        "> np.save(\"esm_embed/DL/PDB/y_pdb_train.npy\", y_pdb_train) <p>\n",
        "np.save(\"esm_embed/DL/PDB/y_pdb_test.npy\",  y_pdb_test)"
      ],
      "metadata": {
        "id": "4d6I9Kcqaj8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"esm_embed_2/DL\", exist_ok=True)\n",
        "\n",
        "torch.save(torch.tensor(x_pdb_train_emb), \"esm_embed_2/DL/PDB/x_pdb_train.pt\")\n",
        "torch.save(torch.tensor(x_pdb_test_emb),  \"esm_embed_2/DL/PDB/x_pdb_test.pt\")\n",
        "\n",
        "np.save(\"esm_embed_2/DL/PDB/y_pdb_train.npy\", y_pdb_train)\n",
        "np.save(\"esm_embed_2/DL/PDB/y_pdb_test.npy\",  y_pdb_test)\n",
        "\n",
        "torch.save(torch.tensor(x_uni_train_emb), \"esm_embed_2/DL/UNI/x_uni_train.pt\")\n",
        "torch.save(torch.tensor(x_uni_test_emb),  \"esm_embed_2/DL/UNI/x_uni_test.pt\")\n",
        "\n",
        "np.save(\"esm_embed_2/DL/UNI/y_uni_train.npy\", y_uni_train)\n",
        "np.save(\"esm_embed_2/DL/UNI/y_uni_test.npy\",  y_uni_test)\n",
        "\n",
        "print(\"Save success\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ViqBQ9vSGzv",
        "outputId": "70fcf18a-953d-4345-e129-d1012e70ec35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Checkpoints\n",
        "Load embedding process for Deep learning and Machine learning"
      ],
      "metadata": {
        "id": "6kn4PNhv0jgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E_SqFEJd8bR",
        "outputId": "18a8b5de-0e2c-4bcb-b999-d0c4083fe5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep learning\n",
        "x_pdb_train_emb = torch.load(\"/content/drive/MyDrive/esm_embed_2/DL/PDB/x_pdb_train.pt\").numpy()\n",
        "y_pdb_train = np.load(\"/content/drive/MyDrive/esm_embed_2/DL/PDB/y_pdb_train.npy\")\n",
        "\n",
        "x_pdb_test_emb = torch.load(\"/content/drive/MyDrive/esm_embed_2/DL/PDB/x_pdb_test.pt\").numpy()\n",
        "y_pdb_test = np.load(\"/content/drive/MyDrive/esm_embed_2/DL/PDB/y_pdb_test.npy\")\n",
        "\n",
        "x_uni_train_emb = torch.load(\"/content/drive/MyDrive/esm_embed_2/DL/UNI/x_uni_train.pt\").numpy()\n",
        "y_uni_train = np.load(\"/content/drive/MyDrive/esm_embed_2/DL/UNI/y_uni_train.npy\")\n",
        "\n",
        "x_uni_test_emb = torch.load(\"/content/drive/MyDrive/esm_embed_2/DL/UNI/x_uni_test.pt\").numpy()\n",
        "y_uni_test = np.load(\"/content/drive/MyDrive/esm_embed_2/DL/UNI/y_uni_test.npy\")\n",
        "\n",
        "print (x_pdb_train_emb.shape, y_pdb_train.shape)\n",
        "print (x_uni_train_emb.shape, y_uni_train.shape)"
      ],
      "metadata": {
        "id": "a_UDRY_Y0rdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9576d64-a07c-4164-da34-ceb06e041020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(985, 1280) (985,)\n",
            "(8937, 1280) (8937,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Dataset"
      ],
      "metadata": {
        "id": "_5mEz7YLZo0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_pdb_train, x_pdb_val, y_pdb_train, y_pdb_val = train_test_split(\n",
        "    x_pdb_train_emb, y_pdb_train,\n",
        "    test_size= 186,\n",
        "    stratify=y_pdb_train,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# For UniSwiss dataset (use similar logic)\n",
        "x_uni_train, x_uni_val, y_uni_train, y_uni_val = train_test_split(\n",
        "    x_uni_train_emb, y_uni_train,\n",
        "    test_size=759,\n",
        "    stratify=y_uni_train,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "A4ashdq-ZqyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"PDB New Training set size: {x_pdb_train.shape[0]}\")\n",
        "print(f\"PDB Validation set size: {x_pdb_val.shape[0]}\")\n",
        "print(f\"PDB Test set size: {x_pdb_test_emb.shape[0]}\")\n",
        "\n",
        "print(f\"\\nUniSwiss New Training set size: {x_uni_train.shape[0]}\")\n",
        "print(f\"UniSwiss Validation set size: {x_uni_val.shape[0]}\")\n",
        "print(f\"UniSwiss Test set size: {x_uni_test_emb.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHWmE_PvgAQT",
        "outputId": "38edc3b1-c20f-4807-f115-50d910652d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDB New Training set size: 799\n",
            "PDB Validation set size: 186\n",
            "PDB Test set size: 186\n",
            "\n",
            "UniSwiss New Training set size: 8178\n",
            "UniSwiss Validation set size: 759\n",
            "UniSwiss Test set size: 759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PDB\n",
        "print(\"PDB - Training Set Class Balance:\")\n",
        "unique, counts = np.unique(y_pdb_train, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}, Percent: {c/len(y_pdb_train)*100:.2f}%\")\n",
        "\n",
        "print(\"\\nPDB - Validation Set Class Balance:\")\n",
        "unique, counts = np.unique(y_pdb_val, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}, Percent: {c/len(y_pdb_val)*100:.2f}%\")\n",
        "\n",
        "print(\"\\nPDB - Test Set Class Balance:\")\n",
        "unique, counts = np.unique(y_pdb_test, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}, Percent: {c/len(y_pdb_test)*100:.2f}%\")\n",
        "\n",
        "# UniSwiss\n",
        "print(\"\\nUniSwiss - Training Set Class Balance:\")\n",
        "unique, counts = np.unique(y_uni_train, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}, Percent: {c/len(y_uni_train)*100:.2f}%\")\n",
        "\n",
        "print(\"\\nUniSwiss - Validation Set Class Balance:\")\n",
        "unique, counts = np.unique(y_uni_val, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}, Percent: {c/len(y_uni_val)*100:.2f}%\")\n",
        "\n",
        "print(\"\\nUniSwiss - Test Set Class Balance:\")\n",
        "unique, counts = np.unique(y_uni_test, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c}, Percent: {c/len(y_uni_test)*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mzYo_1UBsC9",
        "outputId": "95e7fa63-9b5b-4b71-dc18-8402194bae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDB - Training Set Class Balance:\n",
            "Class 0: 442, Percent: 55.32%\n",
            "Class 1: 357, Percent: 44.68%\n",
            "\n",
            "PDB - Validation Set Class Balance:\n",
            "Class 0: 103, Percent: 55.38%\n",
            "Class 1: 83, Percent: 44.62%\n",
            "\n",
            "PDB - Test Set Class Balance:\n",
            "Class 0: 93, Percent: 50.00%\n",
            "Class 1: 93, Percent: 50.00%\n",
            "\n",
            "UniSwiss - Training Set Class Balance:\n",
            "Class 0: 4116, Percent: 50.33%\n",
            "Class 1: 4062, Percent: 49.67%\n",
            "\n",
            "UniSwiss - Validation Set Class Balance:\n",
            "Class 0: 382, Percent: 50.33%\n",
            "Class 1: 377, Percent: 49.67%\n",
            "\n",
            "UniSwiss - Test Set Class Balance:\n",
            "Class 0: 381, Percent: 50.20%\n",
            "Class 1: 378, Percent: 49.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Models\n",
        "Define Bi-LSTM Model\n",
        "\n",
        "\n",
        "```\n",
        "class BiLSTMModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout, output_dim):\n",
        "        super().__init__()\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_dim, hidden_dim, batch_first=True, bidirectional=True\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.fc = torch.nn.Linear(hidden_dim * 2, output_dim)  # times 2 for bidirectional\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape x: [batch_size, input_dim] -> [batch_size, seq_len=1, input_dim]\n",
        "        x = x.unsqueeze(1)\n",
        "        lstm_out, _ = self.lstm(x)  # [batch_size, 1, hidden_dim*2]\n",
        "        x = self.dropout(lstm_out[:, -1, :])   # last output\n",
        "        return self.fc(x)  # [batch_size, output_dim]\n",
        "\n",
        "\n",
        "Set manual hyperparameter loop for find the best Hyperparameter\n",
        "\n",
        "\n",
        "```\n",
        "configs = [\n",
        "    {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005},\n",
        "    {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005},\n",
        "    {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005},\n",
        "    {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001},\n",
        "    {'hidden_dim': 192, 'dropout': 0.4, 'lr': 0.0007}\n",
        "]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Bi5zIvhroCu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example model class - adjust only if your actual class has different arguments!\n",
        "class BiLSTMModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout, output_dim):\n",
        "        super().__init__()\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_dim, hidden_dim, batch_first=True, bidirectional=True\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.fc = torch.nn.Linear(hidden_dim * 2, output_dim)  # times 2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape x: [batch_size, input_dim] -> [batch_size, seq_len=1, input_dim]\n",
        "        x = x.unsqueeze(1)\n",
        "        lstm_out, _ = self.lstm(x)  # [batch_size, 1, hidden_dim*2]\n",
        "        x = self.dropout(lstm_out[:, -1, :])   # last output\n",
        "        return self.fc(x)  # [batch_size, output_dim]\n"
      ],
      "metadata": {
        "id": "qJRfahcoWPQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PDB Hyperparameter grid\n"
      ],
      "metadata": {
        "id": "alOmi3rtNoej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- PDB Hyperparameter grid --\n",
        "hidden_dims_pdb = [128, 256, 512]\n",
        "dropouts_pdb = [0.1, 0.3, 0.5]\n",
        "lrs_pdb = [0.0005, 0.001, 0.002]\n",
        "batch_sizes_pdb = [16, 32, 64]\n",
        "\n",
        "grid_pdb = list(itertools.product(hidden_dims_pdb, dropouts_pdb, lrs_pdb, batch_sizes_pdb))\n",
        "\n",
        "configs_pdb = [\n",
        "    {'hidden_dim': h, 'dropout': d, 'lr': lr, 'batch_size': bs}\n",
        "    for h, d, lr, bs in grid_pdb\n",
        "]\n",
        "results_pdb = []\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# PDB dataset loaders (set these up before this block!)\n",
        "pdb_train_dataset = TensorDataset(torch.tensor(x_pdb_train, dtype=torch.float32), torch.tensor(y_pdb_train, dtype=torch.long))\n",
        "pdb_val_dataset = TensorDataset(torch.tensor(x_pdb_val, dtype=torch.float32), torch.tensor(y_pdb_val, dtype=torch.long))\n",
        "\n",
        "# Make sure you use configs_pdb and results_pdb for this block!\n",
        "for i, config in enumerate(configs_pdb):\n",
        "    print(f\"\\nConfig {i+1}/{len(configs_pdb)}: {config}\")\n",
        "\n",
        "    train_loader = DataLoader(pdb_train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(pdb_val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    model = BiLSTMModel(input_dim=1280, hidden_dim=config['hidden_dim'],\n",
        "                        dropout=config['dropout'], output_dim=2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    patience = 5\n",
        "    best_val_f1 = 0\n",
        "    best_state = None\n",
        "    bad_epochs = 0\n",
        "\n",
        "    # ---- TRACK LOSS ARRAYS HERE ----\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, 31):\n",
        "        # --- Training ---\n",
        "        model.train()\n",
        "        train_loss_epoch = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss_epoch += loss.item() * xb.size(0)\n",
        "        train_loss_epoch = train_loss_epoch / len(train_loader.dataset)\n",
        "        train_losses.append(train_loss_epoch)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_loss_epoch = 0.0\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                outputs = model(xb)\n",
        "                loss = criterion(outputs, yb)\n",
        "                val_loss_epoch += loss.item() * xb.size(0)\n",
        "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "                all_preds.extend(preds)\n",
        "                all_targets.extend(yb.cpu().numpy())\n",
        "        val_loss_epoch = val_loss_epoch / len(val_loader.dataset)\n",
        "        val_losses.append(val_loss_epoch)\n",
        "\n",
        "        val_f1 = f1_score(all_targets, all_preds, average='binary')\n",
        "        val_acc = accuracy_score(all_targets, all_preds)\n",
        "        print(f\"Epoch {epoch}: TrainLoss = {train_loss_epoch:.4f}, ValLoss = {val_loss_epoch:.4f}, Val Acc = {val_acc:.4f}, Val F1 = {val_f1:.4f}\")\n",
        "\n",
        "        # --- Early Stopping ---\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_state = model.state_dict()\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "        if bad_epochs >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    # --- Log best for summary ---\n",
        "    results_pdb.append({\n",
        "        **config,\n",
        "        'best_val_f1': best_val_f1,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses\n",
        "    })\n",
        "\n",
        "# --- Find best configuration ---\n",
        "best_pdb_config = max(results_pdb, key=lambda x: x['best_val_f1'])\n",
        "print(f\"\\nBest PDB Config: {best_pdb_config}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-9sGA7WkOwz",
        "outputId": "b655e319-1d80-4f73-a5b1-90048b5edc34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Config 1/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6287, ValLoss = 0.5828, Val Acc = 0.6075, Val F1 = 0.2316\n",
            "Epoch 2: TrainLoss = 0.4702, ValLoss = 0.3896, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 3: TrainLoss = 0.3491, ValLoss = 0.3416, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 4: TrainLoss = 0.3094, ValLoss = 0.3766, Val Acc = 0.8333, Val F1 = 0.8342\n",
            "Epoch 5: TrainLoss = 0.2742, ValLoss = 0.3219, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 6: TrainLoss = 0.2566, ValLoss = 0.3332, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 7: TrainLoss = 0.2205, ValLoss = 0.3295, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 8: TrainLoss = 0.1918, ValLoss = 0.3264, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Epoch 9: TrainLoss = 0.1816, ValLoss = 0.3962, Val Acc = 0.8172, Val F1 = 0.7606\n",
            "Epoch 10: TrainLoss = 0.1544, ValLoss = 0.3499, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 11: TrainLoss = 0.1492, ValLoss = 0.3479, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 12: TrainLoss = 0.1279, ValLoss = 0.3950, Val Acc = 0.8118, Val F1 = 0.7682\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 2/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6628, ValLoss = 0.6205, Val Acc = 0.5806, Val F1 = 0.1333\n",
            "Epoch 2: TrainLoss = 0.5578, ValLoss = 0.4955, Val Acc = 0.7688, Val F1 = 0.7075\n",
            "Epoch 3: TrainLoss = 0.4190, ValLoss = 0.3862, Val Acc = 0.8226, Val F1 = 0.7975\n",
            "Epoch 4: TrainLoss = 0.3414, ValLoss = 0.3585, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 5: TrainLoss = 0.3005, ValLoss = 0.3404, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 6: TrainLoss = 0.2744, ValLoss = 0.3348, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 7: TrainLoss = 0.2464, ValLoss = 0.3526, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 8: TrainLoss = 0.2229, ValLoss = 0.3252, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 9: TrainLoss = 0.2097, ValLoss = 0.3511, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 3/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6707, ValLoss = 0.6363, Val Acc = 0.6022, Val F1 = 0.2128\n",
            "Epoch 2: TrainLoss = 0.6129, ValLoss = 0.5798, Val Acc = 0.7688, Val F1 = 0.7075\n",
            "Epoch 3: TrainLoss = 0.5392, ValLoss = 0.5029, Val Acc = 0.7742, Val F1 = 0.7200\n",
            "Epoch 4: TrainLoss = 0.4486, ValLoss = 0.4281, Val Acc = 0.8226, Val F1 = 0.8070\n",
            "Epoch 5: TrainLoss = 0.3779, ValLoss = 0.3792, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 6: TrainLoss = 0.3297, ValLoss = 0.3569, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 7: TrainLoss = 0.2988, ValLoss = 0.3459, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 8: TrainLoss = 0.2778, ValLoss = 0.3379, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 9: TrainLoss = 0.2601, ValLoss = 0.3318, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 10: TrainLoss = 0.2437, ValLoss = 0.3286, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 11: TrainLoss = 0.2252, ValLoss = 0.3309, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 12: TrainLoss = 0.2094, ValLoss = 0.3436, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 13: TrainLoss = 0.1982, ValLoss = 0.3350, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 14: TrainLoss = 0.1798, ValLoss = 0.3286, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 15: TrainLoss = 0.1710, ValLoss = 0.3266, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 16: TrainLoss = 0.1583, ValLoss = 0.3341, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Early stopping at epoch 16\n",
            "\n",
            "Config 4/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5860, ValLoss = 0.4214, Val Acc = 0.7903, Val F1 = 0.7547\n",
            "Epoch 2: TrainLoss = 0.3732, ValLoss = 0.3383, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 3: TrainLoss = 0.2892, ValLoss = 0.3214, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 4: TrainLoss = 0.2438, ValLoss = 0.3224, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Epoch 5: TrainLoss = 0.2269, ValLoss = 0.3244, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 6: TrainLoss = 0.1790, ValLoss = 0.3852, Val Acc = 0.8065, Val F1 = 0.7632\n",
            "Epoch 7: TrainLoss = 0.2276, ValLoss = 0.3707, Val Acc = 0.8226, Val F1 = 0.8177\n",
            "Epoch 8: TrainLoss = 0.1321, ValLoss = 0.3742, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 5/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6258, ValLoss = 0.5228, Val Acc = 0.7581, Val F1 = 0.6715\n",
            "Epoch 2: TrainLoss = 0.4201, ValLoss = 0.3589, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Epoch 3: TrainLoss = 0.3250, ValLoss = 0.3393, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 4: TrainLoss = 0.2659, ValLoss = 0.3382, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 5: TrainLoss = 0.2354, ValLoss = 0.3547, Val Acc = 0.8495, Val F1 = 0.8444\n",
            "Epoch 6: TrainLoss = 0.2287, ValLoss = 0.3885, Val Acc = 0.8387, Val F1 = 0.8387\n",
            "Epoch 7: TrainLoss = 0.2062, ValLoss = 0.3686, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Epoch 8: TrainLoss = 0.1539, ValLoss = 0.3337, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 9: TrainLoss = 0.1382, ValLoss = 0.3580, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Epoch 10: TrainLoss = 0.1219, ValLoss = 0.3985, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 6/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6616, ValLoss = 0.5931, Val Acc = 0.7688, Val F1 = 0.7034\n",
            "Epoch 2: TrainLoss = 0.5408, ValLoss = 0.4843, Val Acc = 0.8333, Val F1 = 0.8306\n",
            "Epoch 3: TrainLoss = 0.4191, ValLoss = 0.3810, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 4: TrainLoss = 0.3286, ValLoss = 0.3462, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 5: TrainLoss = 0.2935, ValLoss = 0.3360, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 6: TrainLoss = 0.2572, ValLoss = 0.3256, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 7: TrainLoss = 0.2301, ValLoss = 0.3222, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 8: TrainLoss = 0.2107, ValLoss = 0.3313, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 9: TrainLoss = 0.1791, ValLoss = 0.3345, Val Acc = 0.8280, Val F1 = 0.8095\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 7/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5149, ValLoss = 0.3666, Val Acc = 0.8280, Val F1 = 0.8182\n",
            "Epoch 2: TrainLoss = 0.3504, ValLoss = 0.3621, Val Acc = 0.8280, Val F1 = 0.8280\n",
            "Epoch 3: TrainLoss = 0.3038, ValLoss = 0.3291, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 4: TrainLoss = 0.2301, ValLoss = 0.3285, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 5: TrainLoss = 0.1747, ValLoss = 0.3629, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 6: TrainLoss = 0.1782, ValLoss = 0.4749, Val Acc = 0.7849, Val F1 = 0.7222\n",
            "Epoch 7: TrainLoss = 0.1476, ValLoss = 0.4023, Val Acc = 0.8333, Val F1 = 0.8287\n",
            "Epoch 8: TrainLoss = 0.1055, ValLoss = 0.4314, Val Acc = 0.8172, Val F1 = 0.7901\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 8/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5613, ValLoss = 0.4299, Val Acc = 0.7796, Val F1 = 0.7050\n",
            "Epoch 2: TrainLoss = 0.3589, ValLoss = 0.4064, Val Acc = 0.7742, Val F1 = 0.7000\n",
            "Epoch 3: TrainLoss = 0.2962, ValLoss = 0.3697, Val Acc = 0.8495, Val F1 = 0.8228\n",
            "Epoch 4: TrainLoss = 0.2339, ValLoss = 0.3247, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 5: TrainLoss = 0.1979, ValLoss = 0.3696, Val Acc = 0.8226, Val F1 = 0.7843\n",
            "Epoch 6: TrainLoss = 0.1777, ValLoss = 0.3999, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 7: TrainLoss = 0.1368, ValLoss = 0.3878, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 8: TrainLoss = 0.1544, ValLoss = 0.5252, Val Acc = 0.7849, Val F1 = 0.7183\n",
            "Epoch 9: TrainLoss = 0.1036, ValLoss = 0.3947, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 10: TrainLoss = 0.0767, ValLoss = 0.4527, Val Acc = 0.8280, Val F1 = 0.7922\n",
            "Epoch 11: TrainLoss = 0.0578, ValLoss = 0.5190, Val Acc = 0.7903, Val F1 = 0.7310\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 9/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6482, ValLoss = 0.5511, Val Acc = 0.7312, Val F1 = 0.5902\n",
            "Epoch 2: TrainLoss = 0.4466, ValLoss = 0.3614, Val Acc = 0.8226, Val F1 = 0.8047\n",
            "Epoch 3: TrainLoss = 0.3320, ValLoss = 0.3439, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 4: TrainLoss = 0.2850, ValLoss = 0.3235, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 5: TrainLoss = 0.2706, ValLoss = 0.3355, Val Acc = 0.8495, Val F1 = 0.8250\n",
            "Epoch 6: TrainLoss = 0.2204, ValLoss = 0.3896, Val Acc = 0.8548, Val F1 = 0.8541\n",
            "Epoch 7: TrainLoss = 0.1906, ValLoss = 0.4122, Val Acc = 0.8495, Val F1 = 0.8495\n",
            "Epoch 8: TrainLoss = 0.1546, ValLoss = 0.3714, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 9: TrainLoss = 0.1398, ValLoss = 0.3790, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 10: TrainLoss = 0.1453, ValLoss = 0.4357, Val Acc = 0.8387, Val F1 = 0.8404\n",
            "Epoch 11: TrainLoss = 0.1161, ValLoss = 0.4269, Val Acc = 0.8495, Val F1 = 0.8462\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 10/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6408, ValLoss = 0.5656, Val Acc = 0.7312, Val F1 = 0.5833\n",
            "Epoch 2: TrainLoss = 0.4696, ValLoss = 0.3973, Val Acc = 0.8172, Val F1 = 0.7952\n",
            "Epoch 3: TrainLoss = 0.3742, ValLoss = 0.3609, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 4: TrainLoss = 0.3053, ValLoss = 0.3318, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 5: TrainLoss = 0.2918, ValLoss = 0.3615, Val Acc = 0.8172, Val F1 = 0.7792\n",
            "Epoch 6: TrainLoss = 0.2584, ValLoss = 0.3331, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 7: TrainLoss = 0.2460, ValLoss = 0.3438, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 8: TrainLoss = 0.2244, ValLoss = 0.3391, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 9: TrainLoss = 0.1935, ValLoss = 0.3468, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 10: TrainLoss = 0.1721, ValLoss = 0.3365, Val Acc = 0.8280, Val F1 = 0.8095\n",
            "Epoch 11: TrainLoss = 0.1604, ValLoss = 0.3470, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 12: TrainLoss = 0.1454, ValLoss = 0.3518, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 11/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6717, ValLoss = 0.6319, Val Acc = 0.7849, Val F1 = 0.7826\n",
            "Epoch 2: TrainLoss = 0.5787, ValLoss = 0.5234, Val Acc = 0.7849, Val F1 = 0.7297\n",
            "Epoch 3: TrainLoss = 0.4597, ValLoss = 0.4156, Val Acc = 0.8065, Val F1 = 0.7778\n",
            "Epoch 4: TrainLoss = 0.3638, ValLoss = 0.3637, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 5: TrainLoss = 0.3176, ValLoss = 0.3399, Val Acc = 0.8602, Val F1 = 0.8488\n",
            "Epoch 6: TrainLoss = 0.2881, ValLoss = 0.3411, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 7: TrainLoss = 0.2654, ValLoss = 0.3254, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 8: TrainLoss = 0.2455, ValLoss = 0.3303, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 9: TrainLoss = 0.2234, ValLoss = 0.3196, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 10: TrainLoss = 0.2063, ValLoss = 0.3134, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 12/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6853, ValLoss = 0.6494, Val Acc = 0.5753, Val F1 = 0.1124\n",
            "Epoch 2: TrainLoss = 0.6278, ValLoss = 0.6006, Val Acc = 0.7258, Val F1 = 0.6277\n",
            "Epoch 3: TrainLoss = 0.5648, ValLoss = 0.5303, Val Acc = 0.7634, Val F1 = 0.6986\n",
            "Epoch 4: TrainLoss = 0.4754, ValLoss = 0.4484, Val Acc = 0.8065, Val F1 = 0.7778\n",
            "Epoch 5: TrainLoss = 0.3978, ValLoss = 0.3881, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 6: TrainLoss = 0.3435, ValLoss = 0.3606, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 7: TrainLoss = 0.3096, ValLoss = 0.3547, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 8: TrainLoss = 0.2941, ValLoss = 0.3377, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 9: TrainLoss = 0.2704, ValLoss = 0.3375, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 10: TrainLoss = 0.2546, ValLoss = 0.3265, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 11: TrainLoss = 0.2488, ValLoss = 0.3400, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 12: TrainLoss = 0.2346, ValLoss = 0.3220, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Epoch 13: TrainLoss = 0.2113, ValLoss = 0.3231, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 13/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6090, ValLoss = 0.4818, Val Acc = 0.7419, Val F1 = 0.6250\n",
            "Epoch 2: TrainLoss = 0.3832, ValLoss = 0.3468, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Epoch 3: TrainLoss = 0.3120, ValLoss = 0.3237, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 4: TrainLoss = 0.2665, ValLoss = 0.3229, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 5: TrainLoss = 0.2208, ValLoss = 0.3194, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 6: TrainLoss = 0.2195, ValLoss = 0.3682, Val Acc = 0.8280, Val F1 = 0.7949\n",
            "Epoch 7: TrainLoss = 0.2169, ValLoss = 0.3457, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 14/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6479, ValLoss = 0.5811, Val Acc = 0.8011, Val F1 = 0.8083\n",
            "Epoch 2: TrainLoss = 0.4713, ValLoss = 0.3938, Val Acc = 0.7957, Val F1 = 0.7532\n",
            "Epoch 3: TrainLoss = 0.3457, ValLoss = 0.4285, Val Acc = 0.7688, Val F1 = 0.6861\n",
            "Epoch 4: TrainLoss = 0.3173, ValLoss = 0.3397, Val Acc = 0.8387, Val F1 = 0.8295\n",
            "Epoch 5: TrainLoss = 0.2639, ValLoss = 0.3306, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 6: TrainLoss = 0.2270, ValLoss = 0.3280, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 7: TrainLoss = 0.2281, ValLoss = 0.3488, Val Acc = 0.8495, Val F1 = 0.8478\n",
            "Epoch 8: TrainLoss = 0.1957, ValLoss = 0.3191, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 9: TrainLoss = 0.1700, ValLoss = 0.3768, Val Acc = 0.8656, Val F1 = 0.8634\n",
            "Epoch 10: TrainLoss = 0.1675, ValLoss = 0.3933, Val Acc = 0.8495, Val F1 = 0.8511\n",
            "Epoch 11: TrainLoss = 0.1469, ValLoss = 0.3510, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 12: TrainLoss = 0.1136, ValLoss = 0.3461, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 13: TrainLoss = 0.0970, ValLoss = 0.3801, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 14: TrainLoss = 0.0847, ValLoss = 0.3843, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 15/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6492, ValLoss = 0.5923, Val Acc = 0.6613, Val F1 = 0.4000\n",
            "Epoch 2: TrainLoss = 0.5346, ValLoss = 0.4694, Val Acc = 0.8118, Val F1 = 0.8023\n",
            "Epoch 3: TrainLoss = 0.3952, ValLoss = 0.3746, Val Acc = 0.8280, Val F1 = 0.8118\n",
            "Epoch 4: TrainLoss = 0.3296, ValLoss = 0.3509, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 5: TrainLoss = 0.3124, ValLoss = 0.3699, Val Acc = 0.8333, Val F1 = 0.8306\n",
            "Epoch 6: TrainLoss = 0.2705, ValLoss = 0.3367, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 7: TrainLoss = 0.2415, ValLoss = 0.3309, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 8: TrainLoss = 0.2253, ValLoss = 0.4198, Val Acc = 0.8333, Val F1 = 0.8360\n",
            "Epoch 9: TrainLoss = 0.2167, ValLoss = 0.3284, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 16/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5314, ValLoss = 0.3802, Val Acc = 0.8226, Val F1 = 0.7843\n",
            "Epoch 2: TrainLoss = 0.3399, ValLoss = 0.3679, Val Acc = 0.8333, Val F1 = 0.8306\n",
            "Epoch 3: TrainLoss = 0.3067, ValLoss = 0.3337, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 4: TrainLoss = 0.2547, ValLoss = 0.3273, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 5: TrainLoss = 0.2197, ValLoss = 0.3186, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 6: TrainLoss = 0.1571, ValLoss = 0.3782, Val Acc = 0.8548, Val F1 = 0.8364\n",
            "Epoch 7: TrainLoss = 0.1512, ValLoss = 0.3515, Val Acc = 0.8387, Val F1 = 0.8256\n",
            "Epoch 8: TrainLoss = 0.1321, ValLoss = 0.4655, Val Acc = 0.8226, Val F1 = 0.7925\n",
            "Epoch 9: TrainLoss = 0.1009, ValLoss = 0.5318, Val Acc = 0.7957, Val F1 = 0.7467\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 17/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5733, ValLoss = 0.4050, Val Acc = 0.8280, Val F1 = 0.8118\n",
            "Epoch 2: TrainLoss = 0.3619, ValLoss = 0.3751, Val Acc = 0.8065, Val F1 = 0.7534\n",
            "Epoch 3: TrainLoss = 0.3038, ValLoss = 0.3770, Val Acc = 0.8280, Val F1 = 0.7867\n",
            "Epoch 4: TrainLoss = 0.2627, ValLoss = 0.3361, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 5: TrainLoss = 0.2073, ValLoss = 0.3194, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 6: TrainLoss = 0.1912, ValLoss = 0.3590, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 7: TrainLoss = 0.1789, ValLoss = 0.3702, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 8: TrainLoss = 0.1353, ValLoss = 0.3780, Val Acc = 0.8548, Val F1 = 0.8344\n",
            "Epoch 9: TrainLoss = 0.1162, ValLoss = 0.4125, Val Acc = 0.8065, Val F1 = 0.7600\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 18/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6207, ValLoss = 0.4836, Val Acc = 0.8280, Val F1 = 0.8095\n",
            "Epoch 2: TrainLoss = 0.3983, ValLoss = 0.3588, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 3: TrainLoss = 0.3439, ValLoss = 0.4281, Val Acc = 0.7742, Val F1 = 0.6912\n",
            "Epoch 4: TrainLoss = 0.3033, ValLoss = 0.3357, Val Acc = 0.8280, Val F1 = 0.7949\n",
            "Epoch 5: TrainLoss = 0.2497, ValLoss = 0.3464, Val Acc = 0.8333, Val F1 = 0.8050\n",
            "Epoch 6: TrainLoss = 0.2352, ValLoss = 0.3437, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 7: TrainLoss = 0.2059, ValLoss = 0.3290, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 8: TrainLoss = 0.2007, ValLoss = 0.3559, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 9: TrainLoss = 0.1790, ValLoss = 0.4133, Val Acc = 0.8387, Val F1 = 0.8352\n",
            "Epoch 10: TrainLoss = 0.1843, ValLoss = 0.3904, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 11: TrainLoss = 0.1392, ValLoss = 0.3679, Val Acc = 0.8226, Val F1 = 0.7950\n",
            "Epoch 12: TrainLoss = 0.1062, ValLoss = 0.3709, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 13: TrainLoss = 0.0878, ValLoss = 0.4038, Val Acc = 0.8333, Val F1 = 0.8121\n",
            "Epoch 14: TrainLoss = 0.0690, ValLoss = 0.4252, Val Acc = 0.8280, Val F1 = 0.8025\n",
            "Epoch 15: TrainLoss = 0.0572, ValLoss = 0.4263, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 19/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6575, ValLoss = 0.5955, Val Acc = 0.6720, Val F1 = 0.4404\n",
            "Epoch 2: TrainLoss = 0.5286, ValLoss = 0.4648, Val Acc = 0.7796, Val F1 = 0.7092\n",
            "Epoch 3: TrainLoss = 0.3955, ValLoss = 0.3664, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 4: TrainLoss = 0.3346, ValLoss = 0.3434, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 5: TrainLoss = 0.2988, ValLoss = 0.3319, Val Acc = 0.8602, Val F1 = 0.8488\n",
            "Epoch 6: TrainLoss = 0.2794, ValLoss = 0.3199, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 7: TrainLoss = 0.2505, ValLoss = 0.3299, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 8: TrainLoss = 0.2310, ValLoss = 0.3357, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 9: TrainLoss = 0.2145, ValLoss = 0.3261, Val Acc = 0.8387, Val F1 = 0.8256\n",
            "Epoch 10: TrainLoss = 0.1956, ValLoss = 0.3218, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 20/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6684, ValLoss = 0.6304, Val Acc = 0.7366, Val F1 = 0.6370\n",
            "Epoch 2: TrainLoss = 0.5932, ValLoss = 0.5452, Val Acc = 0.8011, Val F1 = 0.7702\n",
            "Epoch 3: TrainLoss = 0.4907, ValLoss = 0.4443, Val Acc = 0.8226, Val F1 = 0.8092\n",
            "Epoch 4: TrainLoss = 0.3915, ValLoss = 0.3776, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 5: TrainLoss = 0.3422, ValLoss = 0.3641, Val Acc = 0.8387, Val F1 = 0.8333\n",
            "Epoch 6: TrainLoss = 0.3118, ValLoss = 0.3417, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 7: TrainLoss = 0.2796, ValLoss = 0.3302, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 8: TrainLoss = 0.2626, ValLoss = 0.3330, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 9: TrainLoss = 0.2497, ValLoss = 0.3422, Val Acc = 0.8387, Val F1 = 0.8333\n",
            "Epoch 10: TrainLoss = 0.2361, ValLoss = 0.3216, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 11: TrainLoss = 0.2206, ValLoss = 0.3228, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 12: TrainLoss = 0.2058, ValLoss = 0.3244, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 21/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6797, ValLoss = 0.6520, Val Acc = 0.5645, Val F1 = 0.0690\n",
            "Epoch 2: TrainLoss = 0.6355, ValLoss = 0.6074, Val Acc = 0.7258, Val F1 = 0.5920\n",
            "Epoch 3: TrainLoss = 0.5786, ValLoss = 0.5452, Val Acc = 0.7634, Val F1 = 0.6944\n",
            "Epoch 4: TrainLoss = 0.5008, ValLoss = 0.4718, Val Acc = 0.8011, Val F1 = 0.7730\n",
            "Epoch 5: TrainLoss = 0.4245, ValLoss = 0.4126, Val Acc = 0.8118, Val F1 = 0.7853\n",
            "Epoch 6: TrainLoss = 0.3647, ValLoss = 0.3822, Val Acc = 0.8065, Val F1 = 0.7722\n",
            "Epoch 7: TrainLoss = 0.3347, ValLoss = 0.3523, Val Acc = 0.8333, Val F1 = 0.8229\n",
            "Epoch 8: TrainLoss = 0.3066, ValLoss = 0.3463, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 9: TrainLoss = 0.3004, ValLoss = 0.3385, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 10: TrainLoss = 0.2788, ValLoss = 0.3413, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 11: TrainLoss = 0.2739, ValLoss = 0.3344, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 12: TrainLoss = 0.2487, ValLoss = 0.3298, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 13: TrainLoss = 0.2453, ValLoss = 0.3340, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 14: TrainLoss = 0.2349, ValLoss = 0.3454, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 15: TrainLoss = 0.2296, ValLoss = 0.3270, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 16: TrainLoss = 0.2055, ValLoss = 0.3287, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 17: TrainLoss = 0.1919, ValLoss = 0.3298, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 18: TrainLoss = 0.1802, ValLoss = 0.3358, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 19: TrainLoss = 0.1836, ValLoss = 0.3337, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Early stopping at epoch 19\n",
            "\n",
            "Config 22/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6153, ValLoss = 0.4703, Val Acc = 0.7957, Val F1 = 0.7595\n",
            "Epoch 2: TrainLoss = 0.3980, ValLoss = 0.4054, Val Acc = 0.7849, Val F1 = 0.7183\n",
            "Epoch 3: TrainLoss = 0.3401, ValLoss = 0.3769, Val Acc = 0.8387, Val F1 = 0.8370\n",
            "Epoch 4: TrainLoss = 0.2865, ValLoss = 0.3293, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 5: TrainLoss = 0.2544, ValLoss = 0.3351, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 6: TrainLoss = 0.2261, ValLoss = 0.3156, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 7: TrainLoss = 0.1971, ValLoss = 0.3785, Val Acc = 0.8495, Val F1 = 0.8478\n",
            "Epoch 8: TrainLoss = 0.1981, ValLoss = 0.3206, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 9: TrainLoss = 0.1664, ValLoss = 0.3626, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Epoch 10: TrainLoss = 0.1625, ValLoss = 0.3819, Val Acc = 0.8172, Val F1 = 0.7821\n",
            "Epoch 11: TrainLoss = 0.1283, ValLoss = 0.3951, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Epoch 12: TrainLoss = 0.1344, ValLoss = 0.4261, Val Acc = 0.8065, Val F1 = 0.7568\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 23/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6454, ValLoss = 0.5583, Val Acc = 0.7151, Val F1 = 0.5620\n",
            "Epoch 2: TrainLoss = 0.4722, ValLoss = 0.4028, Val Acc = 0.8118, Val F1 = 0.7826\n",
            "Epoch 3: TrainLoss = 0.3688, ValLoss = 0.3946, Val Acc = 0.7796, Val F1 = 0.7092\n",
            "Epoch 4: TrainLoss = 0.3441, ValLoss = 0.3900, Val Acc = 0.8226, Val F1 = 0.8272\n",
            "Epoch 5: TrainLoss = 0.3126, ValLoss = 0.3798, Val Acc = 0.8118, Val F1 = 0.7552\n",
            "Epoch 6: TrainLoss = 0.2710, ValLoss = 0.3365, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 7: TrainLoss = 0.2487, ValLoss = 0.3267, Val Acc = 0.8656, Val F1 = 0.8503\n",
            "Epoch 8: TrainLoss = 0.2202, ValLoss = 0.3337, Val Acc = 0.8495, Val F1 = 0.8293\n",
            "Epoch 9: TrainLoss = 0.1929, ValLoss = 0.3290, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Epoch 10: TrainLoss = 0.1912, ValLoss = 0.3294, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 11: TrainLoss = 0.1538, ValLoss = 0.3392, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 12: TrainLoss = 0.1465, ValLoss = 0.3544, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 24/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6550, ValLoss = 0.6001, Val Acc = 0.6667, Val F1 = 0.4151\n",
            "Epoch 2: TrainLoss = 0.5447, ValLoss = 0.4794, Val Acc = 0.7742, Val F1 = 0.7273\n",
            "Epoch 3: TrainLoss = 0.4262, ValLoss = 0.3920, Val Acc = 0.8172, Val F1 = 0.7927\n",
            "Epoch 4: TrainLoss = 0.3644, ValLoss = 0.3893, Val Acc = 0.7957, Val F1 = 0.7361\n",
            "Epoch 5: TrainLoss = 0.3116, ValLoss = 0.3449, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 6: TrainLoss = 0.2846, ValLoss = 0.3393, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 7: TrainLoss = 0.2640, ValLoss = 0.3303, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 8: TrainLoss = 0.2470, ValLoss = 0.3264, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 9: TrainLoss = 0.2291, ValLoss = 0.3265, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 10: TrainLoss = 0.2113, ValLoss = 0.3254, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 25/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6057, ValLoss = 0.4376, Val Acc = 0.7957, Val F1 = 0.7361\n",
            "Epoch 2: TrainLoss = 0.3777, ValLoss = 0.3522, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Epoch 3: TrainLoss = 0.3192, ValLoss = 0.3403, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 4: TrainLoss = 0.3087, ValLoss = 0.3641, Val Acc = 0.8548, Val F1 = 0.8138\n",
            "Epoch 5: TrainLoss = 0.2706, ValLoss = 0.3468, Val Acc = 0.8387, Val F1 = 0.8000\n",
            "Epoch 6: TrainLoss = 0.2355, ValLoss = 0.3166, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 7: TrainLoss = 0.1958, ValLoss = 0.3039, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 26/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5973, ValLoss = 0.4899, Val Acc = 0.7796, Val F1 = 0.7919\n",
            "Epoch 2: TrainLoss = 0.4087, ValLoss = 0.3759, Val Acc = 0.8065, Val F1 = 0.7632\n",
            "Epoch 3: TrainLoss = 0.3350, ValLoss = 0.3290, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 4: TrainLoss = 0.2768, ValLoss = 0.3318, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 5: TrainLoss = 0.2414, ValLoss = 0.3322, Val Acc = 0.8656, Val F1 = 0.8521\n",
            "Epoch 6: TrainLoss = 0.2518, ValLoss = 0.3272, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 7: TrainLoss = 0.1979, ValLoss = 0.3241, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 8: TrainLoss = 0.1798, ValLoss = 0.3522, Val Acc = 0.8656, Val F1 = 0.8571\n",
            "Epoch 9: TrainLoss = 0.1418, ValLoss = 0.3579, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 10: TrainLoss = 0.1393, ValLoss = 0.4089, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 11: TrainLoss = 0.1185, ValLoss = 0.3501, Val Acc = 0.8548, Val F1 = 0.8323\n",
            "Epoch 12: TrainLoss = 0.1073, ValLoss = 0.3729, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 13: TrainLoss = 0.0916, ValLoss = 0.3860, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 27/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6452, ValLoss = 0.5601, Val Acc = 0.7849, Val F1 = 0.7849\n",
            "Epoch 2: TrainLoss = 0.4583, ValLoss = 0.3929, Val Acc = 0.8011, Val F1 = 0.7643\n",
            "Epoch 3: TrainLoss = 0.3591, ValLoss = 0.3531, Val Acc = 0.8387, Val F1 = 0.8295\n",
            "Epoch 4: TrainLoss = 0.3166, ValLoss = 0.3266, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 5: TrainLoss = 0.2671, ValLoss = 0.3199, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 6: TrainLoss = 0.2467, ValLoss = 0.3186, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 7: TrainLoss = 0.2119, ValLoss = 0.3227, Val Acc = 0.8333, Val F1 = 0.8187\n",
            "Epoch 8: TrainLoss = 0.1837, ValLoss = 0.3623, Val Acc = 0.8226, Val F1 = 0.7785\n",
            "Epoch 9: TrainLoss = 0.1852, ValLoss = 0.3420, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 28/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6116, ValLoss = 0.5004, Val Acc = 0.7688, Val F1 = 0.6993\n",
            "Epoch 2: TrainLoss = 0.4026, ValLoss = 0.3619, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 3: TrainLoss = 0.3185, ValLoss = 0.3332, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 4: TrainLoss = 0.2692, ValLoss = 0.3296, Val Acc = 0.8602, Val F1 = 0.8452\n",
            "Epoch 5: TrainLoss = 0.2364, ValLoss = 0.4024, Val Acc = 0.7903, Val F1 = 0.7310\n",
            "Epoch 6: TrainLoss = 0.2171, ValLoss = 0.3515, Val Acc = 0.8495, Val F1 = 0.8250\n",
            "Epoch 7: TrainLoss = 0.1836, ValLoss = 0.3480, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Epoch 8: TrainLoss = 0.1607, ValLoss = 0.3474, Val Acc = 0.8710, Val F1 = 0.8605\n",
            "Epoch 9: TrainLoss = 0.1526, ValLoss = 0.3585, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 10: TrainLoss = 0.1184, ValLoss = 0.3784, Val Acc = 0.8333, Val F1 = 0.8050\n",
            "Epoch 11: TrainLoss = 0.1061, ValLoss = 0.4350, Val Acc = 0.8172, Val F1 = 0.7703\n",
            "Epoch 12: TrainLoss = 0.0979, ValLoss = 0.4268, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 13: TrainLoss = 0.0824, ValLoss = 0.4263, Val Acc = 0.8602, Val F1 = 0.8488\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 29/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6405, ValLoss = 0.5734, Val Acc = 0.6989, Val F1 = 0.5000\n",
            "Epoch 2: TrainLoss = 0.4890, ValLoss = 0.4183, Val Acc = 0.8172, Val F1 = 0.8000\n",
            "Epoch 3: TrainLoss = 0.3695, ValLoss = 0.3567, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 4: TrainLoss = 0.3086, ValLoss = 0.3539, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 5: TrainLoss = 0.2798, ValLoss = 0.3344, Val Acc = 0.8387, Val F1 = 0.8256\n",
            "Epoch 6: TrainLoss = 0.2481, ValLoss = 0.3346, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 7: TrainLoss = 0.2254, ValLoss = 0.3188, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 8: TrainLoss = 0.2039, ValLoss = 0.3555, Val Acc = 0.8226, Val F1 = 0.7898\n",
            "Epoch 9: TrainLoss = 0.1793, ValLoss = 0.3597, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 10: TrainLoss = 0.1670, ValLoss = 0.3517, Val Acc = 0.8172, Val F1 = 0.7848\n",
            "Epoch 11: TrainLoss = 0.1416, ValLoss = 0.3778, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 12: TrainLoss = 0.1463, ValLoss = 0.3892, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 13: TrainLoss = 0.1261, ValLoss = 0.3696, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 14: TrainLoss = 0.1025, ValLoss = 0.3888, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 30/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6559, ValLoss = 0.6016, Val Acc = 0.7151, Val F1 = 0.5691\n",
            "Epoch 2: TrainLoss = 0.5555, ValLoss = 0.5081, Val Acc = 0.7742, Val F1 = 0.7162\n",
            "Epoch 3: TrainLoss = 0.4451, ValLoss = 0.4150, Val Acc = 0.7903, Val F1 = 0.7516\n",
            "Epoch 4: TrainLoss = 0.3604, ValLoss = 0.3687, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 5: TrainLoss = 0.3175, ValLoss = 0.3504, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 6: TrainLoss = 0.2849, ValLoss = 0.3637, Val Acc = 0.8333, Val F1 = 0.8000\n",
            "Epoch 7: TrainLoss = 0.2725, ValLoss = 0.3470, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 8: TrainLoss = 0.2458, ValLoss = 0.3439, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 9: TrainLoss = 0.2329, ValLoss = 0.3286, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 10: TrainLoss = 0.2065, ValLoss = 0.3401, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 31/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5620, ValLoss = 0.4002, Val Acc = 0.7957, Val F1 = 0.7532\n",
            "Epoch 2: TrainLoss = 0.3659, ValLoss = 0.3899, Val Acc = 0.8333, Val F1 = 0.8324\n",
            "Epoch 3: TrainLoss = 0.2914, ValLoss = 0.3306, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 4: TrainLoss = 0.2470, ValLoss = 0.3464, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 5: TrainLoss = 0.2096, ValLoss = 0.3906, Val Acc = 0.8441, Val F1 = 0.8079\n",
            "Epoch 6: TrainLoss = 0.1860, ValLoss = 0.3598, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 7: TrainLoss = 0.1649, ValLoss = 0.3583, Val Acc = 0.8441, Val F1 = 0.8129\n",
            "Epoch 8: TrainLoss = 0.1232, ValLoss = 0.3884, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 9: TrainLoss = 0.1133, ValLoss = 0.4241, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 10: TrainLoss = 0.0841, ValLoss = 0.4310, Val Acc = 0.8280, Val F1 = 0.8025\n",
            "Epoch 11: TrainLoss = 0.0654, ValLoss = 0.4583, Val Acc = 0.8226, Val F1 = 0.8047\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 32/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6208, ValLoss = 0.5053, Val Acc = 0.7527, Val F1 = 0.6618\n",
            "Epoch 2: TrainLoss = 0.3937, ValLoss = 0.4223, Val Acc = 0.7796, Val F1 = 0.7092\n",
            "Epoch 3: TrainLoss = 0.3153, ValLoss = 0.4214, Val Acc = 0.8226, Val F1 = 0.8272\n",
            "Epoch 4: TrainLoss = 0.2637, ValLoss = 0.3323, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 5: TrainLoss = 0.2402, ValLoss = 0.3425, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Epoch 6: TrainLoss = 0.2288, ValLoss = 0.3583, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 7: TrainLoss = 0.1978, ValLoss = 0.3818, Val Acc = 0.8172, Val F1 = 0.7703\n",
            "Epoch 8: TrainLoss = 0.1525, ValLoss = 0.3775, Val Acc = 0.8333, Val F1 = 0.7947\n",
            "Epoch 9: TrainLoss = 0.1345, ValLoss = 0.3770, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 33/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6488, ValLoss = 0.5635, Val Acc = 0.7796, Val F1 = 0.7320\n",
            "Epoch 2: TrainLoss = 0.4703, ValLoss = 0.4007, Val Acc = 0.8333, Val F1 = 0.8187\n",
            "Epoch 3: TrainLoss = 0.3428, ValLoss = 0.3564, Val Acc = 0.8387, Val F1 = 0.8295\n",
            "Epoch 4: TrainLoss = 0.3028, ValLoss = 0.3378, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 5: TrainLoss = 0.2598, ValLoss = 0.3476, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 6: TrainLoss = 0.2312, ValLoss = 0.3449, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 7: TrainLoss = 0.2282, ValLoss = 0.3347, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 8: TrainLoss = 0.1777, ValLoss = 0.3682, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 9: TrainLoss = 0.1648, ValLoss = 0.3555, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 10: TrainLoss = 0.1425, ValLoss = 0.3865, Val Acc = 0.8602, Val F1 = 0.8506\n",
            "Epoch 11: TrainLoss = 0.1222, ValLoss = 0.3630, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 12: TrainLoss = 0.1100, ValLoss = 0.5384, Val Acc = 0.8387, Val F1 = 0.8438\n",
            "Epoch 13: TrainLoss = 0.1423, ValLoss = 0.5181, Val Acc = 0.7903, Val F1 = 0.7234\n",
            "Epoch 14: TrainLoss = 0.1179, ValLoss = 0.4785, Val Acc = 0.8011, Val F1 = 0.7448\n",
            "Epoch 15: TrainLoss = 0.0821, ValLoss = 0.4154, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 34/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5260, ValLoss = 0.3604, Val Acc = 0.8441, Val F1 = 0.8415\n",
            "Epoch 2: TrainLoss = 0.3518, ValLoss = 0.3477, Val Acc = 0.8656, Val F1 = 0.8588\n",
            "Epoch 3: TrainLoss = 0.2753, ValLoss = 0.3595, Val Acc = 0.8656, Val F1 = 0.8603\n",
            "Epoch 4: TrainLoss = 0.2442, ValLoss = 0.3263, Val Acc = 0.8495, Val F1 = 0.8205\n",
            "Epoch 5: TrainLoss = 0.1836, ValLoss = 0.4550, Val Acc = 0.7957, Val F1 = 0.7286\n",
            "Epoch 6: TrainLoss = 0.1694, ValLoss = 0.6309, Val Acc = 0.7849, Val F1 = 0.7015\n",
            "Epoch 7: TrainLoss = 0.1446, ValLoss = 0.3956, Val Acc = 0.8226, Val F1 = 0.7871\n",
            "Epoch 8: TrainLoss = 0.0769, ValLoss = 0.5390, Val Acc = 0.8495, Val F1 = 0.8511\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 35/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5406, ValLoss = 0.3857, Val Acc = 0.8172, Val F1 = 0.8111\n",
            "Epoch 2: TrainLoss = 0.3530, ValLoss = 0.3338, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Epoch 3: TrainLoss = 0.2799, ValLoss = 0.3220, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 4: TrainLoss = 0.2391, ValLoss = 0.3440, Val Acc = 0.8387, Val F1 = 0.8333\n",
            "Epoch 5: TrainLoss = 0.2443, ValLoss = 0.3338, Val Acc = 0.8602, Val F1 = 0.8488\n",
            "Epoch 6: TrainLoss = 0.1595, ValLoss = 0.3331, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 7: TrainLoss = 0.1463, ValLoss = 0.3819, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 8: TrainLoss = 0.0944, ValLoss = 0.4823, Val Acc = 0.8548, Val F1 = 0.8508\n",
            "Epoch 9: TrainLoss = 0.1106, ValLoss = 0.4919, Val Acc = 0.8280, Val F1 = 0.7867\n",
            "Epoch 10: TrainLoss = 0.0810, ValLoss = 0.4291, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 11: TrainLoss = 0.0462, ValLoss = 0.5380, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Epoch 12: TrainLoss = 0.1137, ValLoss = 0.4512, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 13: TrainLoss = 0.0375, ValLoss = 0.4742, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 36/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6849, ValLoss = 0.6008, Val Acc = 0.5860, Val F1 = 0.1538\n",
            "Epoch 2: TrainLoss = 0.5222, ValLoss = 0.4172, Val Acc = 0.8280, Val F1 = 0.8161\n",
            "Epoch 3: TrainLoss = 0.3635, ValLoss = 0.3678, Val Acc = 0.8333, Val F1 = 0.8050\n",
            "Epoch 4: TrainLoss = 0.3191, ValLoss = 0.3490, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 5: TrainLoss = 0.2531, ValLoss = 0.3356, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 6: TrainLoss = 0.2162, ValLoss = 0.3359, Val Acc = 0.8602, Val F1 = 0.8539\n",
            "Epoch 7: TrainLoss = 0.1842, ValLoss = 0.3562, Val Acc = 0.8602, Val F1 = 0.8539\n",
            "Epoch 8: TrainLoss = 0.1596, ValLoss = 0.4011, Val Acc = 0.8495, Val F1 = 0.8427\n",
            "Epoch 9: TrainLoss = 0.1604, ValLoss = 0.4066, Val Acc = 0.8011, Val F1 = 0.7550\n",
            "Epoch 10: TrainLoss = 0.1353, ValLoss = 0.3998, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 11: TrainLoss = 0.0848, ValLoss = 0.4342, Val Acc = 0.8495, Val F1 = 0.8444\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 37/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6060, ValLoss = 0.5008, Val Acc = 0.8172, Val F1 = 0.8023\n",
            "Epoch 2: TrainLoss = 0.4093, ValLoss = 0.3633, Val Acc = 0.8280, Val F1 = 0.8182\n",
            "Epoch 3: TrainLoss = 0.3304, ValLoss = 0.3407, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 4: TrainLoss = 0.2817, ValLoss = 0.3247, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 5: TrainLoss = 0.2567, ValLoss = 0.3247, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 6: TrainLoss = 0.2218, ValLoss = 0.3609, Val Acc = 0.8495, Val F1 = 0.8462\n",
            "Epoch 7: TrainLoss = 0.2084, ValLoss = 0.3465, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 8: TrainLoss = 0.1815, ValLoss = 0.3325, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 9: TrainLoss = 0.1610, ValLoss = 0.3664, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 10: TrainLoss = 0.1445, ValLoss = 0.4001, Val Acc = 0.8548, Val F1 = 0.8525\n",
            "Epoch 11: TrainLoss = 0.1262, ValLoss = 0.3923, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 12: TrainLoss = 0.1028, ValLoss = 0.3854, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 13: TrainLoss = 0.1128, ValLoss = 0.4184, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Epoch 14: TrainLoss = 0.0885, ValLoss = 0.3890, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 15: TrainLoss = 0.0755, ValLoss = 0.4364, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 38/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6562, ValLoss = 0.5998, Val Acc = 0.8011, Val F1 = 0.8000\n",
            "Epoch 2: TrainLoss = 0.5243, ValLoss = 0.4622, Val Acc = 0.7688, Val F1 = 0.7034\n",
            "Epoch 3: TrainLoss = 0.3930, ValLoss = 0.3715, Val Acc = 0.8172, Val F1 = 0.7952\n",
            "Epoch 4: TrainLoss = 0.3360, ValLoss = 0.3471, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 5: TrainLoss = 0.2971, ValLoss = 0.3351, Val Acc = 0.8602, Val F1 = 0.8506\n",
            "Epoch 6: TrainLoss = 0.2588, ValLoss = 0.3345, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 7: TrainLoss = 0.2395, ValLoss = 0.3330, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 8: TrainLoss = 0.2248, ValLoss = 0.3241, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 9: TrainLoss = 0.1961, ValLoss = 0.3208, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 10: TrainLoss = 0.1876, ValLoss = 0.3333, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 39/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6609, ValLoss = 0.6194, Val Acc = 0.7043, Val F1 = 0.5133\n",
            "Epoch 2: TrainLoss = 0.5817, ValLoss = 0.5343, Val Acc = 0.7903, Val F1 = 0.7451\n",
            "Epoch 3: TrainLoss = 0.4775, ValLoss = 0.4471, Val Acc = 0.7849, Val F1 = 0.7297\n",
            "Epoch 4: TrainLoss = 0.3933, ValLoss = 0.3845, Val Acc = 0.8333, Val F1 = 0.8121\n",
            "Epoch 5: TrainLoss = 0.3351, ValLoss = 0.3516, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 6: TrainLoss = 0.3035, ValLoss = 0.3410, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 7: TrainLoss = 0.2826, ValLoss = 0.3382, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 8: TrainLoss = 0.2613, ValLoss = 0.3388, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 9: TrainLoss = 0.2426, ValLoss = 0.3338, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 10: TrainLoss = 0.2252, ValLoss = 0.3387, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 11: TrainLoss = 0.2065, ValLoss = 0.3235, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 12: TrainLoss = 0.1930, ValLoss = 0.3237, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 13: TrainLoss = 0.1860, ValLoss = 0.3281, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 14: TrainLoss = 0.1691, ValLoss = 0.3388, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 40/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5555, ValLoss = 0.3984, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 2: TrainLoss = 0.3400, ValLoss = 0.3589, Val Acc = 0.8495, Val F1 = 0.8462\n",
            "Epoch 3: TrainLoss = 0.3103, ValLoss = 0.4129, Val Acc = 0.8333, Val F1 = 0.8377\n",
            "Epoch 4: TrainLoss = 0.2449, ValLoss = 0.3290, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 5: TrainLoss = 0.2088, ValLoss = 0.3393, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 6: TrainLoss = 0.1915, ValLoss = 0.3591, Val Acc = 0.8226, Val F1 = 0.7950\n",
            "Epoch 7: TrainLoss = 0.1580, ValLoss = 0.3722, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 41/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6197, ValLoss = 0.5185, Val Acc = 0.7849, Val F1 = 0.7959\n",
            "Epoch 2: TrainLoss = 0.4312, ValLoss = 0.3762, Val Acc = 0.8011, Val F1 = 0.7643\n",
            "Epoch 3: TrainLoss = 0.3372, ValLoss = 0.3740, Val Acc = 0.8065, Val F1 = 0.7534\n",
            "Epoch 4: TrainLoss = 0.2801, ValLoss = 0.3276, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 5: TrainLoss = 0.2476, ValLoss = 0.3325, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 6: TrainLoss = 0.2144, ValLoss = 0.3477, Val Acc = 0.8441, Val F1 = 0.8153\n",
            "Epoch 7: TrainLoss = 0.2353, ValLoss = 0.3132, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 8: TrainLoss = 0.1775, ValLoss = 0.3450, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 9: TrainLoss = 0.1444, ValLoss = 0.3715, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 10: TrainLoss = 0.1243, ValLoss = 0.3739, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 11: TrainLoss = 0.1048, ValLoss = 0.4261, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Epoch 12: TrainLoss = 0.1089, ValLoss = 0.4205, Val Acc = 0.8226, Val F1 = 0.7785\n",
            "Epoch 13: TrainLoss = 0.0822, ValLoss = 0.4033, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 14: TrainLoss = 0.0697, ValLoss = 0.4676, Val Acc = 0.8495, Val F1 = 0.8478\n",
            "Epoch 15: TrainLoss = 0.0852, ValLoss = 0.4746, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 16: TrainLoss = 0.0476, ValLoss = 0.4531, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 17: TrainLoss = 0.0422, ValLoss = 0.4738, Val Acc = 0.8333, Val F1 = 0.8121\n",
            "Epoch 18: TrainLoss = 0.0361, ValLoss = 0.5565, Val Acc = 0.8118, Val F1 = 0.7799\n",
            "Epoch 19: TrainLoss = 0.0317, ValLoss = 0.5667, Val Acc = 0.8280, Val F1 = 0.8202\n",
            "Early stopping at epoch 19\n",
            "\n",
            "Config 42/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6405, ValLoss = 0.5641, Val Acc = 0.7957, Val F1 = 0.7865\n",
            "Epoch 2: TrainLoss = 0.4794, ValLoss = 0.4119, Val Acc = 0.8333, Val F1 = 0.8268\n",
            "Epoch 3: TrainLoss = 0.3585, ValLoss = 0.3594, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 4: TrainLoss = 0.3178, ValLoss = 0.3335, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 5: TrainLoss = 0.2833, ValLoss = 0.3211, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 6: TrainLoss = 0.2470, ValLoss = 0.3317, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Epoch 7: TrainLoss = 0.2268, ValLoss = 0.3204, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 8: TrainLoss = 0.1931, ValLoss = 0.3585, Val Acc = 0.8495, Val F1 = 0.8427\n",
            "Epoch 9: TrainLoss = 0.2046, ValLoss = 0.3352, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 10: TrainLoss = 0.1639, ValLoss = 0.3447, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 11: TrainLoss = 0.1390, ValLoss = 0.3650, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 12: TrainLoss = 0.1300, ValLoss = 0.3983, Val Acc = 0.8495, Val F1 = 0.8462\n",
            "Epoch 13: TrainLoss = 0.1218, ValLoss = 0.3562, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 14: TrainLoss = 0.1029, ValLoss = 0.3870, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 15: TrainLoss = 0.0936, ValLoss = 0.4113, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 16: TrainLoss = 0.0818, ValLoss = 0.4139, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Epoch 17: TrainLoss = 0.0639, ValLoss = 0.4326, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 43/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5281, ValLoss = 0.3635, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 2: TrainLoss = 0.3415, ValLoss = 0.3407, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 3: TrainLoss = 0.2963, ValLoss = 0.3636, Val Acc = 0.8387, Val F1 = 0.8026\n",
            "Epoch 4: TrainLoss = 0.2425, ValLoss = 0.3260, Val Acc = 0.8333, Val F1 = 0.8229\n",
            "Epoch 5: TrainLoss = 0.2215, ValLoss = 0.4839, Val Acc = 0.7903, Val F1 = 0.7068\n",
            "Epoch 6: TrainLoss = 0.2070, ValLoss = 0.3514, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 7: TrainLoss = 0.1418, ValLoss = 0.5358, Val Acc = 0.8226, Val F1 = 0.8216\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 44/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5517, ValLoss = 0.3794, Val Acc = 0.8333, Val F1 = 0.8249\n",
            "Epoch 2: TrainLoss = 0.3362, ValLoss = 0.5211, Val Acc = 0.7473, Val F1 = 0.6179\n",
            "Epoch 3: TrainLoss = 0.3546, ValLoss = 0.3674, Val Acc = 0.8280, Val F1 = 0.7922\n",
            "Epoch 4: TrainLoss = 0.2687, ValLoss = 0.3182, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 5: TrainLoss = 0.2101, ValLoss = 0.3727, Val Acc = 0.8226, Val F1 = 0.7785\n",
            "Epoch 6: TrainLoss = 0.1771, ValLoss = 0.3776, Val Acc = 0.8656, Val F1 = 0.8555\n",
            "Epoch 7: TrainLoss = 0.1526, ValLoss = 0.4211, Val Acc = 0.8333, Val F1 = 0.7919\n",
            "Epoch 8: TrainLoss = 0.1292, ValLoss = 0.4102, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 9: TrainLoss = 0.1401, ValLoss = 0.4327, Val Acc = 0.8656, Val F1 = 0.8588\n",
            "Epoch 10: TrainLoss = 0.1390, ValLoss = 0.4381, Val Acc = 0.8441, Val F1 = 0.8176\n",
            "Epoch 11: TrainLoss = 0.0797, ValLoss = 0.4770, Val Acc = 0.8118, Val F1 = 0.7619\n",
            "Epoch 12: TrainLoss = 0.0593, ValLoss = 0.4644, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 13: TrainLoss = 0.0415, ValLoss = 0.5157, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 14: TrainLoss = 0.0317, ValLoss = 0.5398, Val Acc = 0.8333, Val F1 = 0.8229\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 45/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6364, ValLoss = 0.5073, Val Acc = 0.7581, Val F1 = 0.6853\n",
            "Epoch 2: TrainLoss = 0.4116, ValLoss = 0.3627, Val Acc = 0.8172, Val F1 = 0.7875\n",
            "Epoch 3: TrainLoss = 0.3376, ValLoss = 0.3397, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 4: TrainLoss = 0.2666, ValLoss = 0.3534, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 5: TrainLoss = 0.2527, ValLoss = 0.3412, Val Acc = 0.8280, Val F1 = 0.8182\n",
            "Epoch 6: TrainLoss = 0.2339, ValLoss = 0.3633, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 7: TrainLoss = 0.1669, ValLoss = 0.3427, Val Acc = 0.8387, Val F1 = 0.8256\n",
            "Epoch 8: TrainLoss = 0.1522, ValLoss = 0.3511, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 9: TrainLoss = 0.1295, ValLoss = 0.5177, Val Acc = 0.7903, Val F1 = 0.7194\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 46/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6301, ValLoss = 0.5380, Val Acc = 0.7419, Val F1 = 0.6571\n",
            "Epoch 2: TrainLoss = 0.4459, ValLoss = 0.4170, Val Acc = 0.7742, Val F1 = 0.7042\n",
            "Epoch 3: TrainLoss = 0.3601, ValLoss = 0.3449, Val Acc = 0.8602, Val F1 = 0.8506\n",
            "Epoch 4: TrainLoss = 0.2997, ValLoss = 0.3414, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 5: TrainLoss = 0.2787, ValLoss = 0.3168, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 6: TrainLoss = 0.2635, ValLoss = 0.3382, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 7: TrainLoss = 0.2247, ValLoss = 0.3190, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 8: TrainLoss = 0.2125, ValLoss = 0.3216, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 47/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6504, ValLoss = 0.5973, Val Acc = 0.7957, Val F1 = 0.7683\n",
            "Epoch 2: TrainLoss = 0.5345, ValLoss = 0.4740, Val Acc = 0.8333, Val F1 = 0.8208\n",
            "Epoch 3: TrainLoss = 0.4192, ValLoss = 0.3842, Val Acc = 0.8226, Val F1 = 0.8000\n",
            "Epoch 4: TrainLoss = 0.3481, ValLoss = 0.3575, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 5: TrainLoss = 0.3177, ValLoss = 0.3556, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 6: TrainLoss = 0.2963, ValLoss = 0.3333, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 7: TrainLoss = 0.2608, ValLoss = 0.3351, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 8: TrainLoss = 0.2410, ValLoss = 0.3260, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 9: TrainLoss = 0.2295, ValLoss = 0.3233, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 10: TrainLoss = 0.2144, ValLoss = 0.3287, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 11: TrainLoss = 0.2145, ValLoss = 0.3282, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 12: TrainLoss = 0.1967, ValLoss = 0.3418, Val Acc = 0.8280, Val F1 = 0.8025\n",
            "Epoch 13: TrainLoss = 0.1747, ValLoss = 0.3334, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 14: TrainLoss = 0.1617, ValLoss = 0.3529, Val Acc = 0.8602, Val F1 = 0.8523\n",
            "Epoch 15: TrainLoss = 0.1535, ValLoss = 0.3477, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Epoch 16: TrainLoss = 0.1287, ValLoss = 0.3615, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 17: TrainLoss = 0.1254, ValLoss = 0.3653, Val Acc = 0.8280, Val F1 = 0.8025\n",
            "Epoch 18: TrainLoss = 0.1179, ValLoss = 0.3657, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 19: TrainLoss = 0.1146, ValLoss = 0.3702, Val Acc = 0.8495, Val F1 = 0.8272\n",
            "Early stopping at epoch 19\n",
            "\n",
            "Config 48/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6713, ValLoss = 0.6302, Val Acc = 0.7204, Val F1 = 0.6000\n",
            "Epoch 2: TrainLoss = 0.5979, ValLoss = 0.5589, Val Acc = 0.7849, Val F1 = 0.7333\n",
            "Epoch 3: TrainLoss = 0.5128, ValLoss = 0.4723, Val Acc = 0.7957, Val F1 = 0.7564\n",
            "Epoch 4: TrainLoss = 0.4227, ValLoss = 0.4075, Val Acc = 0.8011, Val F1 = 0.7643\n",
            "Epoch 5: TrainLoss = 0.3682, ValLoss = 0.3726, Val Acc = 0.8333, Val F1 = 0.8249\n",
            "Epoch 6: TrainLoss = 0.3263, ValLoss = 0.3527, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 7: TrainLoss = 0.3083, ValLoss = 0.3495, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 8: TrainLoss = 0.2855, ValLoss = 0.3446, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 9: TrainLoss = 0.2692, ValLoss = 0.3267, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 10: TrainLoss = 0.2590, ValLoss = 0.3268, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 11: TrainLoss = 0.2372, ValLoss = 0.3362, Val Acc = 0.8333, Val F1 = 0.8050\n",
            "Epoch 12: TrainLoss = 0.2219, ValLoss = 0.3255, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 13: TrainLoss = 0.2211, ValLoss = 0.3358, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 14: TrainLoss = 0.2086, ValLoss = 0.3403, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 15: TrainLoss = 0.1976, ValLoss = 0.3484, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 16: TrainLoss = 0.1772, ValLoss = 0.3300, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 17: TrainLoss = 0.1708, ValLoss = 0.3318, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 18: TrainLoss = 0.1623, ValLoss = 0.3653, Val Acc = 0.8602, Val F1 = 0.8571\n",
            "Epoch 19: TrainLoss = 0.1562, ValLoss = 0.3427, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 20: TrainLoss = 0.1403, ValLoss = 0.3460, Val Acc = 0.8280, Val F1 = 0.8095\n",
            "Epoch 21: TrainLoss = 0.1322, ValLoss = 0.3544, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 22: TrainLoss = 0.1361, ValLoss = 0.4099, Val Acc = 0.8441, Val F1 = 0.8432\n",
            "Epoch 23: TrainLoss = 0.1425, ValLoss = 0.3891, Val Acc = 0.8548, Val F1 = 0.8508\n",
            "Early stopping at epoch 23\n",
            "\n",
            "Config 49/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5930, ValLoss = 0.4479, Val Acc = 0.8226, Val F1 = 0.8156\n",
            "Epoch 2: TrainLoss = 0.3735, ValLoss = 0.3676, Val Acc = 0.8226, Val F1 = 0.7815\n",
            "Epoch 3: TrainLoss = 0.3164, ValLoss = 0.3872, Val Acc = 0.7903, Val F1 = 0.7310\n",
            "Epoch 4: TrainLoss = 0.2734, ValLoss = 0.3165, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 5: TrainLoss = 0.2895, ValLoss = 0.4828, Val Acc = 0.8011, Val F1 = 0.8141\n",
            "Epoch 6: TrainLoss = 0.2575, ValLoss = 0.4355, Val Acc = 0.8065, Val F1 = 0.7391\n",
            "Epoch 7: TrainLoss = 0.2212, ValLoss = 0.3160, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 8: TrainLoss = 0.1845, ValLoss = 0.3907, Val Acc = 0.8548, Val F1 = 0.8556\n",
            "Epoch 9: TrainLoss = 0.1776, ValLoss = 0.3459, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 10: TrainLoss = 0.1517, ValLoss = 0.3764, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 11: TrainLoss = 0.1441, ValLoss = 0.3771, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 12: TrainLoss = 0.1264, ValLoss = 0.3846, Val Acc = 0.8172, Val F1 = 0.7901\n",
            "Epoch 13: TrainLoss = 0.0983, ValLoss = 0.4080, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 50/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6235, ValLoss = 0.5242, Val Acc = 0.7258, Val F1 = 0.5854\n",
            "Epoch 2: TrainLoss = 0.4274, ValLoss = 0.3643, Val Acc = 0.8387, Val F1 = 0.8256\n",
            "Epoch 3: TrainLoss = 0.3361, ValLoss = 0.3458, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 4: TrainLoss = 0.2949, ValLoss = 0.3471, Val Acc = 0.8387, Val F1 = 0.8101\n",
            "Epoch 5: TrainLoss = 0.2620, ValLoss = 0.3251, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 6: TrainLoss = 0.2394, ValLoss = 0.3287, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Epoch 7: TrainLoss = 0.2099, ValLoss = 0.3328, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 8: TrainLoss = 0.2235, ValLoss = 0.3906, Val Acc = 0.8495, Val F1 = 0.8478\n",
            "Epoch 9: TrainLoss = 0.1905, ValLoss = 0.3549, Val Acc = 0.8656, Val F1 = 0.8588\n",
            "Epoch 10: TrainLoss = 0.1648, ValLoss = 0.4026, Val Acc = 0.8118, Val F1 = 0.7742\n",
            "Epoch 11: TrainLoss = 0.1426, ValLoss = 0.4105, Val Acc = 0.8011, Val F1 = 0.7517\n",
            "Epoch 12: TrainLoss = 0.1385, ValLoss = 0.3665, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 13: TrainLoss = 0.1039, ValLoss = 0.4059, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Epoch 14: TrainLoss = 0.0983, ValLoss = 0.3759, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 51/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6881, ValLoss = 0.6478, Val Acc = 0.5484, Val F1 = 0.6640\n",
            "Epoch 2: TrainLoss = 0.5838, ValLoss = 0.5199, Val Acc = 0.7419, Val F1 = 0.6471\n",
            "Epoch 3: TrainLoss = 0.4476, ValLoss = 0.4125, Val Acc = 0.7849, Val F1 = 0.7297\n",
            "Epoch 4: TrainLoss = 0.3583, ValLoss = 0.3671, Val Acc = 0.7903, Val F1 = 0.7516\n",
            "Epoch 5: TrainLoss = 0.3120, ValLoss = 0.3760, Val Acc = 0.8172, Val F1 = 0.7703\n",
            "Epoch 6: TrainLoss = 0.2871, ValLoss = 0.3325, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 7: TrainLoss = 0.2549, ValLoss = 0.3238, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 8: TrainLoss = 0.2513, ValLoss = 0.3319, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Epoch 9: TrainLoss = 0.2236, ValLoss = 0.3275, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 10: TrainLoss = 0.1986, ValLoss = 0.3443, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 11: TrainLoss = 0.2060, ValLoss = 0.3560, Val Acc = 0.8333, Val F1 = 0.8025\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 52/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5561, ValLoss = 0.3843, Val Acc = 0.8387, Val F1 = 0.8352\n",
            "Epoch 2: TrainLoss = 0.3646, ValLoss = 0.3684, Val Acc = 0.8118, Val F1 = 0.7712\n",
            "Epoch 3: TrainLoss = 0.3257, ValLoss = 0.3269, Val Acc = 0.8495, Val F1 = 0.8427\n",
            "Epoch 4: TrainLoss = 0.2741, ValLoss = 0.3849, Val Acc = 0.8495, Val F1 = 0.8462\n",
            "Epoch 5: TrainLoss = 0.2478, ValLoss = 0.3347, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 6: TrainLoss = 0.2200, ValLoss = 0.3226, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 7: TrainLoss = 0.1888, ValLoss = 0.3209, Val Acc = 0.8441, Val F1 = 0.8176\n",
            "Epoch 8: TrainLoss = 0.1628, ValLoss = 0.3862, Val Acc = 0.8118, Val F1 = 0.7619\n",
            "Epoch 9: TrainLoss = 0.1917, ValLoss = 0.3431, Val Acc = 0.8495, Val F1 = 0.8272\n",
            "Epoch 10: TrainLoss = 0.1344, ValLoss = 0.3914, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 53/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5846, ValLoss = 0.4234, Val Acc = 0.8118, Val F1 = 0.7853\n",
            "Epoch 2: TrainLoss = 0.3647, ValLoss = 0.3317, Val Acc = 0.8602, Val F1 = 0.8488\n",
            "Epoch 3: TrainLoss = 0.3156, ValLoss = 0.3440, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 4: TrainLoss = 0.2550, ValLoss = 0.3735, Val Acc = 0.8387, Val F1 = 0.8387\n",
            "Epoch 5: TrainLoss = 0.2605, ValLoss = 0.3479, Val Acc = 0.8656, Val F1 = 0.8603\n",
            "Epoch 6: TrainLoss = 0.2052, ValLoss = 0.3509, Val Acc = 0.8387, Val F1 = 0.8077\n",
            "Epoch 7: TrainLoss = 0.2280, ValLoss = 0.3261, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 8: TrainLoss = 0.1471, ValLoss = 0.3646, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 9: TrainLoss = 0.1357, ValLoss = 0.3896, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 10: TrainLoss = 0.1076, ValLoss = 0.4858, Val Acc = 0.8065, Val F1 = 0.7391\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 54/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6111, ValLoss = 0.4799, Val Acc = 0.8011, Val F1 = 0.7910\n",
            "Epoch 2: TrainLoss = 0.4022, ValLoss = 0.3621, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 3: TrainLoss = 0.3333, ValLoss = 0.3427, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 4: TrainLoss = 0.2929, ValLoss = 0.3664, Val Acc = 0.8280, Val F1 = 0.7867\n",
            "Epoch 5: TrainLoss = 0.2481, ValLoss = 0.3231, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 6: TrainLoss = 0.2191, ValLoss = 0.3445, Val Acc = 0.8172, Val F1 = 0.7901\n",
            "Epoch 7: TrainLoss = 0.2187, ValLoss = 0.3513, Val Acc = 0.8602, Val F1 = 0.8539\n",
            "Epoch 8: TrainLoss = 0.1797, ValLoss = 0.3362, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 9: TrainLoss = 0.1495, ValLoss = 0.3922, Val Acc = 0.8011, Val F1 = 0.7517\n",
            "Epoch 10: TrainLoss = 0.1428, ValLoss = 0.3698, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 11: TrainLoss = 0.1170, ValLoss = 0.4001, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 12: TrainLoss = 0.1101, ValLoss = 0.4309, Val Acc = 0.8548, Val F1 = 0.8525\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 55/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5793, ValLoss = 0.4333, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 2: TrainLoss = 0.3795, ValLoss = 0.3482, Val Acc = 0.8602, Val F1 = 0.8434\n",
            "Epoch 3: TrainLoss = 0.3030, ValLoss = 0.4428, Val Acc = 0.7796, Val F1 = 0.6963\n",
            "Epoch 4: TrainLoss = 0.2852, ValLoss = 0.3514, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 5: TrainLoss = 0.2458, ValLoss = 0.3728, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 6: TrainLoss = 0.2103, ValLoss = 0.3376, Val Acc = 0.8333, Val F1 = 0.8121\n",
            "Epoch 7: TrainLoss = 0.1862, ValLoss = 0.3491, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 8: TrainLoss = 0.1663, ValLoss = 0.3570, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 9: TrainLoss = 0.1437, ValLoss = 0.4060, Val Acc = 0.8280, Val F1 = 0.7922\n",
            "Epoch 10: TrainLoss = 0.1080, ValLoss = 0.3807, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 56/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6278, ValLoss = 0.5378, Val Acc = 0.7903, Val F1 = 0.7451\n",
            "Epoch 2: TrainLoss = 0.4387, ValLoss = 0.3846, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 3: TrainLoss = 0.3285, ValLoss = 0.3764, Val Acc = 0.8172, Val F1 = 0.7733\n",
            "Epoch 4: TrainLoss = 0.2879, ValLoss = 0.3477, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 5: TrainLoss = 0.2767, ValLoss = 0.4067, Val Acc = 0.8011, Val F1 = 0.7376\n",
            "Epoch 6: TrainLoss = 0.2564, ValLoss = 0.3333, Val Acc = 0.8602, Val F1 = 0.8506\n",
            "Epoch 7: TrainLoss = 0.2133, ValLoss = 0.3465, Val Acc = 0.8333, Val F1 = 0.8025\n",
            "Epoch 8: TrainLoss = 0.1825, ValLoss = 0.3292, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Epoch 9: TrainLoss = 0.1710, ValLoss = 0.3535, Val Acc = 0.8226, Val F1 = 0.7975\n",
            "Epoch 10: TrainLoss = 0.1513, ValLoss = 0.3493, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 11: TrainLoss = 0.1438, ValLoss = 0.3856, Val Acc = 0.8602, Val F1 = 0.8556\n",
            "Epoch 12: TrainLoss = 0.1270, ValLoss = 0.4301, Val Acc = 0.8011, Val F1 = 0.7413\n",
            "Epoch 13: TrainLoss = 0.1110, ValLoss = 0.4394, Val Acc = 0.8172, Val F1 = 0.7703\n",
            "Epoch 14: TrainLoss = 0.0992, ValLoss = 0.3973, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 15: TrainLoss = 0.0854, ValLoss = 0.4479, Val Acc = 0.8172, Val F1 = 0.7848\n",
            "Epoch 16: TrainLoss = 0.0687, ValLoss = 0.4344, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Early stopping at epoch 16\n",
            "\n",
            "Config 57/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6557, ValLoss = 0.5888, Val Acc = 0.7043, Val F1 = 0.5600\n",
            "Epoch 2: TrainLoss = 0.5322, ValLoss = 0.4731, Val Acc = 0.8280, Val F1 = 0.8140\n",
            "Epoch 3: TrainLoss = 0.4191, ValLoss = 0.4321, Val Acc = 0.8065, Val F1 = 0.8105\n",
            "Epoch 4: TrainLoss = 0.3633, ValLoss = 0.4155, Val Acc = 0.8118, Val F1 = 0.8168\n",
            "Epoch 5: TrainLoss = 0.3272, ValLoss = 0.3451, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 6: TrainLoss = 0.2912, ValLoss = 0.3253, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 7: TrainLoss = 0.2616, ValLoss = 0.3305, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 8: TrainLoss = 0.2339, ValLoss = 0.3254, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 9: TrainLoss = 0.2286, ValLoss = 0.3272, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 10: TrainLoss = 0.1966, ValLoss = 0.3295, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 11: TrainLoss = 0.1821, ValLoss = 0.3324, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 12: TrainLoss = 0.1656, ValLoss = 0.3384, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 13: TrainLoss = 0.1548, ValLoss = 0.3473, Val Acc = 0.8602, Val F1 = 0.8506\n",
            "Epoch 14: TrainLoss = 0.1394, ValLoss = 0.3535, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Epoch 15: TrainLoss = 0.1278, ValLoss = 0.3674, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 16: TrainLoss = 0.1160, ValLoss = 0.3781, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 17: TrainLoss = 0.0965, ValLoss = 0.3768, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 18: TrainLoss = 0.0896, ValLoss = 0.3953, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Early stopping at epoch 18\n",
            "\n",
            "Config 58/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5962, ValLoss = 0.3999, Val Acc = 0.8280, Val F1 = 0.8161\n",
            "Epoch 2: TrainLoss = 0.3792, ValLoss = 0.3439, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 3: TrainLoss = 0.2836, ValLoss = 0.3427, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 4: TrainLoss = 0.2488, ValLoss = 0.4118, Val Acc = 0.8333, Val F1 = 0.8342\n",
            "Epoch 5: TrainLoss = 0.2317, ValLoss = 0.3976, Val Acc = 0.8333, Val F1 = 0.8306\n",
            "Epoch 6: TrainLoss = 0.1722, ValLoss = 0.3535, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Epoch 7: TrainLoss = 0.1353, ValLoss = 0.4249, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 59/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6360, ValLoss = 0.5084, Val Acc = 0.7419, Val F1 = 0.6418\n",
            "Epoch 2: TrainLoss = 0.4049, ValLoss = 0.3628, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 3: TrainLoss = 0.3005, ValLoss = 0.3579, Val Acc = 0.8495, Val F1 = 0.8228\n",
            "Epoch 4: TrainLoss = 0.2656, ValLoss = 0.3496, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Epoch 5: TrainLoss = 0.2252, ValLoss = 0.3456, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 6: TrainLoss = 0.1895, ValLoss = 0.3543, Val Acc = 0.8280, Val F1 = 0.7949\n",
            "Epoch 7: TrainLoss = 0.1716, ValLoss = 0.3686, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 60/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6228, ValLoss = 0.5199, Val Acc = 0.7419, Val F1 = 0.6129\n",
            "Epoch 2: TrainLoss = 0.4411, ValLoss = 0.3905, Val Acc = 0.7903, Val F1 = 0.7516\n",
            "Epoch 3: TrainLoss = 0.3324, ValLoss = 0.3469, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 4: TrainLoss = 0.2847, ValLoss = 0.3565, Val Acc = 0.8280, Val F1 = 0.7949\n",
            "Epoch 5: TrainLoss = 0.2793, ValLoss = 0.3226, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 6: TrainLoss = 0.2440, ValLoss = 0.3752, Val Acc = 0.8441, Val F1 = 0.8380\n",
            "Epoch 7: TrainLoss = 0.2105, ValLoss = 0.3501, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 8: TrainLoss = 0.1863, ValLoss = 0.4115, Val Acc = 0.8011, Val F1 = 0.7448\n",
            "Epoch 9: TrainLoss = 0.1683, ValLoss = 0.3547, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 10: TrainLoss = 0.1482, ValLoss = 0.3846, Val Acc = 0.8602, Val F1 = 0.8523\n",
            "Epoch 11: TrainLoss = 0.1738, ValLoss = 0.5823, Val Acc = 0.7796, Val F1 = 0.6870\n",
            "Epoch 12: TrainLoss = 0.1604, ValLoss = 0.3865, Val Acc = 0.8280, Val F1 = 0.8118\n",
            "Epoch 13: TrainLoss = 0.1058, ValLoss = 0.4328, Val Acc = 0.8226, Val F1 = 0.7815\n",
            "Epoch 14: TrainLoss = 0.0949, ValLoss = 0.4224, Val Acc = 0.8387, Val F1 = 0.8295\n",
            "Epoch 15: TrainLoss = 0.1008, ValLoss = 0.4756, Val Acc = 0.8495, Val F1 = 0.8444\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 61/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5794, ValLoss = 0.3670, Val Acc = 0.8333, Val F1 = 0.8229\n",
            "Epoch 2: TrainLoss = 0.3473, ValLoss = 0.4418, Val Acc = 0.7957, Val F1 = 0.8061\n",
            "Epoch 3: TrainLoss = 0.3027, ValLoss = 0.3269, Val Acc = 0.8495, Val F1 = 0.8250\n",
            "Epoch 4: TrainLoss = 0.2520, ValLoss = 0.4409, Val Acc = 0.7849, Val F1 = 0.7143\n",
            "Epoch 5: TrainLoss = 0.1773, ValLoss = 0.4205, Val Acc = 0.8280, Val F1 = 0.7949\n",
            "Epoch 6: TrainLoss = 0.1483, ValLoss = 0.4295, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 7: TrainLoss = 0.1371, ValLoss = 0.3815, Val Acc = 0.8172, Val F1 = 0.7901\n",
            "Epoch 8: TrainLoss = 0.0943, ValLoss = 0.4167, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 9: TrainLoss = 0.0684, ValLoss = 0.5499, Val Acc = 0.8226, Val F1 = 0.8156\n",
            "Epoch 10: TrainLoss = 0.0451, ValLoss = 0.5374, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 11: TrainLoss = 0.0212, ValLoss = 0.7026, Val Acc = 0.8226, Val F1 = 0.8024\n",
            "Epoch 12: TrainLoss = 0.0127, ValLoss = 0.6729, Val Acc = 0.8441, Val F1 = 0.8324\n",
            "Epoch 13: TrainLoss = 0.0182, ValLoss = 0.6676, Val Acc = 0.8172, Val F1 = 0.7952\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 62/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5089, ValLoss = 0.3574, Val Acc = 0.8226, Val F1 = 0.8114\n",
            "Epoch 2: TrainLoss = 0.3455, ValLoss = 0.3561, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Epoch 3: TrainLoss = 0.2787, ValLoss = 0.3520, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 4: TrainLoss = 0.2416, ValLoss = 0.3510, Val Acc = 0.8226, Val F1 = 0.7898\n",
            "Epoch 5: TrainLoss = 0.2078, ValLoss = 0.4245, Val Acc = 0.8333, Val F1 = 0.8342\n",
            "Epoch 6: TrainLoss = 0.1684, ValLoss = 0.3684, Val Acc = 0.8280, Val F1 = 0.8202\n",
            "Epoch 7: TrainLoss = 0.1129, ValLoss = 0.4395, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 8: TrainLoss = 0.0881, ValLoss = 0.4751, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Epoch 9: TrainLoss = 0.0593, ValLoss = 0.5650, Val Acc = 0.8172, Val F1 = 0.7976\n",
            "Epoch 10: TrainLoss = 0.0551, ValLoss = 0.6196, Val Acc = 0.8280, Val F1 = 0.7867\n",
            "Epoch 11: TrainLoss = 0.0671, ValLoss = 0.7784, Val Acc = 0.8011, Val F1 = 0.7376\n",
            "Epoch 12: TrainLoss = 0.1387, ValLoss = 0.5540, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 63/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.5896, ValLoss = 0.4206, Val Acc = 0.8065, Val F1 = 0.7907\n",
            "Epoch 2: TrainLoss = 0.3579, ValLoss = 0.3477, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 3: TrainLoss = 0.2973, ValLoss = 0.3407, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 4: TrainLoss = 0.2464, ValLoss = 0.3549, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Epoch 5: TrainLoss = 0.2313, ValLoss = 0.3529, Val Acc = 0.8495, Val F1 = 0.8272\n",
            "Epoch 6: TrainLoss = 0.1910, ValLoss = 0.3754, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 7: TrainLoss = 0.1471, ValLoss = 0.3817, Val Acc = 0.8172, Val F1 = 0.7848\n",
            "Epoch 8: TrainLoss = 0.1247, ValLoss = 0.5841, Val Acc = 0.7796, Val F1 = 0.7050\n",
            "Epoch 9: TrainLoss = 0.1568, ValLoss = 0.3797, Val Acc = 0.8441, Val F1 = 0.8199\n",
            "Epoch 10: TrainLoss = 0.1369, ValLoss = 0.4175, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 11: TrainLoss = 0.0849, ValLoss = 0.4222, Val Acc = 0.8280, Val F1 = 0.8182\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 64/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6065, ValLoss = 0.4668, Val Acc = 0.8118, Val F1 = 0.7953\n",
            "Epoch 2: TrainLoss = 0.3979, ValLoss = 0.3764, Val Acc = 0.8065, Val F1 = 0.7600\n",
            "Epoch 3: TrainLoss = 0.3169, ValLoss = 0.4116, Val Acc = 0.8011, Val F1 = 0.7338\n",
            "Epoch 4: TrainLoss = 0.2966, ValLoss = 0.3239, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 5: TrainLoss = 0.2430, ValLoss = 0.3157, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 6: TrainLoss = 0.2122, ValLoss = 0.3226, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 7: TrainLoss = 0.1821, ValLoss = 0.3571, Val Acc = 0.8333, Val F1 = 0.8098\n",
            "Epoch 8: TrainLoss = 0.1657, ValLoss = 0.3724, Val Acc = 0.8333, Val F1 = 0.8075\n",
            "Epoch 9: TrainLoss = 0.1635, ValLoss = 0.4523, Val Acc = 0.8172, Val F1 = 0.7671\n",
            "Epoch 10: TrainLoss = 0.1288, ValLoss = 0.3681, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 11: TrainLoss = 0.1195, ValLoss = 0.4028, Val Acc = 0.8226, Val F1 = 0.7871\n",
            "Epoch 12: TrainLoss = 0.1010, ValLoss = 0.4254, Val Acc = 0.8495, Val F1 = 0.8462\n",
            "Epoch 13: TrainLoss = 0.1154, ValLoss = 0.4074, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 14: TrainLoss = 0.0700, ValLoss = 0.4328, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 15: TrainLoss = 0.0604, ValLoss = 0.4687, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 65/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6292, ValLoss = 0.5381, Val Acc = 0.7849, Val F1 = 0.7368\n",
            "Epoch 2: TrainLoss = 0.4422, ValLoss = 0.3857, Val Acc = 0.8226, Val F1 = 0.7975\n",
            "Epoch 3: TrainLoss = 0.3390, ValLoss = 0.3429, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 4: TrainLoss = 0.2968, ValLoss = 0.3858, Val Acc = 0.8387, Val F1 = 0.8370\n",
            "Epoch 5: TrainLoss = 0.2860, ValLoss = 0.3302, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 6: TrainLoss = 0.2501, ValLoss = 0.3446, Val Acc = 0.8495, Val F1 = 0.8228\n",
            "Epoch 7: TrainLoss = 0.2189, ValLoss = 0.3846, Val Acc = 0.8387, Val F1 = 0.8352\n",
            "Epoch 8: TrainLoss = 0.2227, ValLoss = 0.3217, Val Acc = 0.8387, Val F1 = 0.8235\n",
            "Epoch 9: TrainLoss = 0.1726, ValLoss = 0.3462, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 10: TrainLoss = 0.1635, ValLoss = 0.3542, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 11: TrainLoss = 0.1384, ValLoss = 0.3634, Val Acc = 0.8387, Val F1 = 0.8052\n",
            "Epoch 12: TrainLoss = 0.1285, ValLoss = 0.3688, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 13: TrainLoss = 0.1146, ValLoss = 0.3968, Val Acc = 0.8441, Val F1 = 0.8398\n",
            "Epoch 14: TrainLoss = 0.1460, ValLoss = 0.3804, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 15: TrainLoss = 0.0924, ValLoss = 0.3904, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 66/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6645, ValLoss = 0.5984, Val Acc = 0.7527, Val F1 = 0.6667\n",
            "Epoch 2: TrainLoss = 0.5480, ValLoss = 0.4901, Val Acc = 0.7957, Val F1 = 0.7532\n",
            "Epoch 3: TrainLoss = 0.4345, ValLoss = 0.3949, Val Acc = 0.8118, Val F1 = 0.7879\n",
            "Epoch 4: TrainLoss = 0.3585, ValLoss = 0.3603, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Epoch 5: TrainLoss = 0.3141, ValLoss = 0.3441, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 6: TrainLoss = 0.2882, ValLoss = 0.3370, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 7: TrainLoss = 0.2547, ValLoss = 0.3235, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 8: TrainLoss = 0.2355, ValLoss = 0.3277, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 9: TrainLoss = 0.2177, ValLoss = 0.3251, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 10: TrainLoss = 0.2029, ValLoss = 0.3318, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 11: TrainLoss = 0.1861, ValLoss = 0.3405, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 67/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5249, ValLoss = 0.3624, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 2: TrainLoss = 0.3379, ValLoss = 0.3214, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 3: TrainLoss = 0.2841, ValLoss = 0.3419, Val Acc = 0.8441, Val F1 = 0.8432\n",
            "Epoch 4: TrainLoss = 0.2366, ValLoss = 0.3580, Val Acc = 0.8656, Val F1 = 0.8555\n",
            "Epoch 5: TrainLoss = 0.2006, ValLoss = 0.3571, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 6: TrainLoss = 0.1665, ValLoss = 0.3957, Val Acc = 0.8226, Val F1 = 0.7925\n",
            "Epoch 7: TrainLoss = 0.1458, ValLoss = 0.6710, Val Acc = 0.7473, Val F1 = 0.6299\n",
            "Epoch 8: TrainLoss = 0.1387, ValLoss = 0.4021, Val Acc = 0.8280, Val F1 = 0.8025\n",
            "Epoch 9: TrainLoss = 0.1288, ValLoss = 0.4234, Val Acc = 0.8441, Val F1 = 0.8153\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 68/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5716, ValLoss = 0.4613, Val Acc = 0.7581, Val F1 = 0.6667\n",
            "Epoch 2: TrainLoss = 0.3717, ValLoss = 0.4148, Val Acc = 0.8172, Val F1 = 0.8211\n",
            "Epoch 3: TrainLoss = 0.3225, ValLoss = 0.3621, Val Acc = 0.8441, Val F1 = 0.8432\n",
            "Epoch 4: TrainLoss = 0.2634, ValLoss = 0.3243, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 5: TrainLoss = 0.2252, ValLoss = 0.3295, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 6: TrainLoss = 0.2134, ValLoss = 0.3643, Val Acc = 0.8602, Val F1 = 0.8539\n",
            "Epoch 7: TrainLoss = 0.1671, ValLoss = 0.3473, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 8: TrainLoss = 0.1469, ValLoss = 0.3875, Val Acc = 0.8226, Val F1 = 0.7815\n",
            "Epoch 9: TrainLoss = 0.1417, ValLoss = 0.4165, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 10: TrainLoss = 0.1476, ValLoss = 0.3753, Val Acc = 0.8226, Val F1 = 0.7975\n",
            "Epoch 11: TrainLoss = 0.0994, ValLoss = 0.4565, Val Acc = 0.8118, Val F1 = 0.7799\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 69/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6197, ValLoss = 0.4969, Val Acc = 0.7903, Val F1 = 0.7484\n",
            "Epoch 2: TrainLoss = 0.4313, ValLoss = 0.3998, Val Acc = 0.8333, Val F1 = 0.8306\n",
            "Epoch 3: TrainLoss = 0.3472, ValLoss = 0.3434, Val Acc = 0.8602, Val F1 = 0.8471\n",
            "Epoch 4: TrainLoss = 0.2888, ValLoss = 0.3580, Val Acc = 0.8602, Val F1 = 0.8539\n",
            "Epoch 5: TrainLoss = 0.2537, ValLoss = 0.3246, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 6: TrainLoss = 0.2290, ValLoss = 0.3303, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 7: TrainLoss = 0.1971, ValLoss = 0.3311, Val Acc = 0.8280, Val F1 = 0.8072\n",
            "Epoch 8: TrainLoss = 0.1754, ValLoss = 0.3620, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 9: TrainLoss = 0.1524, ValLoss = 0.3715, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 70/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.6314, ValLoss = 0.4930, Val Acc = 0.7634, Val F1 = 0.7822\n",
            "Epoch 2: TrainLoss = 0.3723, ValLoss = 0.3474, Val Acc = 0.8495, Val F1 = 0.8293\n",
            "Epoch 3: TrainLoss = 0.3013, ValLoss = 0.3339, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 4: TrainLoss = 0.2671, ValLoss = 0.3392, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 5: TrainLoss = 0.2133, ValLoss = 0.3239, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 6: TrainLoss = 0.2071, ValLoss = 0.3830, Val Acc = 0.8172, Val F1 = 0.7763\n",
            "Epoch 7: TrainLoss = 0.1468, ValLoss = 0.3734, Val Acc = 0.8495, Val F1 = 0.8353\n",
            "Epoch 8: TrainLoss = 0.1286, ValLoss = 0.5126, Val Acc = 0.8441, Val F1 = 0.8432\n",
            "Epoch 9: TrainLoss = 0.1478, ValLoss = 0.4619, Val Acc = 0.8065, Val F1 = 0.7750\n",
            "Epoch 10: TrainLoss = 0.0901, ValLoss = 0.4188, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 11: TrainLoss = 0.0507, ValLoss = 0.6870, Val Acc = 0.8065, Val F1 = 0.7429\n",
            "Epoch 12: TrainLoss = 0.0455, ValLoss = 0.5997, Val Acc = 0.8065, Val F1 = 0.7568\n",
            "Epoch 13: TrainLoss = 0.0266, ValLoss = 0.5465, Val Acc = 0.8172, Val F1 = 0.7952\n",
            "Epoch 14: TrainLoss = 0.0329, ValLoss = 0.6620, Val Acc = 0.8226, Val F1 = 0.7925\n",
            "Epoch 15: TrainLoss = 0.0362, ValLoss = 0.6263, Val Acc = 0.8710, Val F1 = 0.8667\n",
            "Epoch 16: TrainLoss = 0.0338, ValLoss = 0.5299, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 17: TrainLoss = 0.0211, ValLoss = 0.5937, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 18: TrainLoss = 0.0159, ValLoss = 0.6454, Val Acc = 0.8280, Val F1 = 0.8000\n",
            "Epoch 19: TrainLoss = 0.0138, ValLoss = 0.7367, Val Acc = 0.8602, Val F1 = 0.8556\n",
            "Epoch 20: TrainLoss = 0.0065, ValLoss = 0.7257, Val Acc = 0.8172, Val F1 = 0.7848\n",
            "Early stopping at epoch 20\n",
            "\n",
            "Config 71/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5874, ValLoss = 0.4154, Val Acc = 0.7957, Val F1 = 0.7467\n",
            "Epoch 2: TrainLoss = 0.3604, ValLoss = 0.3779, Val Acc = 0.8387, Val F1 = 0.8352\n",
            "Epoch 3: TrainLoss = 0.3016, ValLoss = 0.3342, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 4: TrainLoss = 0.2631, ValLoss = 0.3115, Val Acc = 0.8602, Val F1 = 0.8506\n",
            "Epoch 5: TrainLoss = 0.2133, ValLoss = 0.3490, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 6: TrainLoss = 0.1905, ValLoss = 0.3769, Val Acc = 0.8548, Val F1 = 0.8508\n",
            "Epoch 7: TrainLoss = 0.1362, ValLoss = 0.4126, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 8: TrainLoss = 0.1057, ValLoss = 0.3729, Val Acc = 0.8495, Val F1 = 0.8228\n",
            "Epoch 9: TrainLoss = 0.1019, ValLoss = 0.5111, Val Acc = 0.8548, Val F1 = 0.8556\n",
            "Epoch 10: TrainLoss = 0.0888, ValLoss = 0.5578, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 11: TrainLoss = 0.1269, ValLoss = 0.4068, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 12: TrainLoss = 0.0622, ValLoss = 0.4408, Val Acc = 0.8441, Val F1 = 0.8284\n",
            "Epoch 13: TrainLoss = 0.0344, ValLoss = 0.4958, Val Acc = 0.8280, Val F1 = 0.8161\n",
            "Epoch 14: TrainLoss = 0.0261, ValLoss = 0.5514, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 72/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6296, ValLoss = 0.5010, Val Acc = 0.7366, Val F1 = 0.6316\n",
            "Epoch 2: TrainLoss = 0.3935, ValLoss = 0.3528, Val Acc = 0.8387, Val F1 = 0.8295\n",
            "Epoch 3: TrainLoss = 0.3216, ValLoss = 0.3315, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 4: TrainLoss = 0.2559, ValLoss = 0.3256, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 5: TrainLoss = 0.2156, ValLoss = 0.3206, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 6: TrainLoss = 0.1899, ValLoss = 0.3778, Val Acc = 0.8280, Val F1 = 0.7922\n",
            "Epoch 7: TrainLoss = 0.1653, ValLoss = 0.3956, Val Acc = 0.8495, Val F1 = 0.8228\n",
            "Epoch 8: TrainLoss = 0.1434, ValLoss = 0.3720, Val Acc = 0.8387, Val F1 = 0.8101\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 73/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5959, ValLoss = 0.4781, Val Acc = 0.7688, Val F1 = 0.7190\n",
            "Epoch 2: TrainLoss = 0.3957, ValLoss = 0.3565, Val Acc = 0.8495, Val F1 = 0.8391\n",
            "Epoch 3: TrainLoss = 0.3349, ValLoss = 0.3285, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 4: TrainLoss = 0.3035, ValLoss = 0.3235, Val Acc = 0.8441, Val F1 = 0.8304\n",
            "Epoch 5: TrainLoss = 0.2670, ValLoss = 0.3428, Val Acc = 0.8495, Val F1 = 0.8444\n",
            "Epoch 6: TrainLoss = 0.2573, ValLoss = 0.3879, Val Acc = 0.8065, Val F1 = 0.7500\n",
            "Epoch 7: TrainLoss = 0.2322, ValLoss = 0.3304, Val Acc = 0.8548, Val F1 = 0.8457\n",
            "Epoch 8: TrainLoss = 0.1940, ValLoss = 0.3433, Val Acc = 0.8280, Val F1 = 0.7975\n",
            "Epoch 9: TrainLoss = 0.1831, ValLoss = 0.3409, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 10: TrainLoss = 0.1924, ValLoss = 0.3776, Val Acc = 0.8495, Val F1 = 0.8444\n",
            "Epoch 11: TrainLoss = 0.1566, ValLoss = 0.3629, Val Acc = 0.8226, Val F1 = 0.7925\n",
            "Epoch 12: TrainLoss = 0.1292, ValLoss = 0.4106, Val Acc = 0.8333, Val F1 = 0.8324\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 74/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.6376, ValLoss = 0.5589, Val Acc = 0.7419, Val F1 = 0.6471\n",
            "Epoch 2: TrainLoss = 0.4826, ValLoss = 0.4120, Val Acc = 0.8065, Val F1 = 0.7778\n",
            "Epoch 3: TrainLoss = 0.3643, ValLoss = 0.3683, Val Acc = 0.8387, Val F1 = 0.8315\n",
            "Epoch 4: TrainLoss = 0.3534, ValLoss = 0.3840, Val Acc = 0.8011, Val F1 = 0.7376\n",
            "Epoch 5: TrainLoss = 0.2894, ValLoss = 0.3427, Val Acc = 0.8495, Val F1 = 0.8427\n",
            "Epoch 6: TrainLoss = 0.2653, ValLoss = 0.3242, Val Acc = 0.8495, Val F1 = 0.8372\n",
            "Epoch 7: TrainLoss = 0.2487, ValLoss = 0.3289, Val Acc = 0.8602, Val F1 = 0.8523\n",
            "Epoch 8: TrainLoss = 0.2404, ValLoss = 0.3387, Val Acc = 0.8333, Val F1 = 0.8025\n",
            "Epoch 9: TrainLoss = 0.2152, ValLoss = 0.3364, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Epoch 10: TrainLoss = 0.1886, ValLoss = 0.3347, Val Acc = 0.8602, Val F1 = 0.8523\n",
            "Epoch 11: TrainLoss = 0.1701, ValLoss = 0.3311, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 12: TrainLoss = 0.1586, ValLoss = 0.3708, Val Acc = 0.8602, Val F1 = 0.8571\n",
            "Epoch 13: TrainLoss = 0.1530, ValLoss = 0.3605, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 14: TrainLoss = 0.1313, ValLoss = 0.3650, Val Acc = 0.8226, Val F1 = 0.7898\n",
            "Epoch 15: TrainLoss = 0.1211, ValLoss = 0.3604, Val Acc = 0.8387, Val F1 = 0.8171\n",
            "Epoch 16: TrainLoss = 0.1170, ValLoss = 0.3847, Val Acc = 0.8333, Val F1 = 0.8121\n",
            "Epoch 17: TrainLoss = 0.1180, ValLoss = 0.3850, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 75/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6653, ValLoss = 0.6158, Val Acc = 0.7688, Val F1 = 0.7676\n",
            "Epoch 2: TrainLoss = 0.5610, ValLoss = 0.5134, Val Acc = 0.7634, Val F1 = 0.6944\n",
            "Epoch 3: TrainLoss = 0.4504, ValLoss = 0.4149, Val Acc = 0.8065, Val F1 = 0.7778\n",
            "Epoch 4: TrainLoss = 0.3687, ValLoss = 0.3653, Val Acc = 0.8280, Val F1 = 0.8140\n",
            "Epoch 5: TrainLoss = 0.3339, ValLoss = 0.3514, Val Acc = 0.8495, Val F1 = 0.8293\n",
            "Epoch 6: TrainLoss = 0.3062, ValLoss = 0.3443, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 7: TrainLoss = 0.2800, ValLoss = 0.3335, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 8: TrainLoss = 0.2657, ValLoss = 0.3622, Val Acc = 0.8280, Val F1 = 0.7895\n",
            "Epoch 9: TrainLoss = 0.2602, ValLoss = 0.3318, Val Acc = 0.8441, Val F1 = 0.8221\n",
            "Epoch 10: TrainLoss = 0.2291, ValLoss = 0.3331, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 76/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5687, ValLoss = 0.4190, Val Acc = 0.7688, Val F1 = 0.7034\n",
            "Epoch 2: TrainLoss = 0.3836, ValLoss = 0.3447, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 3: TrainLoss = 0.3343, ValLoss = 0.3467, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 4: TrainLoss = 0.2970, ValLoss = 0.3251, Val Acc = 0.8495, Val F1 = 0.8313\n",
            "Epoch 5: TrainLoss = 0.2326, ValLoss = 0.3849, Val Acc = 0.8226, Val F1 = 0.7871\n",
            "Epoch 6: TrainLoss = 0.2644, ValLoss = 0.3195, Val Acc = 0.8226, Val F1 = 0.8000\n",
            "Epoch 7: TrainLoss = 0.1936, ValLoss = 0.3439, Val Acc = 0.8387, Val F1 = 0.8125\n",
            "Epoch 8: TrainLoss = 0.1655, ValLoss = 0.3509, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 77/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5930, ValLoss = 0.4629, Val Acc = 0.7796, Val F1 = 0.7211\n",
            "Epoch 2: TrainLoss = 0.3776, ValLoss = 0.3535, Val Acc = 0.8495, Val F1 = 0.8228\n",
            "Epoch 3: TrainLoss = 0.3256, ValLoss = 0.3414, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 4: TrainLoss = 0.2725, ValLoss = 0.3786, Val Acc = 0.8280, Val F1 = 0.7895\n",
            "Epoch 5: TrainLoss = 0.2599, ValLoss = 0.3678, Val Acc = 0.8548, Val F1 = 0.8525\n",
            "Epoch 6: TrainLoss = 0.2137, ValLoss = 0.3492, Val Acc = 0.8226, Val F1 = 0.7898\n",
            "Epoch 7: TrainLoss = 0.2075, ValLoss = 0.3410, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Epoch 8: TrainLoss = 0.1952, ValLoss = 0.5519, Val Acc = 0.8226, Val F1 = 0.8308\n",
            "Epoch 9: TrainLoss = 0.1881, ValLoss = 0.3637, Val Acc = 0.8602, Val F1 = 0.8556\n",
            "Epoch 10: TrainLoss = 0.1386, ValLoss = 0.3479, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 11: TrainLoss = 0.1418, ValLoss = 0.4800, Val Acc = 0.8065, Val F1 = 0.7465\n",
            "Epoch 12: TrainLoss = 0.1258, ValLoss = 0.4129, Val Acc = 0.8226, Val F1 = 0.7925\n",
            "Epoch 13: TrainLoss = 0.1357, ValLoss = 0.3915, Val Acc = 0.8387, Val F1 = 0.8193\n",
            "Epoch 14: TrainLoss = 0.0973, ValLoss = 0.4327, Val Acc = 0.8172, Val F1 = 0.7848\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 78/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.6356, ValLoss = 0.5678, Val Acc = 0.6559, Val F1 = 0.3725\n",
            "Epoch 2: TrainLoss = 0.4737, ValLoss = 0.4329, Val Acc = 0.7742, Val F1 = 0.7083\n",
            "Epoch 3: TrainLoss = 0.3949, ValLoss = 0.4034, Val Acc = 0.8011, Val F1 = 0.7338\n",
            "Epoch 4: TrainLoss = 0.3284, ValLoss = 0.3932, Val Acc = 0.7903, Val F1 = 0.7234\n",
            "Epoch 5: TrainLoss = 0.2938, ValLoss = 0.3332, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 6: TrainLoss = 0.2693, ValLoss = 0.3227, Val Acc = 0.8548, Val F1 = 0.8421\n",
            "Epoch 7: TrainLoss = 0.2369, ValLoss = 0.3433, Val Acc = 0.8495, Val F1 = 0.8444\n",
            "Epoch 8: TrainLoss = 0.2212, ValLoss = 0.3543, Val Acc = 0.8333, Val F1 = 0.7947\n",
            "Epoch 9: TrainLoss = 0.2000, ValLoss = 0.3308, Val Acc = 0.8333, Val F1 = 0.8166\n",
            "Epoch 10: TrainLoss = 0.1692, ValLoss = 0.3314, Val Acc = 0.8548, Val F1 = 0.8439\n",
            "Epoch 11: TrainLoss = 0.1622, ValLoss = 0.4015, Val Acc = 0.8495, Val F1 = 0.8495\n",
            "Epoch 12: TrainLoss = 0.1676, ValLoss = 0.3695, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 13: TrainLoss = 0.1419, ValLoss = 0.3538, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Epoch 14: TrainLoss = 0.1247, ValLoss = 0.3643, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 15: TrainLoss = 0.0984, ValLoss = 0.3859, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 16: TrainLoss = 0.0945, ValLoss = 0.3982, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Early stopping at epoch 16\n",
            "\n",
            "Config 79/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.5705, ValLoss = 0.4157, Val Acc = 0.8118, Val F1 = 0.8168\n",
            "Epoch 2: TrainLoss = 0.3782, ValLoss = 0.3460, Val Acc = 0.8495, Val F1 = 0.8333\n",
            "Epoch 3: TrainLoss = 0.3246, ValLoss = 0.3155, Val Acc = 0.8333, Val F1 = 0.8229\n",
            "Epoch 4: TrainLoss = 0.3052, ValLoss = 0.3617, Val Acc = 0.8333, Val F1 = 0.8249\n",
            "Epoch 5: TrainLoss = 0.2416, ValLoss = 0.3896, Val Acc = 0.8548, Val F1 = 0.8492\n",
            "Epoch 6: TrainLoss = 0.2159, ValLoss = 0.3392, Val Acc = 0.8548, Val F1 = 0.8475\n",
            "Epoch 7: TrainLoss = 0.1965, ValLoss = 0.3674, Val Acc = 0.8441, Val F1 = 0.8242\n",
            "Epoch 8: TrainLoss = 0.1795, ValLoss = 0.3567, Val Acc = 0.8441, Val F1 = 0.8263\n",
            "Epoch 9: TrainLoss = 0.1443, ValLoss = 0.3833, Val Acc = 0.8441, Val F1 = 0.8343\n",
            "Epoch 10: TrainLoss = 0.1586, ValLoss = 0.4067, Val Acc = 0.8387, Val F1 = 0.8148\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 80/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.5455, ValLoss = 0.3686, Val Acc = 0.8333, Val F1 = 0.8121\n",
            "Epoch 2: TrainLoss = 0.3645, ValLoss = 0.3399, Val Acc = 0.8548, Val F1 = 0.8402\n",
            "Epoch 3: TrainLoss = 0.3191, ValLoss = 0.3653, Val Acc = 0.8387, Val F1 = 0.8352\n",
            "Epoch 4: TrainLoss = 0.2896, ValLoss = 0.3286, Val Acc = 0.8387, Val F1 = 0.8276\n",
            "Epoch 5: TrainLoss = 0.2355, ValLoss = 0.3584, Val Acc = 0.8548, Val F1 = 0.8508\n",
            "Epoch 6: TrainLoss = 0.2546, ValLoss = 0.4000, Val Acc = 0.8118, Val F1 = 0.7742\n",
            "Epoch 7: TrainLoss = 0.2456, ValLoss = 0.4663, Val Acc = 0.8065, Val F1 = 0.7313\n",
            "Epoch 8: TrainLoss = 0.1901, ValLoss = 0.4184, Val Acc = 0.8172, Val F1 = 0.7671\n",
            "Epoch 9: TrainLoss = 0.1472, ValLoss = 0.4041, Val Acc = 0.8065, Val F1 = 0.7692\n",
            "Epoch 10: TrainLoss = 0.1144, ValLoss = 0.3714, Val Acc = 0.8495, Val F1 = 0.8409\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 81/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.5575, ValLoss = 0.4268, Val Acc = 0.8226, Val F1 = 0.8216\n",
            "Epoch 2: TrainLoss = 0.3871, ValLoss = 0.3674, Val Acc = 0.8172, Val F1 = 0.7763\n",
            "Epoch 3: TrainLoss = 0.3116, ValLoss = 0.3651, Val Acc = 0.8441, Val F1 = 0.8432\n",
            "Epoch 4: TrainLoss = 0.2715, ValLoss = 0.3330, Val Acc = 0.8280, Val F1 = 0.8049\n",
            "Epoch 5: TrainLoss = 0.2378, ValLoss = 0.3348, Val Acc = 0.8333, Val F1 = 0.8144\n",
            "Epoch 6: TrainLoss = 0.2006, ValLoss = 0.3396, Val Acc = 0.8387, Val F1 = 0.8214\n",
            "Epoch 7: TrainLoss = 0.2104, ValLoss = 0.4299, Val Acc = 0.8548, Val F1 = 0.8541\n",
            "Epoch 8: TrainLoss = 0.2022, ValLoss = 0.3793, Val Acc = 0.8441, Val F1 = 0.8362\n",
            "Epoch 9: TrainLoss = 0.1547, ValLoss = 0.3497, Val Acc = 0.8548, Val F1 = 0.8383\n",
            "Epoch 10: TrainLoss = 0.1194, ValLoss = 0.3986, Val Acc = 0.8333, Val F1 = 0.8050\n",
            "Epoch 11: TrainLoss = 0.1552, ValLoss = 0.6166, Val Acc = 0.8333, Val F1 = 0.8394\n",
            "Epoch 12: TrainLoss = 0.1284, ValLoss = 0.4701, Val Acc = 0.8226, Val F1 = 0.7871\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Best PDB Config: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16, 'best_val_f1': 0.8666666666666667, 'train_losses': [0.6314111351220867, 0.3722825258858362, 0.30125696932866664, 0.2671320186240205, 0.21329431431612772, 0.20706337205459538, 0.14678807776696393, 0.1286341146996084, 0.14780240814820472, 0.09013787005213235, 0.050723422910826974, 0.04553512241446573, 0.026645072660081377, 0.03288251492652333, 0.03617812579005807, 0.03378261298463401, 0.021131997442546676, 0.015935172937788275, 0.013762495462993657, 0.006460078771649225], 'val_losses': [0.492990977661584, 0.34740241304520636, 0.33391182845638645, 0.33915814276664485, 0.32389513138801823, 0.38297430994690107, 0.373351905615099, 0.5125850227571302, 0.46186597565168974, 0.4188386817132273, 0.6870490876577233, 0.5997133716460197, 0.5464693698831784, 0.6619588053354653, 0.6263429564173504, 0.5299460240589675, 0.5937195808015844, 0.6453819467175391, 0.7366863037309339, 0.7256655628963183]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##UniSwiss hyperparameter Grid"
      ],
      "metadata": {
        "id": "mYbUetobpqEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- UniSwiss Hyperparameter grid --\n",
        "hidden_dims_uni = [128, 256, 512]\n",
        "dropouts_uni = [0.1, 0.3, 0.5]\n",
        "lrs_uni = [0.0005, 0.001, 0.002]\n",
        "batch_sizes_uni = [16, 32, 64]\n",
        "\n",
        "grid_uni = list(itertools.product(hidden_dims_uni, dropouts_uni, lrs_uni, batch_sizes_uni))\n",
        "\n",
        "configs_uni = [\n",
        "    {'hidden_dim': h, 'dropout': d, 'lr': lr, 'batch_size': bs}\n",
        "    for h, d, lr, bs in grid_uni\n",
        "]\n",
        "results_uni = []\n",
        "\n",
        "# Uniswiss dataset loaders (set these up before this block!)\n",
        "uni_train_dataset = TensorDataset(torch.tensor(x_uni_train, dtype=torch.float32), torch.tensor(y_uni_train, dtype=torch.long))\n",
        "uni_val_dataset = TensorDataset(torch.tensor(x_uni_val, dtype=torch.float32), torch.tensor(y_uni_val, dtype=torch.long))\n",
        "\n",
        "# Make sure you use configs_uni and results_uni for this block!\n",
        "for i, config in enumerate(configs_uni):\n",
        "    print(f\"\\nConfig {i+1}/{len(configs_uni)}: {config}\")\n",
        "\n",
        "    train_loader = DataLoader(uni_train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(uni_val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "    model = BiLSTMModel(input_dim=1280, hidden_dim=config['hidden_dim'],\n",
        "                        dropout=config['dropout'], output_dim=2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    patience = 5\n",
        "    best_val_f1 = 0\n",
        "    best_state = None\n",
        "    bad_epochs = 0\n",
        "\n",
        "    # ---- TRACK LOSS ARRAYS HERE ----\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, 31):\n",
        "        # --- Training ---\n",
        "        model.train()\n",
        "        train_loss_epoch = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss_epoch += loss.item() * xb.size(0)\n",
        "        train_loss_epoch = train_loss_epoch / len(train_loader.dataset)\n",
        "        train_losses.append(train_loss_epoch)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        val_loss_epoch = 0.0\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                outputs = model(xb)\n",
        "                loss = criterion(outputs, yb)\n",
        "                val_loss_epoch += loss.item() * xb.size(0)\n",
        "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "                all_preds.extend(preds)\n",
        "                all_targets.extend(yb.cpu().numpy())\n",
        "        val_loss_epoch = val_loss_epoch / len(val_loader.dataset)\n",
        "        val_losses.append(val_loss_epoch)\n",
        "\n",
        "        val_f1 = f1_score(all_targets, all_preds, average='binary')\n",
        "        val_acc = accuracy_score(all_targets, all_preds)\n",
        "        print(f\"Epoch {epoch}: TrainLoss = {train_loss_epoch:.4f}, ValLoss = {val_loss_epoch:.4f}, Val Acc = {val_acc:.4f}, Val F1 = {val_f1:.4f}\")\n",
        "\n",
        "        # --- Early Stopping ---\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_state = model.state_dict()\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "        if bad_epochs >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    # --- Log best for summary ---\n",
        "    results_uni.append({\n",
        "        **config,\n",
        "        'best_val_f1': best_val_f1,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses\n",
        "    })\n",
        "\n",
        "# --- Find best configuration ---\n",
        "best_uni_config = max(results_uni, key=lambda x: x['best_val_f1'])\n",
        "print(f\"\\nBest uni Config: {best_uni_config}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy19hy-Lps7R",
        "outputId": "d4985a80-4865-49c2-9b5b-d3f109099260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Config 1/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3569, ValLoss = 0.2680, Val Acc = 0.8972, Val F1 = 0.8982\n",
            "Epoch 2: TrainLoss = 0.2631, ValLoss = 0.2626, Val Acc = 0.8893, Val F1 = 0.8817\n",
            "Epoch 3: TrainLoss = 0.2437, ValLoss = 0.2395, Val Acc = 0.8999, Val F1 = 0.8981\n",
            "Epoch 4: TrainLoss = 0.2317, ValLoss = 0.2947, Val Acc = 0.8762, Val F1 = 0.8848\n",
            "Epoch 5: TrainLoss = 0.2182, ValLoss = 0.2269, Val Acc = 0.9065, Val F1 = 0.9062\n",
            "Epoch 6: TrainLoss = 0.2043, ValLoss = 0.2325, Val Acc = 0.9038, Val F1 = 0.9012\n",
            "Epoch 7: TrainLoss = 0.1942, ValLoss = 0.2314, Val Acc = 0.9038, Val F1 = 0.9015\n",
            "Epoch 8: TrainLoss = 0.1845, ValLoss = 0.2369, Val Acc = 0.9025, Val F1 = 0.9026\n",
            "Epoch 9: TrainLoss = 0.1727, ValLoss = 0.2330, Val Acc = 0.9117, Val F1 = 0.9088\n",
            "Epoch 10: TrainLoss = 0.1655, ValLoss = 0.2502, Val Acc = 0.9078, Val F1 = 0.9036\n",
            "Epoch 11: TrainLoss = 0.1514, ValLoss = 0.2860, Val Acc = 0.8854, Val F1 = 0.8880\n",
            "Epoch 12: TrainLoss = 0.1459, ValLoss = 0.2554, Val Acc = 0.9051, Val F1 = 0.9060\n",
            "Epoch 13: TrainLoss = 0.1318, ValLoss = 0.2569, Val Acc = 0.8999, Val F1 = 0.9005\n",
            "Epoch 14: TrainLoss = 0.1224, ValLoss = 0.2649, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 2/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3881, ValLoss = 0.2701, Val Acc = 0.8827, Val F1 = 0.8855\n",
            "Epoch 2: TrainLoss = 0.2676, ValLoss = 0.2560, Val Acc = 0.8893, Val F1 = 0.8906\n",
            "Epoch 3: TrainLoss = 0.2488, ValLoss = 0.3063, Val Acc = 0.8656, Val F1 = 0.8753\n",
            "Epoch 4: TrainLoss = 0.2369, ValLoss = 0.2362, Val Acc = 0.9012, Val F1 = 0.8988\n",
            "Epoch 5: TrainLoss = 0.2218, ValLoss = 0.2520, Val Acc = 0.8920, Val F1 = 0.8852\n",
            "Epoch 6: TrainLoss = 0.2160, ValLoss = 0.2290, Val Acc = 0.9130, Val F1 = 0.9101\n",
            "Epoch 7: TrainLoss = 0.2049, ValLoss = 0.2351, Val Acc = 0.8972, Val F1 = 0.9000\n",
            "Epoch 8: TrainLoss = 0.1974, ValLoss = 0.2359, Val Acc = 0.8972, Val F1 = 0.8995\n",
            "Epoch 9: TrainLoss = 0.1889, ValLoss = 0.2364, Val Acc = 0.8999, Val F1 = 0.9021\n",
            "Epoch 10: TrainLoss = 0.1806, ValLoss = 0.2317, Val Acc = 0.9078, Val F1 = 0.9067\n",
            "Epoch 11: TrainLoss = 0.1745, ValLoss = 0.2830, Val Acc = 0.8893, Val F1 = 0.8953\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 3/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4372, ValLoss = 0.2904, Val Acc = 0.8775, Val F1 = 0.8791\n",
            "Epoch 2: TrainLoss = 0.2793, ValLoss = 0.2632, Val Acc = 0.8933, Val F1 = 0.8952\n",
            "Epoch 3: TrainLoss = 0.2560, ValLoss = 0.2493, Val Acc = 0.9012, Val F1 = 0.9030\n",
            "Epoch 4: TrainLoss = 0.2450, ValLoss = 0.2496, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Epoch 5: TrainLoss = 0.2310, ValLoss = 0.2360, Val Acc = 0.9025, Val F1 = 0.9005\n",
            "Epoch 6: TrainLoss = 0.2199, ValLoss = 0.2334, Val Acc = 0.9091, Val F1 = 0.9089\n",
            "Epoch 7: TrainLoss = 0.2166, ValLoss = 0.2280, Val Acc = 0.9078, Val F1 = 0.9062\n",
            "Epoch 8: TrainLoss = 0.2056, ValLoss = 0.2359, Val Acc = 0.8999, Val F1 = 0.8997\n",
            "Epoch 9: TrainLoss = 0.2021, ValLoss = 0.2378, Val Acc = 0.9012, Val F1 = 0.8963\n",
            "Epoch 10: TrainLoss = 0.1943, ValLoss = 0.2369, Val Acc = 0.8972, Val F1 = 0.8995\n",
            "Epoch 11: TrainLoss = 0.1881, ValLoss = 0.2382, Val Acc = 0.8972, Val F1 = 0.9000\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 4/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3398, ValLoss = 0.2610, Val Acc = 0.8893, Val F1 = 0.8856\n",
            "Epoch 2: TrainLoss = 0.2603, ValLoss = 0.2342, Val Acc = 0.9038, Val F1 = 0.9001\n",
            "Epoch 3: TrainLoss = 0.2365, ValLoss = 0.2323, Val Acc = 0.9065, Val F1 = 0.9034\n",
            "Epoch 4: TrainLoss = 0.2189, ValLoss = 0.2373, Val Acc = 0.8999, Val F1 = 0.8962\n",
            "Epoch 5: TrainLoss = 0.2064, ValLoss = 0.2305, Val Acc = 0.9051, Val F1 = 0.9053\n",
            "Epoch 6: TrainLoss = 0.1874, ValLoss = 0.2990, Val Acc = 0.8814, Val F1 = 0.8883\n",
            "Epoch 7: TrainLoss = 0.1734, ValLoss = 0.2517, Val Acc = 0.9025, Val F1 = 0.9039\n",
            "Epoch 8: TrainLoss = 0.1558, ValLoss = 0.3104, Val Acc = 0.8841, Val F1 = 0.8903\n",
            "Epoch 9: TrainLoss = 0.1393, ValLoss = 0.2903, Val Acc = 0.8959, Val F1 = 0.9014\n",
            "Epoch 10: TrainLoss = 0.1239, ValLoss = 0.2495, Val Acc = 0.8999, Val F1 = 0.8967\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 5/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3634, ValLoss = 0.2560, Val Acc = 0.8972, Val F1 = 0.8974\n",
            "Epoch 2: TrainLoss = 0.2612, ValLoss = 0.2451, Val Acc = 0.8999, Val F1 = 0.9005\n",
            "Epoch 3: TrainLoss = 0.2390, ValLoss = 0.2506, Val Acc = 0.8999, Val F1 = 0.9021\n",
            "Epoch 4: TrainLoss = 0.2226, ValLoss = 0.2461, Val Acc = 0.8999, Val F1 = 0.8933\n",
            "Epoch 5: TrainLoss = 0.2093, ValLoss = 0.2414, Val Acc = 0.9012, Val F1 = 0.8957\n",
            "Epoch 6: TrainLoss = 0.1950, ValLoss = 0.2364, Val Acc = 0.9078, Val F1 = 0.9072\n",
            "Epoch 7: TrainLoss = 0.1821, ValLoss = 0.2356, Val Acc = 0.9104, Val F1 = 0.9101\n",
            "Epoch 8: TrainLoss = 0.1673, ValLoss = 0.2467, Val Acc = 0.8959, Val F1 = 0.8942\n",
            "Epoch 9: TrainLoss = 0.1572, ValLoss = 0.2647, Val Acc = 0.8933, Val F1 = 0.8971\n",
            "Epoch 10: TrainLoss = 0.1484, ValLoss = 0.2402, Val Acc = 0.9051, Val F1 = 0.9032\n",
            "Epoch 11: TrainLoss = 0.1311, ValLoss = 0.2575, Val Acc = 0.8986, Val F1 = 0.8952\n",
            "Epoch 12: TrainLoss = 0.1205, ValLoss = 0.2775, Val Acc = 0.8959, Val F1 = 0.8983\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 6/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3794, ValLoss = 0.2663, Val Acc = 0.8867, Val F1 = 0.8856\n",
            "Epoch 2: TrainLoss = 0.2691, ValLoss = 0.2440, Val Acc = 0.8972, Val F1 = 0.8940\n",
            "Epoch 3: TrainLoss = 0.2482, ValLoss = 0.2348, Val Acc = 0.8986, Val F1 = 0.8983\n",
            "Epoch 4: TrainLoss = 0.2311, ValLoss = 0.2362, Val Acc = 0.8986, Val F1 = 0.8983\n",
            "Epoch 5: TrainLoss = 0.2116, ValLoss = 0.2348, Val Acc = 0.9038, Val F1 = 0.8999\n",
            "Epoch 6: TrainLoss = 0.2043, ValLoss = 0.2230, Val Acc = 0.9104, Val F1 = 0.9088\n",
            "Epoch 7: TrainLoss = 0.1946, ValLoss = 0.2243, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 8: TrainLoss = 0.1855, ValLoss = 0.2544, Val Acc = 0.8920, Val F1 = 0.8957\n",
            "Epoch 9: TrainLoss = 0.1722, ValLoss = 0.2605, Val Acc = 0.8946, Val F1 = 0.8985\n",
            "Epoch 10: TrainLoss = 0.1656, ValLoss = 0.2609, Val Acc = 0.8946, Val F1 = 0.8974\n",
            "Epoch 11: TrainLoss = 0.1574, ValLoss = 0.2401, Val Acc = 0.9038, Val F1 = 0.9051\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 7/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3292, ValLoss = 0.2769, Val Acc = 0.8880, Val F1 = 0.8821\n",
            "Epoch 2: TrainLoss = 0.2586, ValLoss = 0.2297, Val Acc = 0.9038, Val F1 = 0.9031\n",
            "Epoch 3: TrainLoss = 0.2359, ValLoss = 0.2445, Val Acc = 0.9051, Val F1 = 0.9062\n",
            "Epoch 4: TrainLoss = 0.2186, ValLoss = 0.2299, Val Acc = 0.9012, Val F1 = 0.9014\n",
            "Epoch 5: TrainLoss = 0.2000, ValLoss = 0.2355, Val Acc = 0.9065, Val F1 = 0.9031\n",
            "Epoch 6: TrainLoss = 0.1889, ValLoss = 0.2963, Val Acc = 0.8827, Val F1 = 0.8905\n",
            "Epoch 7: TrainLoss = 0.1695, ValLoss = 0.2387, Val Acc = 0.9025, Val F1 = 0.9005\n",
            "Epoch 8: TrainLoss = 0.1529, ValLoss = 0.2598, Val Acc = 0.8906, Val F1 = 0.8846\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 8/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3391, ValLoss = 0.2587, Val Acc = 0.9012, Val F1 = 0.9032\n",
            "Epoch 2: TrainLoss = 0.2540, ValLoss = 0.2387, Val Acc = 0.8972, Val F1 = 0.8952\n",
            "Epoch 3: TrainLoss = 0.2315, ValLoss = 0.2373, Val Acc = 0.9104, Val F1 = 0.9101\n",
            "Epoch 4: TrainLoss = 0.2132, ValLoss = 0.2619, Val Acc = 0.8880, Val F1 = 0.8794\n",
            "Epoch 5: TrainLoss = 0.2061, ValLoss = 0.2502, Val Acc = 0.8999, Val F1 = 0.8953\n",
            "Epoch 6: TrainLoss = 0.1859, ValLoss = 0.2464, Val Acc = 0.9038, Val F1 = 0.9036\n",
            "Epoch 7: TrainLoss = 0.1683, ValLoss = 0.2689, Val Acc = 0.8972, Val F1 = 0.8995\n",
            "Epoch 8: TrainLoss = 0.1517, ValLoss = 0.2727, Val Acc = 0.9051, Val F1 = 0.9093\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 9/81: {'hidden_dim': 128, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3584, ValLoss = 0.3199, Val Acc = 0.8656, Val F1 = 0.8768\n",
            "Epoch 2: TrainLoss = 0.2572, ValLoss = 0.2549, Val Acc = 0.8867, Val F1 = 0.8828\n",
            "Epoch 3: TrainLoss = 0.2447, ValLoss = 0.2315, Val Acc = 0.8999, Val F1 = 0.8989\n",
            "Epoch 4: TrainLoss = 0.2221, ValLoss = 0.2299, Val Acc = 0.9104, Val F1 = 0.9093\n",
            "Epoch 5: TrainLoss = 0.2071, ValLoss = 0.2318, Val Acc = 0.9025, Val F1 = 0.8995\n",
            "Epoch 6: TrainLoss = 0.1895, ValLoss = 0.2805, Val Acc = 0.8893, Val F1 = 0.8947\n",
            "Epoch 7: TrainLoss = 0.1792, ValLoss = 0.2405, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 8: TrainLoss = 0.1627, ValLoss = 0.2426, Val Acc = 0.9091, Val F1 = 0.9053\n",
            "Epoch 9: TrainLoss = 0.1417, ValLoss = 0.2283, Val Acc = 0.9130, Val F1 = 0.9108\n",
            "Epoch 10: TrainLoss = 0.1243, ValLoss = 0.2257, Val Acc = 0.9144, Val F1 = 0.9134\n",
            "Epoch 11: TrainLoss = 0.1144, ValLoss = 0.2502, Val Acc = 0.9091, Val F1 = 0.9071\n",
            "Epoch 12: TrainLoss = 0.0980, ValLoss = 0.2646, Val Acc = 0.9051, Val F1 = 0.9030\n",
            "Epoch 13: TrainLoss = 0.0952, ValLoss = 0.2678, Val Acc = 0.9104, Val F1 = 0.9091\n",
            "Epoch 14: TrainLoss = 0.0803, ValLoss = 0.2773, Val Acc = 0.9065, Val F1 = 0.9069\n",
            "Epoch 15: TrainLoss = 0.0791, ValLoss = 0.2871, Val Acc = 0.9065, Val F1 = 0.9077\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 10/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3597, ValLoss = 0.2638, Val Acc = 0.8880, Val F1 = 0.8840\n",
            "Epoch 2: TrainLoss = 0.2683, ValLoss = 0.2542, Val Acc = 0.8959, Val F1 = 0.8907\n",
            "Epoch 3: TrainLoss = 0.2464, ValLoss = 0.2407, Val Acc = 0.9051, Val F1 = 0.9024\n",
            "Epoch 4: TrainLoss = 0.2369, ValLoss = 0.2617, Val Acc = 0.8880, Val F1 = 0.8784\n",
            "Epoch 5: TrainLoss = 0.2279, ValLoss = 0.2520, Val Acc = 0.8920, Val F1 = 0.8832\n",
            "Epoch 6: TrainLoss = 0.2133, ValLoss = 0.2413, Val Acc = 0.8999, Val F1 = 0.9031\n",
            "Epoch 7: TrainLoss = 0.2054, ValLoss = 0.2247, Val Acc = 0.9170, Val F1 = 0.9152\n",
            "Epoch 8: TrainLoss = 0.1984, ValLoss = 0.2362, Val Acc = 0.8986, Val F1 = 0.8996\n",
            "Epoch 9: TrainLoss = 0.1904, ValLoss = 0.2310, Val Acc = 0.9051, Val F1 = 0.9014\n",
            "Epoch 10: TrainLoss = 0.1803, ValLoss = 0.2334, Val Acc = 0.9025, Val F1 = 0.9013\n",
            "Epoch 11: TrainLoss = 0.1735, ValLoss = 0.2429, Val Acc = 0.9012, Val F1 = 0.9035\n",
            "Epoch 12: TrainLoss = 0.1668, ValLoss = 0.2323, Val Acc = 0.9104, Val F1 = 0.9096\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 11/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3988, ValLoss = 0.2770, Val Acc = 0.8841, Val F1 = 0.8811\n",
            "Epoch 2: TrainLoss = 0.2715, ValLoss = 0.2542, Val Acc = 0.8893, Val F1 = 0.8898\n",
            "Epoch 3: TrainLoss = 0.2543, ValLoss = 0.2404, Val Acc = 0.8999, Val F1 = 0.9000\n",
            "Epoch 4: TrainLoss = 0.2374, ValLoss = 0.2381, Val Acc = 0.8972, Val F1 = 0.8979\n",
            "Epoch 5: TrainLoss = 0.2307, ValLoss = 0.2588, Val Acc = 0.8893, Val F1 = 0.8817\n",
            "Epoch 6: TrainLoss = 0.2210, ValLoss = 0.2537, Val Acc = 0.8946, Val F1 = 0.8987\n",
            "Epoch 7: TrainLoss = 0.2166, ValLoss = 0.2873, Val Acc = 0.8814, Val F1 = 0.8892\n",
            "Epoch 8: TrainLoss = 0.2031, ValLoss = 0.2353, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 9: TrainLoss = 0.2003, ValLoss = 0.2378, Val Acc = 0.9025, Val F1 = 0.8972\n",
            "Epoch 10: TrainLoss = 0.1923, ValLoss = 0.2303, Val Acc = 0.9078, Val F1 = 0.9084\n",
            "Epoch 11: TrainLoss = 0.1920, ValLoss = 0.2231, Val Acc = 0.9091, Val F1 = 0.9084\n",
            "Epoch 12: TrainLoss = 0.1772, ValLoss = 0.2343, Val Acc = 0.9012, Val F1 = 0.9012\n",
            "Epoch 13: TrainLoss = 0.1739, ValLoss = 0.2345, Val Acc = 0.8999, Val F1 = 0.9018\n",
            "Epoch 14: TrainLoss = 0.1693, ValLoss = 0.2860, Val Acc = 0.8841, Val F1 = 0.8914\n",
            "Epoch 15: TrainLoss = 0.1595, ValLoss = 0.2631, Val Acc = 0.8959, Val F1 = 0.9006\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 12/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4442, ValLoss = 0.3281, Val Acc = 0.8445, Val F1 = 0.8280\n",
            "Epoch 2: TrainLoss = 0.2858, ValLoss = 0.2663, Val Acc = 0.8946, Val F1 = 0.8913\n",
            "Epoch 3: TrainLoss = 0.2625, ValLoss = 0.2463, Val Acc = 0.8959, Val F1 = 0.8940\n",
            "Epoch 4: TrainLoss = 0.2471, ValLoss = 0.2764, Val Acc = 0.8814, Val F1 = 0.8878\n",
            "Epoch 5: TrainLoss = 0.2389, ValLoss = 0.2498, Val Acc = 0.8893, Val F1 = 0.8923\n",
            "Epoch 6: TrainLoss = 0.2283, ValLoss = 0.2436, Val Acc = 0.8986, Val F1 = 0.8996\n",
            "Epoch 7: TrainLoss = 0.2199, ValLoss = 0.2366, Val Acc = 0.8999, Val F1 = 0.9005\n",
            "Epoch 8: TrainLoss = 0.2141, ValLoss = 0.2310, Val Acc = 0.9038, Val F1 = 0.9033\n",
            "Epoch 9: TrainLoss = 0.2090, ValLoss = 0.2296, Val Acc = 0.8999, Val F1 = 0.8967\n",
            "Epoch 10: TrainLoss = 0.2056, ValLoss = 0.2353, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 11: TrainLoss = 0.2028, ValLoss = 0.2410, Val Acc = 0.8959, Val F1 = 0.8967\n",
            "Epoch 12: TrainLoss = 0.1933, ValLoss = 0.2376, Val Acc = 0.8999, Val F1 = 0.9005\n",
            "Epoch 13: TrainLoss = 0.1877, ValLoss = 0.2607, Val Acc = 0.8867, Val F1 = 0.8914\n",
            "Epoch 14: TrainLoss = 0.1814, ValLoss = 0.2471, Val Acc = 0.8880, Val F1 = 0.8914\n",
            "Epoch 15: TrainLoss = 0.1748, ValLoss = 0.2376, Val Acc = 0.9012, Val F1 = 0.8982\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 13/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3506, ValLoss = 0.2546, Val Acc = 0.8867, Val F1 = 0.8871\n",
            "Epoch 2: TrainLoss = 0.2712, ValLoss = 0.2432, Val Acc = 0.8986, Val F1 = 0.9009\n",
            "Epoch 3: TrainLoss = 0.2447, ValLoss = 0.2390, Val Acc = 0.9012, Val F1 = 0.9012\n",
            "Epoch 4: TrainLoss = 0.2286, ValLoss = 0.2314, Val Acc = 0.9038, Val F1 = 0.9053\n",
            "Epoch 5: TrainLoss = 0.2201, ValLoss = 0.2449, Val Acc = 0.9078, Val F1 = 0.9098\n",
            "Epoch 6: TrainLoss = 0.2105, ValLoss = 0.2974, Val Acc = 0.8775, Val F1 = 0.8856\n",
            "Epoch 7: TrainLoss = 0.1932, ValLoss = 0.2461, Val Acc = 0.9051, Val F1 = 0.9062\n",
            "Epoch 8: TrainLoss = 0.1818, ValLoss = 0.2318, Val Acc = 0.9078, Val F1 = 0.9064\n",
            "Epoch 9: TrainLoss = 0.1739, ValLoss = 0.2477, Val Acc = 0.8972, Val F1 = 0.8914\n",
            "Epoch 10: TrainLoss = 0.1568, ValLoss = 0.2663, Val Acc = 0.8999, Val F1 = 0.8956\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 14/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3598, ValLoss = 0.2716, Val Acc = 0.8801, Val F1 = 0.8788\n",
            "Epoch 2: TrainLoss = 0.2685, ValLoss = 0.2422, Val Acc = 0.8906, Val F1 = 0.8898\n",
            "Epoch 3: TrainLoss = 0.2464, ValLoss = 0.2540, Val Acc = 0.8867, Val F1 = 0.8785\n",
            "Epoch 4: TrainLoss = 0.2296, ValLoss = 0.2389, Val Acc = 0.9025, Val F1 = 0.9041\n",
            "Epoch 5: TrainLoss = 0.2216, ValLoss = 0.2246, Val Acc = 0.9091, Val F1 = 0.9084\n",
            "Epoch 6: TrainLoss = 0.2118, ValLoss = 0.2409, Val Acc = 0.9078, Val F1 = 0.9077\n",
            "Epoch 7: TrainLoss = 0.2000, ValLoss = 0.2365, Val Acc = 0.8972, Val F1 = 0.8971\n",
            "Epoch 8: TrainLoss = 0.1975, ValLoss = 0.2293, Val Acc = 0.9051, Val F1 = 0.9011\n",
            "Epoch 9: TrainLoss = 0.1806, ValLoss = 0.2358, Val Acc = 0.8959, Val F1 = 0.8973\n",
            "Epoch 10: TrainLoss = 0.1680, ValLoss = 0.2479, Val Acc = 0.9025, Val F1 = 0.9029\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 15/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3858, ValLoss = 0.2777, Val Acc = 0.8854, Val F1 = 0.8886\n",
            "Epoch 2: TrainLoss = 0.2713, ValLoss = 0.2515, Val Acc = 0.8986, Val F1 = 0.8950\n",
            "Epoch 3: TrainLoss = 0.2578, ValLoss = 0.2692, Val Acc = 0.8920, Val F1 = 0.8962\n",
            "Epoch 4: TrainLoss = 0.2397, ValLoss = 0.2350, Val Acc = 0.9051, Val F1 = 0.9022\n",
            "Epoch 5: TrainLoss = 0.2288, ValLoss = 0.2483, Val Acc = 0.8972, Val F1 = 0.9005\n",
            "Epoch 6: TrainLoss = 0.2160, ValLoss = 0.2318, Val Acc = 0.9025, Val F1 = 0.9029\n",
            "Epoch 7: TrainLoss = 0.2063, ValLoss = 0.2375, Val Acc = 0.9012, Val F1 = 0.8966\n",
            "Epoch 8: TrainLoss = 0.2030, ValLoss = 0.2311, Val Acc = 0.9051, Val F1 = 0.9024\n",
            "Epoch 9: TrainLoss = 0.1875, ValLoss = 0.2241, Val Acc = 0.9117, Val F1 = 0.9105\n",
            "Epoch 10: TrainLoss = 0.1809, ValLoss = 0.2594, Val Acc = 0.8906, Val F1 = 0.8964\n",
            "Epoch 11: TrainLoss = 0.1706, ValLoss = 0.2294, Val Acc = 0.9091, Val F1 = 0.9076\n",
            "Epoch 12: TrainLoss = 0.1663, ValLoss = 0.2475, Val Acc = 0.8959, Val F1 = 0.8973\n",
            "Epoch 13: TrainLoss = 0.1592, ValLoss = 0.2376, Val Acc = 0.9025, Val F1 = 0.8997\n",
            "Epoch 14: TrainLoss = 0.1436, ValLoss = 0.2529, Val Acc = 0.9051, Val F1 = 0.9014\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 16/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3409, ValLoss = 0.2648, Val Acc = 0.8946, Val F1 = 0.8969\n",
            "Epoch 2: TrainLoss = 0.2700, ValLoss = 0.2624, Val Acc = 0.8827, Val F1 = 0.8745\n",
            "Epoch 3: TrainLoss = 0.2488, ValLoss = 0.2484, Val Acc = 0.8933, Val F1 = 0.8963\n",
            "Epoch 4: TrainLoss = 0.2388, ValLoss = 0.2680, Val Acc = 0.8880, Val F1 = 0.8798\n",
            "Epoch 5: TrainLoss = 0.2271, ValLoss = 0.2932, Val Acc = 0.8854, Val F1 = 0.8925\n",
            "Epoch 6: TrainLoss = 0.2144, ValLoss = 0.2410, Val Acc = 0.9012, Val F1 = 0.8971\n",
            "Epoch 7: TrainLoss = 0.2016, ValLoss = 0.2407, Val Acc = 0.9025, Val F1 = 0.8966\n",
            "Epoch 8: TrainLoss = 0.1910, ValLoss = 0.2367, Val Acc = 0.9065, Val F1 = 0.9057\n",
            "Epoch 9: TrainLoss = 0.1767, ValLoss = 0.2237, Val Acc = 0.9051, Val F1 = 0.9032\n",
            "Epoch 10: TrainLoss = 0.1656, ValLoss = 0.2564, Val Acc = 0.8972, Val F1 = 0.8940\n",
            "Epoch 11: TrainLoss = 0.1590, ValLoss = 0.2490, Val Acc = 0.9025, Val F1 = 0.9051\n",
            "Epoch 12: TrainLoss = 0.1510, ValLoss = 0.2388, Val Acc = 0.9091, Val F1 = 0.9091\n",
            "Epoch 13: TrainLoss = 0.1406, ValLoss = 0.2704, Val Acc = 0.8959, Val F1 = 0.8996\n",
            "Epoch 14: TrainLoss = 0.1359, ValLoss = 0.2390, Val Acc = 0.9130, Val F1 = 0.9132\n",
            "Epoch 15: TrainLoss = 0.1213, ValLoss = 0.2497, Val Acc = 0.9078, Val F1 = 0.9051\n",
            "Epoch 16: TrainLoss = 0.1213, ValLoss = 0.2589, Val Acc = 0.9170, Val F1 = 0.9157\n",
            "Epoch 17: TrainLoss = 0.1086, ValLoss = 0.2881, Val Acc = 0.9038, Val F1 = 0.9077\n",
            "Epoch 18: TrainLoss = 0.1009, ValLoss = 0.2736, Val Acc = 0.9078, Val F1 = 0.9057\n",
            "Epoch 19: TrainLoss = 0.1012, ValLoss = 0.2758, Val Acc = 0.9038, Val F1 = 0.9017\n",
            "Epoch 20: TrainLoss = 0.0925, ValLoss = 0.3043, Val Acc = 0.9065, Val F1 = 0.9089\n",
            "Epoch 21: TrainLoss = 0.1004, ValLoss = 0.3417, Val Acc = 0.8999, Val F1 = 0.9048\n",
            "Early stopping at epoch 21\n",
            "\n",
            "Config 17/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3416, ValLoss = 0.2944, Val Acc = 0.8827, Val F1 = 0.8723\n",
            "Epoch 2: TrainLoss = 0.2774, ValLoss = 0.2370, Val Acc = 0.8999, Val F1 = 0.8981\n",
            "Epoch 3: TrainLoss = 0.2444, ValLoss = 0.2337, Val Acc = 0.8946, Val F1 = 0.8945\n",
            "Epoch 4: TrainLoss = 0.2298, ValLoss = 0.2443, Val Acc = 0.8972, Val F1 = 0.8949\n",
            "Epoch 5: TrainLoss = 0.2146, ValLoss = 0.2275, Val Acc = 0.9038, Val F1 = 0.9031\n",
            "Epoch 6: TrainLoss = 0.2072, ValLoss = 0.2430, Val Acc = 0.9038, Val F1 = 0.9063\n",
            "Epoch 7: TrainLoss = 0.2012, ValLoss = 0.2410, Val Acc = 0.9025, Val F1 = 0.8986\n",
            "Epoch 8: TrainLoss = 0.1827, ValLoss = 0.2471, Val Acc = 0.9065, Val F1 = 0.9004\n",
            "Epoch 9: TrainLoss = 0.1708, ValLoss = 0.2481, Val Acc = 0.9038, Val F1 = 0.9072\n",
            "Epoch 10: TrainLoss = 0.1584, ValLoss = 0.2592, Val Acc = 0.8986, Val F1 = 0.8996\n",
            "Epoch 11: TrainLoss = 0.1513, ValLoss = 0.2497, Val Acc = 0.9065, Val F1 = 0.9057\n",
            "Epoch 12: TrainLoss = 0.1352, ValLoss = 0.2409, Val Acc = 0.9078, Val F1 = 0.9079\n",
            "Epoch 13: TrainLoss = 0.1244, ValLoss = 0.2533, Val Acc = 0.9091, Val F1 = 0.9103\n",
            "Epoch 14: TrainLoss = 0.1138, ValLoss = 0.2612, Val Acc = 0.9012, Val F1 = 0.9025\n",
            "Epoch 15: TrainLoss = 0.1048, ValLoss = 0.2606, Val Acc = 0.9104, Val F1 = 0.9103\n",
            "Epoch 16: TrainLoss = 0.1010, ValLoss = 0.2810, Val Acc = 0.9051, Val F1 = 0.9043\n",
            "Epoch 17: TrainLoss = 0.1009, ValLoss = 0.2763, Val Acc = 0.9078, Val F1 = 0.9081\n",
            "Epoch 18: TrainLoss = 0.0838, ValLoss = 0.2818, Val Acc = 0.9038, Val F1 = 0.9036\n",
            "Epoch 19: TrainLoss = 0.0847, ValLoss = 0.2931, Val Acc = 0.9038, Val F1 = 0.9031\n",
            "Epoch 20: TrainLoss = 0.0787, ValLoss = 0.2964, Val Acc = 0.9038, Val F1 = 0.9063\n",
            "Early stopping at epoch 20\n",
            "\n",
            "Config 18/81: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3600, ValLoss = 0.2811, Val Acc = 0.8827, Val F1 = 0.8741\n",
            "Epoch 2: TrainLoss = 0.2735, ValLoss = 0.2411, Val Acc = 0.8972, Val F1 = 0.8940\n",
            "Epoch 3: TrainLoss = 0.2415, ValLoss = 0.2424, Val Acc = 0.8972, Val F1 = 0.8923\n",
            "Epoch 4: TrainLoss = 0.2288, ValLoss = 0.2323, Val Acc = 0.9051, Val F1 = 0.9014\n",
            "Epoch 5: TrainLoss = 0.2143, ValLoss = 0.2429, Val Acc = 0.9091, Val F1 = 0.9107\n",
            "Epoch 6: TrainLoss = 0.2043, ValLoss = 0.2838, Val Acc = 0.8788, Val F1 = 0.8861\n",
            "Epoch 7: TrainLoss = 0.1913, ValLoss = 0.2470, Val Acc = 0.9012, Val F1 = 0.9032\n",
            "Epoch 8: TrainLoss = 0.1884, ValLoss = 0.2269, Val Acc = 0.9065, Val F1 = 0.9069\n",
            "Epoch 9: TrainLoss = 0.1686, ValLoss = 0.2466, Val Acc = 0.8972, Val F1 = 0.8926\n",
            "Epoch 10: TrainLoss = 0.1617, ValLoss = 0.2396, Val Acc = 0.9065, Val F1 = 0.9065\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 19/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3770, ValLoss = 0.2791, Val Acc = 0.8827, Val F1 = 0.8855\n",
            "Epoch 2: TrainLoss = 0.2767, ValLoss = 0.2575, Val Acc = 0.8933, Val F1 = 0.8889\n",
            "Epoch 3: TrainLoss = 0.2609, ValLoss = 0.2564, Val Acc = 0.8959, Val F1 = 0.8994\n",
            "Epoch 4: TrainLoss = 0.2413, ValLoss = 0.2361, Val Acc = 0.8986, Val F1 = 0.8980\n",
            "Epoch 5: TrainLoss = 0.2374, ValLoss = 0.2678, Val Acc = 0.8841, Val F1 = 0.8911\n",
            "Epoch 6: TrainLoss = 0.2297, ValLoss = 0.2284, Val Acc = 0.9065, Val F1 = 0.9057\n",
            "Epoch 7: TrainLoss = 0.2199, ValLoss = 0.2434, Val Acc = 0.8946, Val F1 = 0.8974\n",
            "Epoch 8: TrainLoss = 0.2141, ValLoss = 0.2394, Val Acc = 0.8946, Val F1 = 0.8969\n",
            "Epoch 9: TrainLoss = 0.2083, ValLoss = 0.2236, Val Acc = 0.9065, Val F1 = 0.9042\n",
            "Epoch 10: TrainLoss = 0.2008, ValLoss = 0.2199, Val Acc = 0.9078, Val F1 = 0.9064\n",
            "Epoch 11: TrainLoss = 0.1927, ValLoss = 0.2253, Val Acc = 0.9038, Val F1 = 0.9020\n",
            "Epoch 12: TrainLoss = 0.1900, ValLoss = 0.2276, Val Acc = 0.9038, Val F1 = 0.9020\n",
            "Epoch 13: TrainLoss = 0.1818, ValLoss = 0.2229, Val Acc = 0.9104, Val F1 = 0.9091\n",
            "Epoch 14: TrainLoss = 0.1745, ValLoss = 0.2660, Val Acc = 0.8906, Val F1 = 0.8964\n",
            "Epoch 15: TrainLoss = 0.1749, ValLoss = 0.2392, Val Acc = 0.8999, Val F1 = 0.9018\n",
            "Epoch 16: TrainLoss = 0.1634, ValLoss = 0.2410, Val Acc = 0.9051, Val F1 = 0.9006\n",
            "Epoch 17: TrainLoss = 0.1637, ValLoss = 0.2415, Val Acc = 0.9012, Val F1 = 0.9032\n",
            "Epoch 18: TrainLoss = 0.1487, ValLoss = 0.2446, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Early stopping at epoch 18\n",
            "\n",
            "Config 20/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.4089, ValLoss = 0.2909, Val Acc = 0.8722, Val F1 = 0.8758\n",
            "Epoch 2: TrainLoss = 0.2848, ValLoss = 0.2554, Val Acc = 0.8933, Val F1 = 0.8921\n",
            "Epoch 3: TrainLoss = 0.2606, ValLoss = 0.2450, Val Acc = 0.8959, Val F1 = 0.8954\n",
            "Epoch 4: TrainLoss = 0.2541, ValLoss = 0.2408, Val Acc = 0.8999, Val F1 = 0.9013\n",
            "Epoch 5: TrainLoss = 0.2350, ValLoss = 0.2589, Val Acc = 0.8906, Val F1 = 0.8956\n",
            "Epoch 6: TrainLoss = 0.2319, ValLoss = 0.2355, Val Acc = 0.9078, Val F1 = 0.9081\n",
            "Epoch 7: TrainLoss = 0.2254, ValLoss = 0.2398, Val Acc = 0.8999, Val F1 = 0.9021\n",
            "Epoch 8: TrainLoss = 0.2166, ValLoss = 0.2450, Val Acc = 0.8986, Val F1 = 0.9009\n",
            "Epoch 9: TrainLoss = 0.2106, ValLoss = 0.2261, Val Acc = 0.9012, Val F1 = 0.8999\n",
            "Epoch 10: TrainLoss = 0.2037, ValLoss = 0.2283, Val Acc = 0.9065, Val F1 = 0.9067\n",
            "Epoch 11: TrainLoss = 0.2039, ValLoss = 0.2484, Val Acc = 0.9038, Val F1 = 0.8979\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 21/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4554, ValLoss = 0.3058, Val Acc = 0.8656, Val F1 = 0.8675\n",
            "Epoch 2: TrainLoss = 0.2969, ValLoss = 0.2649, Val Acc = 0.8906, Val F1 = 0.8921\n",
            "Epoch 3: TrainLoss = 0.2699, ValLoss = 0.2737, Val Acc = 0.8906, Val F1 = 0.8948\n",
            "Epoch 4: TrainLoss = 0.2512, ValLoss = 0.2793, Val Acc = 0.8748, Val F1 = 0.8808\n",
            "Epoch 5: TrainLoss = 0.2487, ValLoss = 0.2438, Val Acc = 0.8986, Val F1 = 0.8958\n",
            "Epoch 6: TrainLoss = 0.2380, ValLoss = 0.2390, Val Acc = 0.9038, Val F1 = 0.9031\n",
            "Epoch 7: TrainLoss = 0.2288, ValLoss = 0.2353, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 8: TrainLoss = 0.2265, ValLoss = 0.2476, Val Acc = 0.9025, Val F1 = 0.9054\n",
            "Epoch 9: TrainLoss = 0.2203, ValLoss = 0.2259, Val Acc = 0.9051, Val F1 = 0.9040\n",
            "Epoch 10: TrainLoss = 0.2186, ValLoss = 0.2273, Val Acc = 0.9051, Val F1 = 0.9048\n",
            "Epoch 11: TrainLoss = 0.2083, ValLoss = 0.2318, Val Acc = 0.9078, Val F1 = 0.9044\n",
            "Epoch 12: TrainLoss = 0.2079, ValLoss = 0.2247, Val Acc = 0.9078, Val F1 = 0.9072\n",
            "Epoch 13: TrainLoss = 0.2003, ValLoss = 0.2401, Val Acc = 0.8867, Val F1 = 0.8892\n",
            "Epoch 14: TrainLoss = 0.1987, ValLoss = 0.2259, Val Acc = 0.9078, Val F1 = 0.9069\n",
            "Epoch 15: TrainLoss = 0.1931, ValLoss = 0.2336, Val Acc = 0.9065, Val F1 = 0.9074\n",
            "Epoch 16: TrainLoss = 0.1887, ValLoss = 0.2276, Val Acc = 0.9051, Val F1 = 0.9048\n",
            "Epoch 17: TrainLoss = 0.1860, ValLoss = 0.2298, Val Acc = 0.9091, Val F1 = 0.9066\n",
            "Epoch 18: TrainLoss = 0.1822, ValLoss = 0.2383, Val Acc = 0.8972, Val F1 = 0.8992\n",
            "Epoch 19: TrainLoss = 0.1779, ValLoss = 0.2458, Val Acc = 0.8959, Val F1 = 0.8988\n",
            "Epoch 20: TrainLoss = 0.1731, ValLoss = 0.2510, Val Acc = 0.8986, Val F1 = 0.9006\n",
            "Early stopping at epoch 20\n",
            "\n",
            "Config 22/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3551, ValLoss = 0.2867, Val Acc = 0.8827, Val F1 = 0.8894\n",
            "Epoch 2: TrainLoss = 0.2782, ValLoss = 0.2543, Val Acc = 0.8972, Val F1 = 0.8987\n",
            "Epoch 3: TrainLoss = 0.2626, ValLoss = 0.2592, Val Acc = 0.8906, Val F1 = 0.8959\n",
            "Epoch 4: TrainLoss = 0.2454, ValLoss = 0.2464, Val Acc = 0.8999, Val F1 = 0.9010\n",
            "Epoch 5: TrainLoss = 0.2359, ValLoss = 0.2422, Val Acc = 0.8946, Val F1 = 0.8925\n",
            "Epoch 6: TrainLoss = 0.2283, ValLoss = 0.2249, Val Acc = 0.9065, Val F1 = 0.9055\n",
            "Epoch 7: TrainLoss = 0.2184, ValLoss = 0.2277, Val Acc = 0.9183, Val F1 = 0.9178\n",
            "Epoch 8: TrainLoss = 0.2130, ValLoss = 0.2373, Val Acc = 0.9065, Val F1 = 0.9086\n",
            "Epoch 9: TrainLoss = 0.1994, ValLoss = 0.2613, Val Acc = 0.8946, Val F1 = 0.9000\n",
            "Epoch 10: TrainLoss = 0.1905, ValLoss = 0.2279, Val Acc = 0.9104, Val F1 = 0.9068\n",
            "Epoch 11: TrainLoss = 0.1875, ValLoss = 0.2526, Val Acc = 0.9025, Val F1 = 0.9056\n",
            "Epoch 12: TrainLoss = 0.1828, ValLoss = 0.2416, Val Acc = 0.9025, Val F1 = 0.8975\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 23/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3696, ValLoss = 0.2817, Val Acc = 0.8841, Val F1 = 0.8764\n",
            "Epoch 2: TrainLoss = 0.2824, ValLoss = 0.2445, Val Acc = 0.8972, Val F1 = 0.8949\n",
            "Epoch 3: TrainLoss = 0.2562, ValLoss = 0.2690, Val Acc = 0.8893, Val F1 = 0.8947\n",
            "Epoch 4: TrainLoss = 0.2419, ValLoss = 0.2371, Val Acc = 0.8986, Val F1 = 0.8977\n",
            "Epoch 5: TrainLoss = 0.2409, ValLoss = 0.2334, Val Acc = 0.9051, Val F1 = 0.9048\n",
            "Epoch 6: TrainLoss = 0.2218, ValLoss = 0.2368, Val Acc = 0.8972, Val F1 = 0.8997\n",
            "Epoch 7: TrainLoss = 0.2240, ValLoss = 0.2310, Val Acc = 0.8986, Val F1 = 0.8972\n",
            "Epoch 8: TrainLoss = 0.2147, ValLoss = 0.2244, Val Acc = 0.9091, Val F1 = 0.9076\n",
            "Epoch 9: TrainLoss = 0.2010, ValLoss = 0.2351, Val Acc = 0.8999, Val F1 = 0.9010\n",
            "Epoch 10: TrainLoss = 0.1930, ValLoss = 0.2233, Val Acc = 0.9130, Val F1 = 0.9118\n",
            "Epoch 11: TrainLoss = 0.1861, ValLoss = 0.2374, Val Acc = 0.9130, Val F1 = 0.9115\n",
            "Epoch 12: TrainLoss = 0.1805, ValLoss = 0.2298, Val Acc = 0.9078, Val F1 = 0.9062\n",
            "Epoch 13: TrainLoss = 0.1768, ValLoss = 0.2578, Val Acc = 0.8946, Val F1 = 0.8867\n",
            "Epoch 14: TrainLoss = 0.1672, ValLoss = 0.2483, Val Acc = 0.9012, Val F1 = 0.9042\n",
            "Epoch 15: TrainLoss = 0.1592, ValLoss = 0.2413, Val Acc = 0.9091, Val F1 = 0.9061\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 24/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4020, ValLoss = 0.2719, Val Acc = 0.8893, Val F1 = 0.8880\n",
            "Epoch 2: TrainLoss = 0.2836, ValLoss = 0.2550, Val Acc = 0.8972, Val F1 = 0.8995\n",
            "Epoch 3: TrainLoss = 0.2607, ValLoss = 0.2339, Val Acc = 0.9012, Val F1 = 0.8999\n",
            "Epoch 4: TrainLoss = 0.2482, ValLoss = 0.2449, Val Acc = 0.8959, Val F1 = 0.8951\n",
            "Epoch 5: TrainLoss = 0.2343, ValLoss = 0.2516, Val Acc = 0.8999, Val F1 = 0.9038\n",
            "Epoch 6: TrainLoss = 0.2284, ValLoss = 0.2408, Val Acc = 0.9025, Val F1 = 0.9036\n",
            "Epoch 7: TrainLoss = 0.2190, ValLoss = 0.2316, Val Acc = 0.9038, Val F1 = 0.9009\n",
            "Epoch 8: TrainLoss = 0.2109, ValLoss = 0.2312, Val Acc = 0.9065, Val F1 = 0.9077\n",
            "Epoch 9: TrainLoss = 0.2108, ValLoss = 0.2448, Val Acc = 0.8986, Val F1 = 0.9024\n",
            "Epoch 10: TrainLoss = 0.2032, ValLoss = 0.2270, Val Acc = 0.9091, Val F1 = 0.9098\n",
            "Epoch 11: TrainLoss = 0.1943, ValLoss = 0.2280, Val Acc = 0.9117, Val F1 = 0.9120\n",
            "Epoch 12: TrainLoss = 0.1936, ValLoss = 0.2260, Val Acc = 0.9144, Val F1 = 0.9137\n",
            "Epoch 13: TrainLoss = 0.1856, ValLoss = 0.2304, Val Acc = 0.8999, Val F1 = 0.9000\n",
            "Epoch 14: TrainLoss = 0.1736, ValLoss = 0.2277, Val Acc = 0.9117, Val F1 = 0.9083\n",
            "Epoch 15: TrainLoss = 0.1668, ValLoss = 0.2547, Val Acc = 0.8946, Val F1 = 0.8982\n",
            "Epoch 16: TrainLoss = 0.1682, ValLoss = 0.2449, Val Acc = 0.8999, Val F1 = 0.9026\n",
            "Epoch 17: TrainLoss = 0.1583, ValLoss = 0.2308, Val Acc = 0.9078, Val F1 = 0.9079\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 25/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3594, ValLoss = 0.2730, Val Acc = 0.8880, Val F1 = 0.8837\n",
            "Epoch 2: TrainLoss = 0.2899, ValLoss = 0.2637, Val Acc = 0.8827, Val F1 = 0.8745\n",
            "Epoch 3: TrainLoss = 0.2751, ValLoss = 0.2383, Val Acc = 0.9012, Val F1 = 0.8971\n",
            "Epoch 4: TrainLoss = 0.2588, ValLoss = 0.2366, Val Acc = 0.8959, Val F1 = 0.8919\n",
            "Epoch 5: TrainLoss = 0.2463, ValLoss = 0.2314, Val Acc = 0.8972, Val F1 = 0.8952\n",
            "Epoch 6: TrainLoss = 0.2373, ValLoss = 0.2241, Val Acc = 0.9078, Val F1 = 0.9033\n",
            "Epoch 7: TrainLoss = 0.2299, ValLoss = 0.2238, Val Acc = 0.9078, Val F1 = 0.9064\n",
            "Epoch 8: TrainLoss = 0.2256, ValLoss = 0.2192, Val Acc = 0.9051, Val F1 = 0.9043\n",
            "Epoch 9: TrainLoss = 0.2089, ValLoss = 0.2274, Val Acc = 0.9038, Val F1 = 0.9046\n",
            "Epoch 10: TrainLoss = 0.2058, ValLoss = 0.2332, Val Acc = 0.9012, Val F1 = 0.8980\n",
            "Epoch 11: TrainLoss = 0.2035, ValLoss = 0.2331, Val Acc = 0.9104, Val F1 = 0.9103\n",
            "Epoch 12: TrainLoss = 0.1968, ValLoss = 0.2411, Val Acc = 0.9025, Val F1 = 0.9039\n",
            "Epoch 13: TrainLoss = 0.1891, ValLoss = 0.2822, Val Acc = 0.8880, Val F1 = 0.8944\n",
            "Epoch 14: TrainLoss = 0.1788, ValLoss = 0.2476, Val Acc = 0.9065, Val F1 = 0.9074\n",
            "Epoch 15: TrainLoss = 0.1842, ValLoss = 0.2307, Val Acc = 0.9104, Val F1 = 0.9112\n",
            "Epoch 16: TrainLoss = 0.1676, ValLoss = 0.2330, Val Acc = 0.9091, Val F1 = 0.9098\n",
            "Epoch 17: TrainLoss = 0.1595, ValLoss = 0.2443, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 18: TrainLoss = 0.1558, ValLoss = 0.2449, Val Acc = 0.9091, Val F1 = 0.9074\n",
            "Epoch 19: TrainLoss = 0.1501, ValLoss = 0.2451, Val Acc = 0.9051, Val F1 = 0.9043\n",
            "Epoch 20: TrainLoss = 0.1423, ValLoss = 0.2627, Val Acc = 0.9038, Val F1 = 0.9041\n",
            "Early stopping at epoch 20\n",
            "\n",
            "Config 26/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3708, ValLoss = 0.2629, Val Acc = 0.8854, Val F1 = 0.8860\n",
            "Epoch 2: TrainLoss = 0.2764, ValLoss = 0.2417, Val Acc = 0.8959, Val F1 = 0.8956\n",
            "Epoch 3: TrainLoss = 0.2634, ValLoss = 0.2760, Val Acc = 0.8841, Val F1 = 0.8903\n",
            "Epoch 4: TrainLoss = 0.2529, ValLoss = 0.2528, Val Acc = 0.8906, Val F1 = 0.8932\n",
            "Epoch 5: TrainLoss = 0.2373, ValLoss = 0.2348, Val Acc = 0.9038, Val F1 = 0.9007\n",
            "Epoch 6: TrainLoss = 0.2325, ValLoss = 0.2263, Val Acc = 0.9078, Val F1 = 0.9062\n",
            "Epoch 7: TrainLoss = 0.2203, ValLoss = 0.2264, Val Acc = 0.9091, Val F1 = 0.9089\n",
            "Epoch 8: TrainLoss = 0.2130, ValLoss = 0.2270, Val Acc = 0.9157, Val F1 = 0.9149\n",
            "Epoch 9: TrainLoss = 0.2063, ValLoss = 0.2676, Val Acc = 0.8906, Val F1 = 0.8951\n",
            "Epoch 10: TrainLoss = 0.1993, ValLoss = 0.2302, Val Acc = 0.9051, Val F1 = 0.9065\n",
            "Epoch 11: TrainLoss = 0.1904, ValLoss = 0.2551, Val Acc = 0.8959, Val F1 = 0.8970\n",
            "Epoch 12: TrainLoss = 0.1853, ValLoss = 0.2278, Val Acc = 0.9051, Val F1 = 0.9040\n",
            "Epoch 13: TrainLoss = 0.1796, ValLoss = 0.2378, Val Acc = 0.9038, Val F1 = 0.8979\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 27/81: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3728, ValLoss = 0.2657, Val Acc = 0.8841, Val F1 = 0.8851\n",
            "Epoch 2: TrainLoss = 0.2785, ValLoss = 0.2509, Val Acc = 0.9038, Val F1 = 0.9060\n",
            "Epoch 3: TrainLoss = 0.2562, ValLoss = 0.2360, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Epoch 4: TrainLoss = 0.2407, ValLoss = 0.2424, Val Acc = 0.9065, Val F1 = 0.9060\n",
            "Epoch 5: TrainLoss = 0.2375, ValLoss = 0.2309, Val Acc = 0.8986, Val F1 = 0.8944\n",
            "Epoch 6: TrainLoss = 0.2257, ValLoss = 0.2293, Val Acc = 0.9117, Val F1 = 0.9105\n",
            "Epoch 7: TrainLoss = 0.2145, ValLoss = 0.2355, Val Acc = 0.8986, Val F1 = 0.8999\n",
            "Epoch 8: TrainLoss = 0.2152, ValLoss = 0.2309, Val Acc = 0.9025, Val F1 = 0.8992\n",
            "Epoch 9: TrainLoss = 0.2035, ValLoss = 0.2225, Val Acc = 0.9117, Val F1 = 0.9086\n",
            "Epoch 10: TrainLoss = 0.1957, ValLoss = 0.2371, Val Acc = 0.8999, Val F1 = 0.8944\n",
            "Epoch 11: TrainLoss = 0.1849, ValLoss = 0.2312, Val Acc = 0.9130, Val F1 = 0.9122\n",
            "Epoch 12: TrainLoss = 0.1768, ValLoss = 0.2732, Val Acc = 0.8880, Val F1 = 0.8941\n",
            "Epoch 13: TrainLoss = 0.1634, ValLoss = 0.2384, Val Acc = 0.9078, Val F1 = 0.9074\n",
            "Epoch 14: TrainLoss = 0.1559, ValLoss = 0.2284, Val Acc = 0.9157, Val F1 = 0.9133\n",
            "Epoch 15: TrainLoss = 0.1516, ValLoss = 0.2409, Val Acc = 0.9038, Val F1 = 0.9036\n",
            "Epoch 16: TrainLoss = 0.1516, ValLoss = 0.2357, Val Acc = 0.9051, Val F1 = 0.9048\n",
            "Epoch 17: TrainLoss = 0.1389, ValLoss = 0.2589, Val Acc = 0.9025, Val F1 = 0.9044\n",
            "Epoch 18: TrainLoss = 0.1300, ValLoss = 0.3304, Val Acc = 0.8814, Val F1 = 0.8886\n",
            "Epoch 19: TrainLoss = 0.1339, ValLoss = 0.2445, Val Acc = 0.9078, Val F1 = 0.9059\n",
            "Early stopping at epoch 19\n",
            "\n",
            "Config 28/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3412, ValLoss = 0.2599, Val Acc = 0.8933, Val F1 = 0.8944\n",
            "Epoch 2: TrainLoss = 0.2628, ValLoss = 0.2478, Val Acc = 0.8986, Val F1 = 0.8980\n",
            "Epoch 3: TrainLoss = 0.2453, ValLoss = 0.2367, Val Acc = 0.8999, Val F1 = 0.8987\n",
            "Epoch 4: TrainLoss = 0.2296, ValLoss = 0.2574, Val Acc = 0.8972, Val F1 = 0.9018\n",
            "Epoch 5: TrainLoss = 0.2148, ValLoss = 0.2365, Val Acc = 0.8946, Val F1 = 0.8964\n",
            "Epoch 6: TrainLoss = 0.2088, ValLoss = 0.2298, Val Acc = 0.9025, Val F1 = 0.9019\n",
            "Epoch 7: TrainLoss = 0.1973, ValLoss = 0.2419, Val Acc = 0.8906, Val F1 = 0.8915\n",
            "Epoch 8: TrainLoss = 0.1817, ValLoss = 0.2501, Val Acc = 0.9065, Val F1 = 0.9082\n",
            "Epoch 9: TrainLoss = 0.1738, ValLoss = 0.2407, Val Acc = 0.9091, Val F1 = 0.9069\n",
            "Epoch 10: TrainLoss = 0.1631, ValLoss = 0.2999, Val Acc = 0.8814, Val F1 = 0.8881\n",
            "Epoch 11: TrainLoss = 0.1507, ValLoss = 0.2441, Val Acc = 0.9025, Val F1 = 0.9011\n",
            "Epoch 12: TrainLoss = 0.1343, ValLoss = 0.2884, Val Acc = 0.8920, Val F1 = 0.8927\n",
            "Epoch 13: TrainLoss = 0.1299, ValLoss = 0.2852, Val Acc = 0.9012, Val F1 = 0.9045\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 29/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3724, ValLoss = 0.2582, Val Acc = 0.8854, Val F1 = 0.8842\n",
            "Epoch 2: TrainLoss = 0.2657, ValLoss = 0.2534, Val Acc = 0.8972, Val F1 = 0.8976\n",
            "Epoch 3: TrainLoss = 0.2484, ValLoss = 0.2498, Val Acc = 0.8972, Val F1 = 0.8997\n",
            "Epoch 4: TrainLoss = 0.2391, ValLoss = 0.2357, Val Acc = 0.8999, Val F1 = 0.8965\n",
            "Epoch 5: TrainLoss = 0.2278, ValLoss = 0.2314, Val Acc = 0.9038, Val F1 = 0.9015\n",
            "Epoch 6: TrainLoss = 0.2119, ValLoss = 0.2397, Val Acc = 0.9065, Val F1 = 0.9074\n",
            "Epoch 7: TrainLoss = 0.2028, ValLoss = 0.2314, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 8: TrainLoss = 0.1948, ValLoss = 0.2298, Val Acc = 0.9170, Val F1 = 0.9143\n",
            "Epoch 9: TrainLoss = 0.1893, ValLoss = 0.2363, Val Acc = 0.8999, Val F1 = 0.9003\n",
            "Epoch 10: TrainLoss = 0.1807, ValLoss = 0.2342, Val Acc = 0.9038, Val F1 = 0.9043\n",
            "Epoch 11: TrainLoss = 0.1667, ValLoss = 0.2415, Val Acc = 0.8946, Val F1 = 0.8958\n",
            "Epoch 12: TrainLoss = 0.1595, ValLoss = 0.2452, Val Acc = 0.9025, Val F1 = 0.9008\n",
            "Epoch 13: TrainLoss = 0.1491, ValLoss = 0.2445, Val Acc = 0.9038, Val F1 = 0.9001\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 30/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3990, ValLoss = 0.2749, Val Acc = 0.8854, Val F1 = 0.8813\n",
            "Epoch 2: TrainLoss = 0.2702, ValLoss = 0.2574, Val Acc = 0.8946, Val F1 = 0.8901\n",
            "Epoch 3: TrainLoss = 0.2558, ValLoss = 0.2490, Val Acc = 0.8933, Val F1 = 0.8955\n",
            "Epoch 4: TrainLoss = 0.2352, ValLoss = 0.2460, Val Acc = 0.8999, Val F1 = 0.8995\n",
            "Epoch 5: TrainLoss = 0.2289, ValLoss = 0.2382, Val Acc = 0.9012, Val F1 = 0.9009\n",
            "Epoch 6: TrainLoss = 0.2173, ValLoss = 0.2304, Val Acc = 0.9051, Val F1 = 0.9053\n",
            "Epoch 7: TrainLoss = 0.2093, ValLoss = 0.2346, Val Acc = 0.9091, Val F1 = 0.9084\n",
            "Epoch 8: TrainLoss = 0.2071, ValLoss = 0.2293, Val Acc = 0.9038, Val F1 = 0.9028\n",
            "Epoch 9: TrainLoss = 0.2002, ValLoss = 0.2379, Val Acc = 0.9065, Val F1 = 0.9050\n",
            "Epoch 10: TrainLoss = 0.1929, ValLoss = 0.2324, Val Acc = 0.9117, Val F1 = 0.9086\n",
            "Epoch 11: TrainLoss = 0.1872, ValLoss = 0.2408, Val Acc = 0.9051, Val F1 = 0.9027\n",
            "Epoch 12: TrainLoss = 0.1817, ValLoss = 0.2364, Val Acc = 0.9025, Val F1 = 0.9019\n",
            "Epoch 13: TrainLoss = 0.1715, ValLoss = 0.2651, Val Acc = 0.8827, Val F1 = 0.8872\n",
            "Epoch 14: TrainLoss = 0.1660, ValLoss = 0.2516, Val Acc = 0.8946, Val F1 = 0.8947\n",
            "Epoch 15: TrainLoss = 0.1590, ValLoss = 0.2518, Val Acc = 0.9025, Val F1 = 0.9034\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 31/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3331, ValLoss = 0.2480, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 2: TrainLoss = 0.2593, ValLoss = 0.2325, Val Acc = 0.8999, Val F1 = 0.8965\n",
            "Epoch 3: TrainLoss = 0.2345, ValLoss = 0.2589, Val Acc = 0.8854, Val F1 = 0.8780\n",
            "Epoch 4: TrainLoss = 0.2208, ValLoss = 0.2754, Val Acc = 0.8867, Val F1 = 0.8938\n",
            "Epoch 5: TrainLoss = 0.2071, ValLoss = 0.2468, Val Acc = 0.8920, Val F1 = 0.8907\n",
            "Epoch 6: TrainLoss = 0.1891, ValLoss = 0.2369, Val Acc = 0.9104, Val F1 = 0.9079\n",
            "Epoch 7: TrainLoss = 0.1734, ValLoss = 0.2585, Val Acc = 0.8959, Val F1 = 0.8991\n",
            "Epoch 8: TrainLoss = 0.1556, ValLoss = 0.2741, Val Acc = 0.8946, Val F1 = 0.8969\n",
            "Epoch 9: TrainLoss = 0.1357, ValLoss = 0.2714, Val Acc = 0.9051, Val F1 = 0.9055\n",
            "Epoch 10: TrainLoss = 0.1228, ValLoss = 0.2829, Val Acc = 0.9012, Val F1 = 0.8977\n",
            "Epoch 11: TrainLoss = 0.1148, ValLoss = 0.3227, Val Acc = 0.8959, Val F1 = 0.8996\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 32/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3455, ValLoss = 0.2918, Val Acc = 0.8827, Val F1 = 0.8719\n",
            "Epoch 2: TrainLoss = 0.2609, ValLoss = 0.2480, Val Acc = 0.9012, Val F1 = 0.9030\n",
            "Epoch 3: TrainLoss = 0.2394, ValLoss = 0.2365, Val Acc = 0.8999, Val F1 = 0.8987\n",
            "Epoch 4: TrainLoss = 0.2199, ValLoss = 0.2292, Val Acc = 0.9038, Val F1 = 0.9007\n",
            "Epoch 5: TrainLoss = 0.2091, ValLoss = 0.2429, Val Acc = 0.8986, Val F1 = 0.8911\n",
            "Epoch 6: TrainLoss = 0.1954, ValLoss = 0.2386, Val Acc = 0.9117, Val F1 = 0.9083\n",
            "Epoch 7: TrainLoss = 0.1804, ValLoss = 0.2322, Val Acc = 0.9104, Val F1 = 0.9121\n",
            "Epoch 8: TrainLoss = 0.1698, ValLoss = 0.2387, Val Acc = 0.9051, Val F1 = 0.9053\n",
            "Epoch 9: TrainLoss = 0.1604, ValLoss = 0.2676, Val Acc = 0.8972, Val F1 = 0.9015\n",
            "Epoch 10: TrainLoss = 0.1360, ValLoss = 0.2847, Val Acc = 0.8986, Val F1 = 0.9029\n",
            "Epoch 11: TrainLoss = 0.1256, ValLoss = 0.3026, Val Acc = 0.8906, Val F1 = 0.8969\n",
            "Epoch 12: TrainLoss = 0.1177, ValLoss = 0.2641, Val Acc = 0.9038, Val F1 = 0.9048\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 33/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3540, ValLoss = 0.3038, Val Acc = 0.8735, Val F1 = 0.8812\n",
            "Epoch 2: TrainLoss = 0.2660, ValLoss = 0.2701, Val Acc = 0.8920, Val F1 = 0.8962\n",
            "Epoch 3: TrainLoss = 0.2477, ValLoss = 0.2485, Val Acc = 0.8933, Val F1 = 0.8960\n",
            "Epoch 4: TrainLoss = 0.2315, ValLoss = 0.2885, Val Acc = 0.8788, Val F1 = 0.8881\n",
            "Epoch 5: TrainLoss = 0.2178, ValLoss = 0.2259, Val Acc = 0.9078, Val F1 = 0.9062\n",
            "Epoch 6: TrainLoss = 0.2032, ValLoss = 0.2494, Val Acc = 0.8933, Val F1 = 0.8971\n",
            "Epoch 7: TrainLoss = 0.1981, ValLoss = 0.2300, Val Acc = 0.9051, Val F1 = 0.9037\n",
            "Epoch 8: TrainLoss = 0.1874, ValLoss = 0.2321, Val Acc = 0.9091, Val F1 = 0.9103\n",
            "Epoch 9: TrainLoss = 0.1726, ValLoss = 0.2499, Val Acc = 0.8986, Val F1 = 0.9006\n",
            "Epoch 10: TrainLoss = 0.1606, ValLoss = 0.2648, Val Acc = 0.8933, Val F1 = 0.8966\n",
            "Epoch 11: TrainLoss = 0.1494, ValLoss = 0.3061, Val Acc = 0.8867, Val F1 = 0.8933\n",
            "Epoch 12: TrainLoss = 0.1414, ValLoss = 0.2607, Val Acc = 0.9012, Val F1 = 0.9027\n",
            "Epoch 13: TrainLoss = 0.1377, ValLoss = 0.2973, Val Acc = 0.8946, Val F1 = 0.9010\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 34/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3300, ValLoss = 0.2592, Val Acc = 0.8854, Val F1 = 0.8793\n",
            "Epoch 2: TrainLoss = 0.2596, ValLoss = 0.2439, Val Acc = 0.8972, Val F1 = 0.8952\n",
            "Epoch 3: TrainLoss = 0.2414, ValLoss = 0.2413, Val Acc = 0.8999, Val F1 = 0.8959\n",
            "Epoch 4: TrainLoss = 0.2200, ValLoss = 0.2286, Val Acc = 0.9157, Val F1 = 0.9158\n",
            "Epoch 5: TrainLoss = 0.2081, ValLoss = 0.2453, Val Acc = 0.8986, Val F1 = 0.9014\n",
            "Epoch 6: TrainLoss = 0.1850, ValLoss = 0.2499, Val Acc = 0.8999, Val F1 = 0.9000\n",
            "Epoch 7: TrainLoss = 0.1674, ValLoss = 0.2721, Val Acc = 0.9078, Val F1 = 0.9044\n",
            "Epoch 8: TrainLoss = 0.1489, ValLoss = 0.2915, Val Acc = 0.8933, Val F1 = 0.8960\n",
            "Epoch 9: TrainLoss = 0.1386, ValLoss = 0.2722, Val Acc = 0.9025, Val F1 = 0.8975\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 35/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3471, ValLoss = 0.2793, Val Acc = 0.8867, Val F1 = 0.8922\n",
            "Epoch 2: TrainLoss = 0.2638, ValLoss = 0.2499, Val Acc = 0.9025, Val F1 = 0.9054\n",
            "Epoch 3: TrainLoss = 0.2332, ValLoss = 0.2433, Val Acc = 0.8933, Val F1 = 0.8960\n",
            "Epoch 4: TrainLoss = 0.2183, ValLoss = 0.2418, Val Acc = 0.8946, Val F1 = 0.8969\n",
            "Epoch 5: TrainLoss = 0.2059, ValLoss = 0.2678, Val Acc = 0.8906, Val F1 = 0.8912\n",
            "Epoch 6: TrainLoss = 0.1810, ValLoss = 0.2471, Val Acc = 0.8920, Val F1 = 0.8957\n",
            "Epoch 7: TrainLoss = 0.1650, ValLoss = 0.2589, Val Acc = 0.8999, Val F1 = 0.9031\n",
            "Early stopping at epoch 7\n",
            "\n",
            "Config 36/81: {'hidden_dim': 256, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3491, ValLoss = 0.2638, Val Acc = 0.8814, Val F1 = 0.8790\n",
            "Epoch 2: TrainLoss = 0.2547, ValLoss = 0.2457, Val Acc = 0.8959, Val F1 = 0.8916\n",
            "Epoch 3: TrainLoss = 0.2364, ValLoss = 0.2426, Val Acc = 0.8920, Val F1 = 0.8886\n",
            "Epoch 4: TrainLoss = 0.2223, ValLoss = 0.2355, Val Acc = 0.9012, Val F1 = 0.8993\n",
            "Epoch 5: TrainLoss = 0.1972, ValLoss = 0.2386, Val Acc = 0.9038, Val F1 = 0.9028\n",
            "Epoch 6: TrainLoss = 0.1969, ValLoss = 0.2481, Val Acc = 0.9117, Val F1 = 0.9142\n",
            "Epoch 7: TrainLoss = 0.1729, ValLoss = 0.2594, Val Acc = 0.9012, Val F1 = 0.9017\n",
            "Epoch 8: TrainLoss = 0.1612, ValLoss = 0.2650, Val Acc = 0.8933, Val F1 = 0.8848\n",
            "Epoch 9: TrainLoss = 0.1435, ValLoss = 0.2810, Val Acc = 0.8999, Val F1 = 0.9031\n",
            "Epoch 10: TrainLoss = 0.1252, ValLoss = 0.2707, Val Acc = 0.9091, Val F1 = 0.9096\n",
            "Epoch 11: TrainLoss = 0.1074, ValLoss = 0.2947, Val Acc = 0.9038, Val F1 = 0.9031\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 37/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3558, ValLoss = 0.2647, Val Acc = 0.8906, Val F1 = 0.8880\n",
            "Epoch 2: TrainLoss = 0.2682, ValLoss = 0.2442, Val Acc = 0.8920, Val F1 = 0.8910\n",
            "Epoch 3: TrainLoss = 0.2500, ValLoss = 0.2453, Val Acc = 0.9012, Val F1 = 0.9022\n",
            "Epoch 4: TrainLoss = 0.2396, ValLoss = 0.2727, Val Acc = 0.8867, Val F1 = 0.8928\n",
            "Epoch 5: TrainLoss = 0.2239, ValLoss = 0.2400, Val Acc = 0.9038, Val F1 = 0.9038\n",
            "Epoch 6: TrainLoss = 0.2167, ValLoss = 0.2771, Val Acc = 0.8893, Val F1 = 0.8953\n",
            "Epoch 7: TrainLoss = 0.2124, ValLoss = 0.2325, Val Acc = 0.8999, Val F1 = 0.9003\n",
            "Epoch 8: TrainLoss = 0.1990, ValLoss = 0.2672, Val Acc = 0.8801, Val F1 = 0.8691\n",
            "Epoch 9: TrainLoss = 0.1936, ValLoss = 0.2298, Val Acc = 0.9130, Val F1 = 0.9120\n",
            "Epoch 10: TrainLoss = 0.1822, ValLoss = 0.2518, Val Acc = 0.8906, Val F1 = 0.8839\n",
            "Epoch 11: TrainLoss = 0.1735, ValLoss = 0.2336, Val Acc = 0.9078, Val F1 = 0.9046\n",
            "Epoch 12: TrainLoss = 0.1681, ValLoss = 0.2408, Val Acc = 0.9038, Val F1 = 0.9009\n",
            "Epoch 13: TrainLoss = 0.1567, ValLoss = 0.2702, Val Acc = 0.8972, Val F1 = 0.9018\n",
            "Epoch 14: TrainLoss = 0.1424, ValLoss = 0.2488, Val Acc = 0.9038, Val F1 = 0.9017\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 38/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3805, ValLoss = 0.2631, Val Acc = 0.8893, Val F1 = 0.8877\n",
            "Epoch 2: TrainLoss = 0.2716, ValLoss = 0.2491, Val Acc = 0.9012, Val F1 = 0.8991\n",
            "Epoch 3: TrainLoss = 0.2527, ValLoss = 0.2478, Val Acc = 0.9025, Val F1 = 0.9039\n",
            "Epoch 4: TrainLoss = 0.2407, ValLoss = 0.2366, Val Acc = 0.9025, Val F1 = 0.9034\n",
            "Epoch 5: TrainLoss = 0.2259, ValLoss = 0.2290, Val Acc = 0.9091, Val F1 = 0.9066\n",
            "Epoch 6: TrainLoss = 0.2167, ValLoss = 0.2315, Val Acc = 0.8959, Val F1 = 0.8978\n",
            "Epoch 7: TrainLoss = 0.2127, ValLoss = 0.2269, Val Acc = 0.8999, Val F1 = 0.8987\n",
            "Epoch 8: TrainLoss = 0.2053, ValLoss = 0.2371, Val Acc = 0.8972, Val F1 = 0.8987\n",
            "Epoch 9: TrainLoss = 0.1968, ValLoss = 0.2270, Val Acc = 0.9183, Val F1 = 0.9173\n",
            "Epoch 10: TrainLoss = 0.1944, ValLoss = 0.2277, Val Acc = 0.9091, Val F1 = 0.9079\n",
            "Epoch 11: TrainLoss = 0.1836, ValLoss = 0.2330, Val Acc = 0.9012, Val F1 = 0.9009\n",
            "Epoch 12: TrainLoss = 0.1791, ValLoss = 0.2359, Val Acc = 0.9012, Val F1 = 0.9020\n",
            "Epoch 13: TrainLoss = 0.1693, ValLoss = 0.2386, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 14: TrainLoss = 0.1662, ValLoss = 0.2566, Val Acc = 0.9025, Val F1 = 0.9054\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 39/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4129, ValLoss = 0.2921, Val Acc = 0.8827, Val F1 = 0.8846\n",
            "Epoch 2: TrainLoss = 0.2761, ValLoss = 0.2584, Val Acc = 0.8959, Val F1 = 0.8934\n",
            "Epoch 3: TrainLoss = 0.2547, ValLoss = 0.2443, Val Acc = 0.8986, Val F1 = 0.8961\n",
            "Epoch 4: TrainLoss = 0.2427, ValLoss = 0.2383, Val Acc = 0.9117, Val F1 = 0.9117\n",
            "Epoch 5: TrainLoss = 0.2332, ValLoss = 0.2386, Val Acc = 0.9065, Val F1 = 0.9074\n",
            "Epoch 6: TrainLoss = 0.2254, ValLoss = 0.2425, Val Acc = 0.8986, Val F1 = 0.8991\n",
            "Epoch 7: TrainLoss = 0.2224, ValLoss = 0.2389, Val Acc = 0.8972, Val F1 = 0.8982\n",
            "Epoch 8: TrainLoss = 0.2202, ValLoss = 0.2477, Val Acc = 0.8933, Val F1 = 0.8960\n",
            "Epoch 9: TrainLoss = 0.2089, ValLoss = 0.2451, Val Acc = 0.8959, Val F1 = 0.8978\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 40/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3359, ValLoss = 0.2635, Val Acc = 0.8920, Val F1 = 0.8932\n",
            "Epoch 2: TrainLoss = 0.2698, ValLoss = 0.3368, Val Acc = 0.8577, Val F1 = 0.8373\n",
            "Epoch 3: TrainLoss = 0.2475, ValLoss = 0.2410, Val Acc = 0.8972, Val F1 = 0.8979\n",
            "Epoch 4: TrainLoss = 0.2350, ValLoss = 0.2334, Val Acc = 0.9104, Val F1 = 0.9105\n",
            "Epoch 5: TrainLoss = 0.2264, ValLoss = 0.2393, Val Acc = 0.8946, Val F1 = 0.8977\n",
            "Epoch 6: TrainLoss = 0.2071, ValLoss = 0.2685, Val Acc = 0.8946, Val F1 = 0.8966\n",
            "Epoch 7: TrainLoss = 0.1981, ValLoss = 0.2541, Val Acc = 0.8880, Val F1 = 0.8914\n",
            "Epoch 8: TrainLoss = 0.1860, ValLoss = 0.2303, Val Acc = 0.9104, Val F1 = 0.9091\n",
            "Epoch 9: TrainLoss = 0.1694, ValLoss = 0.2446, Val Acc = 0.9025, Val F1 = 0.9008\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 41/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3581, ValLoss = 0.2983, Val Acc = 0.8801, Val F1 = 0.8875\n",
            "Epoch 2: TrainLoss = 0.2653, ValLoss = 0.2652, Val Acc = 0.8854, Val F1 = 0.8769\n",
            "Epoch 3: TrainLoss = 0.2466, ValLoss = 0.2375, Val Acc = 0.8986, Val F1 = 0.8952\n",
            "Epoch 4: TrainLoss = 0.2331, ValLoss = 0.2451, Val Acc = 0.8972, Val F1 = 0.8990\n",
            "Epoch 5: TrainLoss = 0.2237, ValLoss = 0.2274, Val Acc = 0.9078, Val F1 = 0.9049\n",
            "Epoch 6: TrainLoss = 0.2153, ValLoss = 0.2270, Val Acc = 0.9091, Val F1 = 0.9100\n",
            "Epoch 7: TrainLoss = 0.2088, ValLoss = 0.2395, Val Acc = 0.8999, Val F1 = 0.8984\n",
            "Epoch 8: TrainLoss = 0.1909, ValLoss = 0.2366, Val Acc = 0.8986, Val F1 = 0.9001\n",
            "Epoch 9: TrainLoss = 0.1852, ValLoss = 0.2346, Val Acc = 0.9091, Val F1 = 0.9096\n",
            "Epoch 10: TrainLoss = 0.1702, ValLoss = 0.2380, Val Acc = 0.9012, Val F1 = 0.8999\n",
            "Epoch 11: TrainLoss = 0.1591, ValLoss = 0.2545, Val Acc = 0.9065, Val F1 = 0.9093\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 42/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3689, ValLoss = 0.2842, Val Acc = 0.8867, Val F1 = 0.8906\n",
            "Epoch 2: TrainLoss = 0.2642, ValLoss = 0.2734, Val Acc = 0.8946, Val F1 = 0.8985\n",
            "Epoch 3: TrainLoss = 0.2489, ValLoss = 0.2416, Val Acc = 0.8999, Val F1 = 0.8981\n",
            "Epoch 4: TrainLoss = 0.2359, ValLoss = 0.2355, Val Acc = 0.8986, Val F1 = 0.8955\n",
            "Epoch 5: TrainLoss = 0.2212, ValLoss = 0.2353, Val Acc = 0.9104, Val F1 = 0.9061\n",
            "Epoch 6: TrainLoss = 0.2125, ValLoss = 0.3164, Val Acc = 0.8643, Val F1 = 0.8456\n",
            "Epoch 7: TrainLoss = 0.2157, ValLoss = 0.2796, Val Acc = 0.8893, Val F1 = 0.8963\n",
            "Epoch 8: TrainLoss = 0.2021, ValLoss = 0.2361, Val Acc = 0.9078, Val F1 = 0.9046\n",
            "Epoch 9: TrainLoss = 0.1880, ValLoss = 0.2284, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 10: TrainLoss = 0.1807, ValLoss = 0.2387, Val Acc = 0.9078, Val F1 = 0.9038\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 43/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3443, ValLoss = 0.2538, Val Acc = 0.8959, Val F1 = 0.8916\n",
            "Epoch 2: TrainLoss = 0.2766, ValLoss = 0.2811, Val Acc = 0.8775, Val F1 = 0.8650\n",
            "Epoch 3: TrainLoss = 0.2529, ValLoss = 0.2457, Val Acc = 0.8906, Val F1 = 0.8895\n",
            "Epoch 4: TrainLoss = 0.2423, ValLoss = 0.2750, Val Acc = 0.8893, Val F1 = 0.8945\n",
            "Epoch 5: TrainLoss = 0.2270, ValLoss = 0.2340, Val Acc = 0.9025, Val F1 = 0.8981\n",
            "Epoch 6: TrainLoss = 0.2205, ValLoss = 0.2442, Val Acc = 0.9130, Val F1 = 0.9152\n",
            "Epoch 7: TrainLoss = 0.2062, ValLoss = 0.2434, Val Acc = 0.9038, Val F1 = 0.8976\n",
            "Epoch 8: TrainLoss = 0.1992, ValLoss = 0.2236, Val Acc = 0.9051, Val F1 = 0.9043\n",
            "Epoch 9: TrainLoss = 0.1847, ValLoss = 0.2647, Val Acc = 0.8933, Val F1 = 0.8973\n",
            "Epoch 10: TrainLoss = 0.1683, ValLoss = 0.2528, Val Acc = 0.9065, Val F1 = 0.9069\n",
            "Epoch 11: TrainLoss = 0.1600, ValLoss = 0.2543, Val Acc = 0.9012, Val F1 = 0.8982\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 44/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3408, ValLoss = 0.2598, Val Acc = 0.8841, Val F1 = 0.8866\n",
            "Epoch 2: TrainLoss = 0.2643, ValLoss = 0.2405, Val Acc = 0.8946, Val F1 = 0.8950\n",
            "Epoch 3: TrainLoss = 0.2443, ValLoss = 0.2612, Val Acc = 0.8972, Val F1 = 0.9010\n",
            "Epoch 4: TrainLoss = 0.2342, ValLoss = 0.2487, Val Acc = 0.8893, Val F1 = 0.8807\n",
            "Epoch 5: TrainLoss = 0.2217, ValLoss = 0.2337, Val Acc = 0.9078, Val F1 = 0.9074\n",
            "Epoch 6: TrainLoss = 0.2100, ValLoss = 0.2365, Val Acc = 0.9078, Val F1 = 0.9069\n",
            "Epoch 7: TrainLoss = 0.1970, ValLoss = 0.2454, Val Acc = 0.8999, Val F1 = 0.9021\n",
            "Epoch 8: TrainLoss = 0.1861, ValLoss = 0.2361, Val Acc = 0.9091, Val F1 = 0.9086\n",
            "Epoch 9: TrainLoss = 0.1745, ValLoss = 0.2789, Val Acc = 0.8906, Val F1 = 0.8937\n",
            "Epoch 10: TrainLoss = 0.1640, ValLoss = 0.2682, Val Acc = 0.8920, Val F1 = 0.8839\n",
            "Epoch 11: TrainLoss = 0.1472, ValLoss = 0.2479, Val Acc = 0.9025, Val F1 = 0.9031\n",
            "Epoch 12: TrainLoss = 0.1472, ValLoss = 0.2708, Val Acc = 0.8933, Val F1 = 0.8895\n",
            "Epoch 13: TrainLoss = 0.1318, ValLoss = 0.2734, Val Acc = 0.9038, Val F1 = 0.8988\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 45/81: {'hidden_dim': 256, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3443, ValLoss = 0.2615, Val Acc = 0.8920, Val F1 = 0.8880\n",
            "Epoch 2: TrainLoss = 0.2658, ValLoss = 0.2392, Val Acc = 0.8972, Val F1 = 0.8966\n",
            "Epoch 3: TrainLoss = 0.2379, ValLoss = 0.2336, Val Acc = 0.8999, Val F1 = 0.8987\n",
            "Epoch 4: TrainLoss = 0.2359, ValLoss = 0.3270, Val Acc = 0.8590, Val F1 = 0.8725\n",
            "Epoch 5: TrainLoss = 0.2224, ValLoss = 0.2431, Val Acc = 0.8999, Val F1 = 0.9028\n",
            "Epoch 6: TrainLoss = 0.2006, ValLoss = 0.2381, Val Acc = 0.9012, Val F1 = 0.9020\n",
            "Epoch 7: TrainLoss = 0.1918, ValLoss = 0.2769, Val Acc = 0.8788, Val F1 = 0.8850\n",
            "Epoch 8: TrainLoss = 0.1862, ValLoss = 0.2333, Val Acc = 0.9051, Val F1 = 0.9043\n",
            "Epoch 9: TrainLoss = 0.1753, ValLoss = 0.2264, Val Acc = 0.9157, Val F1 = 0.9158\n",
            "Epoch 10: TrainLoss = 0.1676, ValLoss = 0.2657, Val Acc = 0.8972, Val F1 = 0.8908\n",
            "Epoch 11: TrainLoss = 0.1575, ValLoss = 0.3037, Val Acc = 0.8867, Val F1 = 0.8914\n",
            "Epoch 12: TrainLoss = 0.1380, ValLoss = 0.2610, Val Acc = 0.9051, Val F1 = 0.9079\n",
            "Epoch 13: TrainLoss = 0.1291, ValLoss = 0.2664, Val Acc = 0.9051, Val F1 = 0.9062\n",
            "Epoch 14: TrainLoss = 0.1176, ValLoss = 0.2810, Val Acc = 0.9038, Val F1 = 0.9063\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 46/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3676, ValLoss = 0.2633, Val Acc = 0.8959, Val F1 = 0.8962\n",
            "Epoch 2: TrainLoss = 0.2773, ValLoss = 0.2754, Val Acc = 0.8867, Val F1 = 0.8903\n",
            "Epoch 3: TrainLoss = 0.2613, ValLoss = 0.2505, Val Acc = 0.8959, Val F1 = 0.8988\n",
            "Epoch 4: TrainLoss = 0.2458, ValLoss = 0.2810, Val Acc = 0.8788, Val F1 = 0.8873\n",
            "Epoch 5: TrainLoss = 0.2435, ValLoss = 0.2650, Val Acc = 0.8841, Val F1 = 0.8897\n",
            "Epoch 6: TrainLoss = 0.2275, ValLoss = 0.2331, Val Acc = 0.9051, Val F1 = 0.9062\n",
            "Epoch 7: TrainLoss = 0.2224, ValLoss = 0.2285, Val Acc = 0.9012, Val F1 = 0.9014\n",
            "Epoch 8: TrainLoss = 0.2136, ValLoss = 0.2482, Val Acc = 0.8880, Val F1 = 0.8923\n",
            "Epoch 9: TrainLoss = 0.2068, ValLoss = 0.2357, Val Acc = 0.9051, Val F1 = 0.9075\n",
            "Epoch 10: TrainLoss = 0.1994, ValLoss = 0.2728, Val Acc = 0.8827, Val F1 = 0.8894\n",
            "Epoch 11: TrainLoss = 0.1962, ValLoss = 0.2513, Val Acc = 0.8933, Val F1 = 0.8968\n",
            "Epoch 12: TrainLoss = 0.1870, ValLoss = 0.2361, Val Acc = 0.9051, Val F1 = 0.9075\n",
            "Epoch 13: TrainLoss = 0.1793, ValLoss = 0.2288, Val Acc = 0.9130, Val F1 = 0.9132\n",
            "Epoch 14: TrainLoss = 0.1764, ValLoss = 0.2681, Val Acc = 0.8867, Val F1 = 0.8925\n",
            "Epoch 15: TrainLoss = 0.1710, ValLoss = 0.2587, Val Acc = 0.8933, Val F1 = 0.8966\n",
            "Epoch 16: TrainLoss = 0.1621, ValLoss = 0.2496, Val Acc = 0.9012, Val F1 = 0.9020\n",
            "Epoch 17: TrainLoss = 0.1566, ValLoss = 0.2678, Val Acc = 0.8827, Val F1 = 0.8872\n",
            "Epoch 18: TrainLoss = 0.1486, ValLoss = 0.2501, Val Acc = 0.8920, Val F1 = 0.8930\n",
            "Early stopping at epoch 18\n",
            "\n",
            "Config 47/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3808, ValLoss = 0.2718, Val Acc = 0.8841, Val F1 = 0.8801\n",
            "Epoch 2: TrainLoss = 0.2788, ValLoss = 0.2555, Val Acc = 0.9012, Val F1 = 0.9030\n",
            "Epoch 3: TrainLoss = 0.2647, ValLoss = 0.2481, Val Acc = 0.8933, Val F1 = 0.8898\n",
            "Epoch 4: TrainLoss = 0.2463, ValLoss = 0.2406, Val Acc = 0.9051, Val F1 = 0.9022\n",
            "Epoch 5: TrainLoss = 0.2394, ValLoss = 0.2403, Val Acc = 0.9038, Val F1 = 0.9036\n",
            "Epoch 6: TrainLoss = 0.2295, ValLoss = 0.2333, Val Acc = 0.9065, Val F1 = 0.9037\n",
            "Epoch 7: TrainLoss = 0.2271, ValLoss = 0.2615, Val Acc = 0.8920, Val F1 = 0.8962\n",
            "Epoch 8: TrainLoss = 0.2158, ValLoss = 0.2352, Val Acc = 0.9025, Val F1 = 0.8995\n",
            "Epoch 9: TrainLoss = 0.2113, ValLoss = 0.2475, Val Acc = 0.8959, Val F1 = 0.8889\n",
            "Epoch 10: TrainLoss = 0.2115, ValLoss = 0.2316, Val Acc = 0.9025, Val F1 = 0.9029\n",
            "Epoch 11: TrainLoss = 0.2010, ValLoss = 0.2223, Val Acc = 0.9078, Val F1 = 0.9057\n",
            "Epoch 12: TrainLoss = 0.1966, ValLoss = 0.2246, Val Acc = 0.9130, Val F1 = 0.9103\n",
            "Epoch 13: TrainLoss = 0.1932, ValLoss = 0.2771, Val Acc = 0.8841, Val F1 = 0.8911\n",
            "Epoch 14: TrainLoss = 0.1849, ValLoss = 0.2558, Val Acc = 0.8906, Val F1 = 0.8823\n",
            "Epoch 15: TrainLoss = 0.1825, ValLoss = 0.2348, Val Acc = 0.8999, Val F1 = 0.9021\n",
            "Epoch 16: TrainLoss = 0.1746, ValLoss = 0.2443, Val Acc = 0.8986, Val F1 = 0.9014\n",
            "Epoch 17: TrainLoss = 0.1715, ValLoss = 0.2408, Val Acc = 0.9012, Val F1 = 0.9017\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 48/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4251, ValLoss = 0.3003, Val Acc = 0.8775, Val F1 = 0.8812\n",
            "Epoch 2: TrainLoss = 0.2861, ValLoss = 0.2614, Val Acc = 0.8906, Val F1 = 0.8918\n",
            "Epoch 3: TrainLoss = 0.2650, ValLoss = 0.2993, Val Acc = 0.8762, Val F1 = 0.8840\n",
            "Epoch 4: TrainLoss = 0.2507, ValLoss = 0.2419, Val Acc = 0.8999, Val F1 = 0.8978\n",
            "Epoch 5: TrainLoss = 0.2417, ValLoss = 0.2404, Val Acc = 0.8959, Val F1 = 0.8942\n",
            "Epoch 6: TrainLoss = 0.2340, ValLoss = 0.2415, Val Acc = 0.8999, Val F1 = 0.8953\n",
            "Epoch 7: TrainLoss = 0.2262, ValLoss = 0.2493, Val Acc = 0.8972, Val F1 = 0.9000\n",
            "Epoch 8: TrainLoss = 0.2230, ValLoss = 0.2301, Val Acc = 0.9025, Val F1 = 0.9008\n",
            "Epoch 9: TrainLoss = 0.2170, ValLoss = 0.2295, Val Acc = 0.8999, Val F1 = 0.8992\n",
            "Epoch 10: TrainLoss = 0.2158, ValLoss = 0.2590, Val Acc = 0.8933, Val F1 = 0.8973\n",
            "Epoch 11: TrainLoss = 0.2099, ValLoss = 0.2426, Val Acc = 0.8986, Val F1 = 0.8996\n",
            "Epoch 12: TrainLoss = 0.2058, ValLoss = 0.2513, Val Acc = 0.8893, Val F1 = 0.8920\n",
            "Epoch 13: TrainLoss = 0.2009, ValLoss = 0.2452, Val Acc = 0.8880, Val F1 = 0.8914\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 49/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3542, ValLoss = 0.2882, Val Acc = 0.8775, Val F1 = 0.8836\n",
            "Epoch 2: TrainLoss = 0.2811, ValLoss = 0.2483, Val Acc = 0.8986, Val F1 = 0.8958\n",
            "Epoch 3: TrainLoss = 0.2608, ValLoss = 0.2515, Val Acc = 0.8906, Val F1 = 0.8940\n",
            "Epoch 4: TrainLoss = 0.2487, ValLoss = 0.2294, Val Acc = 0.9065, Val F1 = 0.9037\n",
            "Epoch 5: TrainLoss = 0.2391, ValLoss = 0.2228, Val Acc = 0.9065, Val F1 = 0.9060\n",
            "Epoch 6: TrainLoss = 0.2274, ValLoss = 0.2260, Val Acc = 0.9051, Val F1 = 0.9055\n",
            "Epoch 7: TrainLoss = 0.2218, ValLoss = 0.2603, Val Acc = 0.9012, Val F1 = 0.8954\n",
            "Epoch 8: TrainLoss = 0.2138, ValLoss = 0.2260, Val Acc = 0.9117, Val F1 = 0.9115\n",
            "Epoch 9: TrainLoss = 0.2069, ValLoss = 0.2665, Val Acc = 0.8893, Val F1 = 0.8814\n",
            "Epoch 10: TrainLoss = 0.1956, ValLoss = 0.2238, Val Acc = 0.9104, Val F1 = 0.9096\n",
            "Epoch 11: TrainLoss = 0.1867, ValLoss = 0.2251, Val Acc = 0.9078, Val F1 = 0.9077\n",
            "Epoch 12: TrainLoss = 0.1816, ValLoss = 0.2430, Val Acc = 0.9038, Val F1 = 0.9051\n",
            "Epoch 13: TrainLoss = 0.1708, ValLoss = 0.2309, Val Acc = 0.9038, Val F1 = 0.9053\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 50/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3592, ValLoss = 0.2658, Val Acc = 0.8867, Val F1 = 0.8865\n",
            "Epoch 2: TrainLoss = 0.2749, ValLoss = 0.2465, Val Acc = 0.8893, Val F1 = 0.8865\n",
            "Epoch 3: TrainLoss = 0.2601, ValLoss = 0.2462, Val Acc = 0.9038, Val F1 = 0.9063\n",
            "Epoch 4: TrainLoss = 0.2450, ValLoss = 0.2477, Val Acc = 0.8933, Val F1 = 0.8963\n",
            "Epoch 5: TrainLoss = 0.2337, ValLoss = 0.2369, Val Acc = 0.9104, Val F1 = 0.9115\n",
            "Epoch 6: TrainLoss = 0.2267, ValLoss = 0.2330, Val Acc = 0.9038, Val F1 = 0.9007\n",
            "Epoch 7: TrainLoss = 0.2149, ValLoss = 0.2278, Val Acc = 0.9051, Val F1 = 0.9053\n",
            "Epoch 8: TrainLoss = 0.2132, ValLoss = 0.2297, Val Acc = 0.9091, Val F1 = 0.9079\n",
            "Epoch 9: TrainLoss = 0.2041, ValLoss = 0.2446, Val Acc = 0.9038, Val F1 = 0.8985\n",
            "Epoch 10: TrainLoss = 0.1911, ValLoss = 0.2482, Val Acc = 0.9012, Val F1 = 0.9022\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 51/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3861, ValLoss = 0.2746, Val Acc = 0.8827, Val F1 = 0.8855\n",
            "Epoch 2: TrainLoss = 0.2769, ValLoss = 0.2559, Val Acc = 0.8946, Val F1 = 0.8898\n",
            "Epoch 3: TrainLoss = 0.2593, ValLoss = 0.2426, Val Acc = 0.9051, Val F1 = 0.9040\n",
            "Epoch 4: TrainLoss = 0.2543, ValLoss = 0.2355, Val Acc = 0.8999, Val F1 = 0.8997\n",
            "Epoch 5: TrainLoss = 0.2396, ValLoss = 0.2738, Val Acc = 0.8841, Val F1 = 0.8908\n",
            "Epoch 6: TrainLoss = 0.2268, ValLoss = 0.2430, Val Acc = 0.9038, Val F1 = 0.9056\n",
            "Epoch 7: TrainLoss = 0.2185, ValLoss = 0.2334, Val Acc = 0.9038, Val F1 = 0.9043\n",
            "Epoch 8: TrainLoss = 0.2138, ValLoss = 0.2346, Val Acc = 0.9038, Val F1 = 0.9017\n",
            "Epoch 9: TrainLoss = 0.2107, ValLoss = 0.2508, Val Acc = 0.8880, Val F1 = 0.8920\n",
            "Epoch 10: TrainLoss = 0.2048, ValLoss = 0.2291, Val Acc = 0.9130, Val F1 = 0.9113\n",
            "Epoch 11: TrainLoss = 0.1943, ValLoss = 0.2295, Val Acc = 0.9025, Val F1 = 0.9026\n",
            "Epoch 12: TrainLoss = 0.1884, ValLoss = 0.2307, Val Acc = 0.8986, Val F1 = 0.9001\n",
            "Epoch 13: TrainLoss = 0.1785, ValLoss = 0.2576, Val Acc = 0.8986, Val F1 = 0.8923\n",
            "Epoch 14: TrainLoss = 0.1769, ValLoss = 0.2372, Val Acc = 0.9091, Val F1 = 0.9069\n",
            "Epoch 15: TrainLoss = 0.1679, ValLoss = 0.2359, Val Acc = 0.9025, Val F1 = 0.9021\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 52/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3522, ValLoss = 0.2573, Val Acc = 0.8906, Val F1 = 0.8883\n",
            "Epoch 2: TrainLoss = 0.2976, ValLoss = 0.2931, Val Acc = 0.8801, Val F1 = 0.8875\n",
            "Epoch 3: TrainLoss = 0.2787, ValLoss = 0.2347, Val Acc = 0.9065, Val F1 = 0.9057\n",
            "Epoch 4: TrainLoss = 0.2754, ValLoss = 0.2379, Val Acc = 0.9038, Val F1 = 0.9004\n",
            "Epoch 5: TrainLoss = 0.2572, ValLoss = 0.2565, Val Acc = 0.8933, Val F1 = 0.8976\n",
            "Epoch 6: TrainLoss = 0.2490, ValLoss = 0.2990, Val Acc = 0.8775, Val F1 = 0.8856\n",
            "Epoch 7: TrainLoss = 0.2368, ValLoss = 0.2394, Val Acc = 0.8972, Val F1 = 0.8946\n",
            "Epoch 8: TrainLoss = 0.2225, ValLoss = 0.2233, Val Acc = 0.9012, Val F1 = 0.8991\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 53/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3514, ValLoss = 0.3126, Val Acc = 0.8511, Val F1 = 0.8603\n",
            "Epoch 2: TrainLoss = 0.2785, ValLoss = 0.2464, Val Acc = 0.8920, Val F1 = 0.8874\n",
            "Epoch 3: TrainLoss = 0.2681, ValLoss = 0.2505, Val Acc = 0.8906, Val F1 = 0.8929\n",
            "Epoch 4: TrainLoss = 0.2596, ValLoss = 0.2501, Val Acc = 0.8999, Val F1 = 0.9036\n",
            "Epoch 5: TrainLoss = 0.2401, ValLoss = 0.2250, Val Acc = 0.9051, Val F1 = 0.9037\n",
            "Epoch 6: TrainLoss = 0.2286, ValLoss = 0.2423, Val Acc = 0.8959, Val F1 = 0.8973\n",
            "Epoch 7: TrainLoss = 0.2238, ValLoss = 0.2638, Val Acc = 0.8893, Val F1 = 0.8800\n",
            "Epoch 8: TrainLoss = 0.2136, ValLoss = 0.2437, Val Acc = 0.8986, Val F1 = 0.8969\n",
            "Epoch 9: TrainLoss = 0.2040, ValLoss = 0.2408, Val Acc = 0.9038, Val F1 = 0.9020\n",
            "Epoch 10: TrainLoss = 0.2061, ValLoss = 0.2302, Val Acc = 0.9065, Val F1 = 0.9047\n",
            "Epoch 11: TrainLoss = 0.1900, ValLoss = 0.2251, Val Acc = 0.9104, Val F1 = 0.9098\n",
            "Epoch 12: TrainLoss = 0.1807, ValLoss = 0.2735, Val Acc = 0.8933, Val F1 = 0.8968\n",
            "Epoch 13: TrainLoss = 0.1861, ValLoss = 0.2550, Val Acc = 0.9025, Val F1 = 0.9054\n",
            "Epoch 14: TrainLoss = 0.1754, ValLoss = 0.2527, Val Acc = 0.9051, Val F1 = 0.9079\n",
            "Epoch 15: TrainLoss = 0.1678, ValLoss = 0.2283, Val Acc = 0.9170, Val F1 = 0.9147\n",
            "Epoch 16: TrainLoss = 0.1581, ValLoss = 0.2496, Val Acc = 0.9065, Val F1 = 0.9082\n",
            "Epoch 17: TrainLoss = 0.1446, ValLoss = 0.2666, Val Acc = 0.9065, Val F1 = 0.9021\n",
            "Epoch 18: TrainLoss = 0.1518, ValLoss = 0.2972, Val Acc = 0.8854, Val F1 = 0.8903\n",
            "Epoch 19: TrainLoss = 0.1449, ValLoss = 0.2614, Val Acc = 0.9104, Val F1 = 0.9061\n",
            "Epoch 20: TrainLoss = 0.1270, ValLoss = 0.2468, Val Acc = 0.9091, Val F1 = 0.9089\n",
            "Early stopping at epoch 20\n",
            "\n",
            "Config 54/81: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3633, ValLoss = 0.2669, Val Acc = 0.8893, Val F1 = 0.8898\n",
            "Epoch 2: TrainLoss = 0.2771, ValLoss = 0.2514, Val Acc = 0.8959, Val F1 = 0.8954\n",
            "Epoch 3: TrainLoss = 0.2553, ValLoss = 0.2414, Val Acc = 0.9012, Val F1 = 0.8977\n",
            "Epoch 4: TrainLoss = 0.2490, ValLoss = 0.2419, Val Acc = 0.8933, Val F1 = 0.8936\n",
            "Epoch 5: TrainLoss = 0.2469, ValLoss = 0.2386, Val Acc = 0.8933, Val F1 = 0.8949\n",
            "Epoch 6: TrainLoss = 0.2194, ValLoss = 0.2384, Val Acc = 0.8959, Val F1 = 0.8962\n",
            "Epoch 7: TrainLoss = 0.2142, ValLoss = 0.2332, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Epoch 8: TrainLoss = 0.2051, ValLoss = 0.2403, Val Acc = 0.8959, Val F1 = 0.8922\n",
            "Epoch 9: TrainLoss = 0.2059, ValLoss = 0.2613, Val Acc = 0.8880, Val F1 = 0.8934\n",
            "Epoch 10: TrainLoss = 0.1981, ValLoss = 0.2351, Val Acc = 0.9012, Val F1 = 0.9014\n",
            "Epoch 11: TrainLoss = 0.1867, ValLoss = 0.2475, Val Acc = 0.9051, Val F1 = 0.9027\n",
            "Epoch 12: TrainLoss = 0.1765, ValLoss = 0.2298, Val Acc = 0.9078, Val F1 = 0.9074\n",
            "Epoch 13: TrainLoss = 0.1726, ValLoss = 0.2709, Val Acc = 0.8959, Val F1 = 0.9001\n",
            "Epoch 14: TrainLoss = 0.1610, ValLoss = 0.2509, Val Acc = 0.9025, Val F1 = 0.9036\n",
            "Epoch 15: TrainLoss = 0.1539, ValLoss = 0.2719, Val Acc = 0.8933, Val F1 = 0.8963\n",
            "Epoch 16: TrainLoss = 0.1506, ValLoss = 0.2576, Val Acc = 0.8972, Val F1 = 0.8976\n",
            "Epoch 17: TrainLoss = 0.1463, ValLoss = 0.2476, Val Acc = 0.8999, Val F1 = 0.9005\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 55/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3456, ValLoss = 0.2931, Val Acc = 0.8735, Val F1 = 0.8621\n",
            "Epoch 2: TrainLoss = 0.2638, ValLoss = 0.2992, Val Acc = 0.8656, Val F1 = 0.8491\n",
            "Epoch 3: TrainLoss = 0.2469, ValLoss = 0.2331, Val Acc = 0.9051, Val F1 = 0.9019\n",
            "Epoch 4: TrainLoss = 0.2339, ValLoss = 0.2462, Val Acc = 0.8933, Val F1 = 0.8971\n",
            "Epoch 5: TrainLoss = 0.2187, ValLoss = 0.2235, Val Acc = 0.9170, Val F1 = 0.9150\n",
            "Epoch 6: TrainLoss = 0.2036, ValLoss = 0.2363, Val Acc = 0.9065, Val F1 = 0.9055\n",
            "Epoch 7: TrainLoss = 0.1905, ValLoss = 0.2437, Val Acc = 0.9065, Val F1 = 0.9062\n",
            "Epoch 8: TrainLoss = 0.1790, ValLoss = 0.2772, Val Acc = 0.8827, Val F1 = 0.8866\n",
            "Epoch 9: TrainLoss = 0.1675, ValLoss = 0.2489, Val Acc = 0.8972, Val F1 = 0.8940\n",
            "Epoch 10: TrainLoss = 0.1557, ValLoss = 0.2505, Val Acc = 0.9025, Val F1 = 0.9024\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 56/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3565, ValLoss = 0.2562, Val Acc = 0.8946, Val F1 = 0.8933\n",
            "Epoch 2: TrainLoss = 0.2658, ValLoss = 0.2529, Val Acc = 0.8946, Val F1 = 0.8895\n",
            "Epoch 3: TrainLoss = 0.2463, ValLoss = 0.2419, Val Acc = 0.9078, Val F1 = 0.9086\n",
            "Epoch 4: TrainLoss = 0.2308, ValLoss = 0.2327, Val Acc = 0.9025, Val F1 = 0.9019\n",
            "Epoch 5: TrainLoss = 0.2278, ValLoss = 0.2233, Val Acc = 0.9078, Val F1 = 0.9072\n",
            "Epoch 6: TrainLoss = 0.2137, ValLoss = 0.2389, Val Acc = 0.9078, Val F1 = 0.9091\n",
            "Epoch 7: TrainLoss = 0.2087, ValLoss = 0.2281, Val Acc = 0.9144, Val F1 = 0.9139\n",
            "Epoch 8: TrainLoss = 0.1931, ValLoss = 0.2483, Val Acc = 0.8959, Val F1 = 0.8901\n",
            "Epoch 9: TrainLoss = 0.1848, ValLoss = 0.2388, Val Acc = 0.9091, Val F1 = 0.9053\n",
            "Epoch 10: TrainLoss = 0.1771, ValLoss = 0.2428, Val Acc = 0.9051, Val F1 = 0.9032\n",
            "Epoch 11: TrainLoss = 0.1664, ValLoss = 0.2419, Val Acc = 0.9038, Val F1 = 0.9004\n",
            "Epoch 12: TrainLoss = 0.1546, ValLoss = 0.2642, Val Acc = 0.9065, Val F1 = 0.9042\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 57/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3807, ValLoss = 0.2894, Val Acc = 0.8841, Val F1 = 0.8894\n",
            "Epoch 2: TrainLoss = 0.2721, ValLoss = 0.2591, Val Acc = 0.8933, Val F1 = 0.8947\n",
            "Epoch 3: TrainLoss = 0.2523, ValLoss = 0.2623, Val Acc = 0.8880, Val F1 = 0.8931\n",
            "Epoch 4: TrainLoss = 0.2339, ValLoss = 0.2474, Val Acc = 0.8972, Val F1 = 0.8987\n",
            "Epoch 5: TrainLoss = 0.2265, ValLoss = 0.2514, Val Acc = 0.8906, Val F1 = 0.8940\n",
            "Epoch 6: TrainLoss = 0.2214, ValLoss = 0.2333, Val Acc = 0.9078, Val F1 = 0.9069\n",
            "Epoch 7: TrainLoss = 0.2126, ValLoss = 0.2632, Val Acc = 0.8920, Val F1 = 0.8829\n",
            "Epoch 8: TrainLoss = 0.2083, ValLoss = 0.2306, Val Acc = 0.9117, Val F1 = 0.9105\n",
            "Epoch 9: TrainLoss = 0.1975, ValLoss = 0.2736, Val Acc = 0.8880, Val F1 = 0.8939\n",
            "Epoch 10: TrainLoss = 0.1909, ValLoss = 0.2299, Val Acc = 0.9078, Val F1 = 0.9054\n",
            "Epoch 11: TrainLoss = 0.1874, ValLoss = 0.2383, Val Acc = 0.8972, Val F1 = 0.8974\n",
            "Epoch 12: TrainLoss = 0.1742, ValLoss = 0.2409, Val Acc = 0.9012, Val F1 = 0.9007\n",
            "Epoch 13: TrainLoss = 0.1737, ValLoss = 0.2363, Val Acc = 0.9065, Val F1 = 0.9039\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 58/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3311, ValLoss = 0.2515, Val Acc = 0.9051, Val F1 = 0.9050\n",
            "Epoch 2: TrainLoss = 0.2611, ValLoss = 0.3549, Val Acc = 0.8564, Val F1 = 0.8679\n",
            "Epoch 3: TrainLoss = 0.2402, ValLoss = 0.2409, Val Acc = 0.8999, Val F1 = 0.8962\n",
            "Epoch 4: TrainLoss = 0.2242, ValLoss = 0.2331, Val Acc = 0.9104, Val F1 = 0.9103\n",
            "Epoch 5: TrainLoss = 0.2091, ValLoss = 0.2858, Val Acc = 0.8735, Val F1 = 0.8601\n",
            "Epoch 6: TrainLoss = 0.1878, ValLoss = 0.2445, Val Acc = 0.9104, Val F1 = 0.9096\n",
            "Epoch 7: TrainLoss = 0.1709, ValLoss = 0.2766, Val Acc = 0.8946, Val F1 = 0.8972\n",
            "Epoch 8: TrainLoss = 0.1561, ValLoss = 0.2432, Val Acc = 0.9104, Val F1 = 0.9093\n",
            "Epoch 9: TrainLoss = 0.1380, ValLoss = 0.2488, Val Acc = 0.9078, Val F1 = 0.9062\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 59/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3397, ValLoss = 0.2987, Val Acc = 0.8748, Val F1 = 0.8820\n",
            "Epoch 2: TrainLoss = 0.2588, ValLoss = 0.2442, Val Acc = 0.8999, Val F1 = 0.9000\n",
            "Epoch 3: TrainLoss = 0.2436, ValLoss = 0.2294, Val Acc = 0.9051, Val F1 = 0.9045\n",
            "Epoch 4: TrainLoss = 0.2251, ValLoss = 0.2321, Val Acc = 0.9130, Val F1 = 0.9096\n",
            "Epoch 5: TrainLoss = 0.2099, ValLoss = 0.2490, Val Acc = 0.8959, Val F1 = 0.8886\n",
            "Epoch 6: TrainLoss = 0.1964, ValLoss = 0.2328, Val Acc = 0.9091, Val F1 = 0.9091\n",
            "Epoch 7: TrainLoss = 0.1859, ValLoss = 0.2383, Val Acc = 0.9117, Val F1 = 0.9124\n",
            "Epoch 8: TrainLoss = 0.1673, ValLoss = 0.2776, Val Acc = 0.8999, Val F1 = 0.9023\n",
            "Epoch 9: TrainLoss = 0.1508, ValLoss = 0.2859, Val Acc = 0.8946, Val F1 = 0.8880\n",
            "Epoch 10: TrainLoss = 0.1395, ValLoss = 0.2596, Val Acc = 0.9012, Val F1 = 0.9012\n",
            "Epoch 11: TrainLoss = 0.1250, ValLoss = 0.3142, Val Acc = 0.8841, Val F1 = 0.8880\n",
            "Epoch 12: TrainLoss = 0.1130, ValLoss = 0.2918, Val Acc = 0.8972, Val F1 = 0.8990\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 60/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3518, ValLoss = 0.2593, Val Acc = 0.8946, Val F1 = 0.8942\n",
            "Epoch 2: TrainLoss = 0.2658, ValLoss = 0.2649, Val Acc = 0.8867, Val F1 = 0.8771\n",
            "Epoch 3: TrainLoss = 0.2489, ValLoss = 0.2524, Val Acc = 0.8999, Val F1 = 0.9018\n",
            "Epoch 4: TrainLoss = 0.2252, ValLoss = 0.2322, Val Acc = 0.8999, Val F1 = 0.8987\n",
            "Epoch 5: TrainLoss = 0.2213, ValLoss = 0.2335, Val Acc = 0.9091, Val F1 = 0.9081\n",
            "Epoch 6: TrainLoss = 0.2033, ValLoss = 0.2499, Val Acc = 0.8999, Val F1 = 0.9023\n",
            "Epoch 7: TrainLoss = 0.1965, ValLoss = 0.2378, Val Acc = 0.9091, Val F1 = 0.9086\n",
            "Epoch 8: TrainLoss = 0.1874, ValLoss = 0.2307, Val Acc = 0.9091, Val F1 = 0.9084\n",
            "Epoch 9: TrainLoss = 0.1683, ValLoss = 0.2555, Val Acc = 0.8972, Val F1 = 0.8932\n",
            "Epoch 10: TrainLoss = 0.1613, ValLoss = 0.2611, Val Acc = 0.9025, Val F1 = 0.9046\n",
            "Epoch 11: TrainLoss = 0.1541, ValLoss = 0.2544, Val Acc = 0.9025, Val F1 = 0.9011\n",
            "Epoch 12: TrainLoss = 0.1378, ValLoss = 0.2660, Val Acc = 0.8972, Val F1 = 0.8984\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 61/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3301, ValLoss = 0.2731, Val Acc = 0.8880, Val F1 = 0.8925\n",
            "Epoch 2: TrainLoss = 0.2610, ValLoss = 0.3288, Val Acc = 0.8511, Val F1 = 0.8637\n",
            "Epoch 3: TrainLoss = 0.2387, ValLoss = 0.2449, Val Acc = 0.8986, Val F1 = 0.9017\n",
            "Epoch 4: TrainLoss = 0.2214, ValLoss = 0.2448, Val Acc = 0.8959, Val F1 = 0.8913\n",
            "Epoch 5: TrainLoss = 0.2016, ValLoss = 0.2240, Val Acc = 0.9117, Val F1 = 0.9120\n",
            "Epoch 6: TrainLoss = 0.1828, ValLoss = 0.2394, Val Acc = 0.9078, Val F1 = 0.9084\n",
            "Epoch 7: TrainLoss = 0.1700, ValLoss = 0.2266, Val Acc = 0.9196, Val F1 = 0.9172\n",
            "Epoch 8: TrainLoss = 0.1550, ValLoss = 0.2555, Val Acc = 0.8946, Val F1 = 0.8883\n",
            "Epoch 9: TrainLoss = 0.1460, ValLoss = 0.2499, Val Acc = 0.9012, Val F1 = 0.8993\n",
            "Epoch 10: TrainLoss = 0.1219, ValLoss = 0.3073, Val Acc = 0.9012, Val F1 = 0.8951\n",
            "Epoch 11: TrainLoss = 0.1091, ValLoss = 0.2659, Val Acc = 0.9012, Val F1 = 0.9020\n",
            "Epoch 12: TrainLoss = 0.0968, ValLoss = 0.3009, Val Acc = 0.9091, Val F1 = 0.9091\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 62/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3327, ValLoss = 0.2507, Val Acc = 0.8893, Val F1 = 0.8909\n",
            "Epoch 2: TrainLoss = 0.2595, ValLoss = 0.2760, Val Acc = 0.8854, Val F1 = 0.8903\n",
            "Epoch 3: TrainLoss = 0.2402, ValLoss = 0.2418, Val Acc = 0.9051, Val F1 = 0.9070\n",
            "Epoch 4: TrainLoss = 0.2131, ValLoss = 0.2652, Val Acc = 0.8946, Val F1 = 0.8958\n",
            "Epoch 5: TrainLoss = 0.1995, ValLoss = 0.2322, Val Acc = 0.9091, Val F1 = 0.9074\n",
            "Epoch 6: TrainLoss = 0.1835, ValLoss = 0.2435, Val Acc = 0.9038, Val F1 = 0.9001\n",
            "Epoch 7: TrainLoss = 0.1673, ValLoss = 0.2654, Val Acc = 0.8986, Val F1 = 0.9022\n",
            "Epoch 8: TrainLoss = 0.1548, ValLoss = 0.3211, Val Acc = 0.8814, Val F1 = 0.8881\n",
            "Epoch 9: TrainLoss = 0.1307, ValLoss = 0.2577, Val Acc = 0.9078, Val F1 = 0.9084\n",
            "Epoch 10: TrainLoss = 0.1170, ValLoss = 0.2655, Val Acc = 0.9104, Val F1 = 0.9119\n",
            "Epoch 11: TrainLoss = 0.1073, ValLoss = 0.3110, Val Acc = 0.8867, Val F1 = 0.8775\n",
            "Epoch 12: TrainLoss = 0.0935, ValLoss = 0.2983, Val Acc = 0.9170, Val F1 = 0.9170\n",
            "Epoch 13: TrainLoss = 0.0850, ValLoss = 0.3085, Val Acc = 0.9078, Val F1 = 0.9077\n",
            "Epoch 14: TrainLoss = 0.0714, ValLoss = 0.3331, Val Acc = 0.8946, Val F1 = 0.8947\n",
            "Epoch 15: TrainLoss = 0.0638, ValLoss = 0.3723, Val Acc = 0.8999, Val F1 = 0.8976\n",
            "Epoch 16: TrainLoss = 0.0617, ValLoss = 0.3582, Val Acc = 0.9078, Val F1 = 0.9081\n",
            "Epoch 17: TrainLoss = 0.0577, ValLoss = 0.3623, Val Acc = 0.9091, Val F1 = 0.9076\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 63/81: {'hidden_dim': 512, 'dropout': 0.1, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3536, ValLoss = 0.2630, Val Acc = 0.8920, Val F1 = 0.8877\n",
            "Epoch 2: TrainLoss = 0.2604, ValLoss = 0.2547, Val Acc = 0.8906, Val F1 = 0.8849\n",
            "Epoch 3: TrainLoss = 0.2352, ValLoss = 0.2763, Val Acc = 0.8946, Val F1 = 0.8982\n",
            "Epoch 4: TrainLoss = 0.2218, ValLoss = 0.2315, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 5: TrainLoss = 0.2037, ValLoss = 0.2326, Val Acc = 0.9065, Val F1 = 0.9044\n",
            "Epoch 6: TrainLoss = 0.1932, ValLoss = 0.2390, Val Acc = 0.9104, Val F1 = 0.9086\n",
            "Epoch 7: TrainLoss = 0.1780, ValLoss = 0.2377, Val Acc = 0.9065, Val F1 = 0.9077\n",
            "Epoch 8: TrainLoss = 0.1542, ValLoss = 0.2697, Val Acc = 0.9025, Val F1 = 0.9061\n",
            "Epoch 9: TrainLoss = 0.1419, ValLoss = 0.3245, Val Acc = 0.8801, Val F1 = 0.8878\n",
            "Epoch 10: TrainLoss = 0.1292, ValLoss = 0.2821, Val Acc = 0.9051, Val F1 = 0.9065\n",
            "Epoch 11: TrainLoss = 0.1089, ValLoss = 0.2765, Val Acc = 0.9117, Val F1 = 0.9101\n",
            "Epoch 12: TrainLoss = 0.1005, ValLoss = 0.2928, Val Acc = 0.8972, Val F1 = 0.8904\n",
            "Epoch 13: TrainLoss = 0.0844, ValLoss = 0.3070, Val Acc = 0.9065, Val F1 = 0.9091\n",
            "Epoch 14: TrainLoss = 0.0774, ValLoss = 0.3281, Val Acc = 0.9051, Val F1 = 0.9075\n",
            "Epoch 15: TrainLoss = 0.0657, ValLoss = 0.3432, Val Acc = 0.8972, Val F1 = 0.8926\n",
            "Epoch 16: TrainLoss = 0.0614, ValLoss = 0.3477, Val Acc = 0.9038, Val F1 = 0.9063\n",
            "Early stopping at epoch 16\n",
            "\n",
            "Config 64/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3454, ValLoss = 0.2854, Val Acc = 0.8775, Val F1 = 0.8666\n",
            "Epoch 2: TrainLoss = 0.2716, ValLoss = 0.2441, Val Acc = 0.8986, Val F1 = 0.8961\n",
            "Epoch 3: TrainLoss = 0.2480, ValLoss = 0.2360, Val Acc = 0.9012, Val F1 = 0.8993\n",
            "Epoch 4: TrainLoss = 0.2393, ValLoss = 0.2368, Val Acc = 0.9012, Val F1 = 0.9009\n",
            "Epoch 5: TrainLoss = 0.2294, ValLoss = 0.2535, Val Acc = 0.8933, Val F1 = 0.8848\n",
            "Epoch 6: TrainLoss = 0.2188, ValLoss = 0.2544, Val Acc = 0.8946, Val F1 = 0.8961\n",
            "Epoch 7: TrainLoss = 0.2158, ValLoss = 0.2680, Val Acc = 0.8893, Val F1 = 0.8955\n",
            "Epoch 8: TrainLoss = 0.1969, ValLoss = 0.2417, Val Acc = 0.8986, Val F1 = 0.8964\n",
            "Epoch 9: TrainLoss = 0.1927, ValLoss = 0.2331, Val Acc = 0.9012, Val F1 = 0.8999\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 65/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3602, ValLoss = 0.2811, Val Acc = 0.8788, Val F1 = 0.8838\n",
            "Epoch 2: TrainLoss = 0.2687, ValLoss = 0.2597, Val Acc = 0.8841, Val F1 = 0.8781\n",
            "Epoch 3: TrainLoss = 0.2484, ValLoss = 0.2475, Val Acc = 0.8999, Val F1 = 0.8965\n",
            "Epoch 4: TrainLoss = 0.2353, ValLoss = 0.2619, Val Acc = 0.8959, Val F1 = 0.8889\n",
            "Epoch 5: TrainLoss = 0.2327, ValLoss = 0.2373, Val Acc = 0.9012, Val F1 = 0.8996\n",
            "Epoch 6: TrainLoss = 0.2222, ValLoss = 0.2411, Val Acc = 0.9012, Val F1 = 0.8966\n",
            "Epoch 7: TrainLoss = 0.2130, ValLoss = 0.2333, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 8: TrainLoss = 0.2088, ValLoss = 0.2374, Val Acc = 0.8999, Val F1 = 0.8970\n",
            "Epoch 9: TrainLoss = 0.1982, ValLoss = 0.2318, Val Acc = 0.9091, Val F1 = 0.9081\n",
            "Epoch 10: TrainLoss = 0.1913, ValLoss = 0.2321, Val Acc = 0.9065, Val F1 = 0.9072\n",
            "Epoch 11: TrainLoss = 0.1901, ValLoss = 0.2342, Val Acc = 0.9012, Val F1 = 0.8974\n",
            "Epoch 12: TrainLoss = 0.1788, ValLoss = 0.2302, Val Acc = 0.9078, Val F1 = 0.9067\n",
            "Epoch 13: TrainLoss = 0.1741, ValLoss = 0.2615, Val Acc = 0.8906, Val F1 = 0.8937\n",
            "Epoch 14: TrainLoss = 0.1630, ValLoss = 0.2428, Val Acc = 0.9012, Val F1 = 0.9017\n",
            "Early stopping at epoch 14\n",
            "\n",
            "Config 66/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3874, ValLoss = 0.2763, Val Acc = 0.8841, Val F1 = 0.8851\n",
            "Epoch 2: TrainLoss = 0.2709, ValLoss = 0.2815, Val Acc = 0.8827, Val F1 = 0.8892\n",
            "Epoch 3: TrainLoss = 0.2519, ValLoss = 0.2823, Val Acc = 0.8801, Val F1 = 0.8875\n",
            "Epoch 4: TrainLoss = 0.2451, ValLoss = 0.2361, Val Acc = 0.9012, Val F1 = 0.8991\n",
            "Epoch 5: TrainLoss = 0.2313, ValLoss = 0.2337, Val Acc = 0.9065, Val F1 = 0.9062\n",
            "Epoch 6: TrainLoss = 0.2242, ValLoss = 0.2391, Val Acc = 0.9051, Val F1 = 0.9037\n",
            "Epoch 7: TrainLoss = 0.2225, ValLoss = 0.2278, Val Acc = 0.9065, Val F1 = 0.9055\n",
            "Epoch 8: TrainLoss = 0.2138, ValLoss = 0.2365, Val Acc = 0.9078, Val F1 = 0.9074\n",
            "Epoch 9: TrainLoss = 0.2057, ValLoss = 0.2302, Val Acc = 0.9065, Val F1 = 0.9065\n",
            "Epoch 10: TrainLoss = 0.2010, ValLoss = 0.2620, Val Acc = 0.8867, Val F1 = 0.8911\n",
            "Epoch 11: TrainLoss = 0.1988, ValLoss = 0.2437, Val Acc = 0.8986, Val F1 = 0.8938\n",
            "Epoch 12: TrainLoss = 0.1923, ValLoss = 0.2465, Val Acc = 0.8933, Val F1 = 0.8966\n",
            "Epoch 13: TrainLoss = 0.1848, ValLoss = 0.2471, Val Acc = 0.9065, Val F1 = 0.9082\n",
            "Epoch 14: TrainLoss = 0.1828, ValLoss = 0.2603, Val Acc = 0.8893, Val F1 = 0.8937\n",
            "Epoch 15: TrainLoss = 0.1723, ValLoss = 0.2449, Val Acc = 0.8933, Val F1 = 0.8921\n",
            "Epoch 16: TrainLoss = 0.1714, ValLoss = 0.2403, Val Acc = 0.9065, Val F1 = 0.9047\n",
            "Epoch 17: TrainLoss = 0.1604, ValLoss = 0.2368, Val Acc = 0.8986, Val F1 = 0.9009\n",
            "Epoch 18: TrainLoss = 0.1570, ValLoss = 0.2470, Val Acc = 0.8920, Val F1 = 0.8883\n",
            "Early stopping at epoch 18\n",
            "\n",
            "Config 67/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3414, ValLoss = 0.3191, Val Acc = 0.8682, Val F1 = 0.8792\n",
            "Epoch 2: TrainLoss = 0.2716, ValLoss = 0.2623, Val Acc = 0.8906, Val F1 = 0.8948\n",
            "Epoch 3: TrainLoss = 0.2486, ValLoss = 0.2616, Val Acc = 0.8946, Val F1 = 0.8980\n",
            "Epoch 4: TrainLoss = 0.2322, ValLoss = 0.2735, Val Acc = 0.8893, Val F1 = 0.8958\n",
            "Epoch 5: TrainLoss = 0.2228, ValLoss = 0.2621, Val Acc = 0.8814, Val F1 = 0.8866\n",
            "Epoch 6: TrainLoss = 0.2064, ValLoss = 0.2500, Val Acc = 0.9038, Val F1 = 0.9053\n",
            "Epoch 7: TrainLoss = 0.1960, ValLoss = 0.3592, Val Acc = 0.8643, Val F1 = 0.8474\n",
            "Epoch 8: TrainLoss = 0.1819, ValLoss = 0.2714, Val Acc = 0.8893, Val F1 = 0.8830\n",
            "Epoch 9: TrainLoss = 0.1745, ValLoss = 0.2874, Val Acc = 0.8801, Val F1 = 0.8702\n",
            "Epoch 10: TrainLoss = 0.1577, ValLoss = 0.2415, Val Acc = 0.9078, Val F1 = 0.9074\n",
            "Epoch 11: TrainLoss = 0.1434, ValLoss = 0.2718, Val Acc = 0.8972, Val F1 = 0.8966\n",
            "Epoch 12: TrainLoss = 0.1333, ValLoss = 0.2739, Val Acc = 0.9025, Val F1 = 0.9041\n",
            "Epoch 13: TrainLoss = 0.1236, ValLoss = 0.3327, Val Acc = 0.8827, Val F1 = 0.8889\n",
            "Epoch 14: TrainLoss = 0.1135, ValLoss = 0.2787, Val Acc = 0.8986, Val F1 = 0.8980\n",
            "Epoch 15: TrainLoss = 0.1041, ValLoss = 0.3006, Val Acc = 0.9012, Val F1 = 0.9017\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 68/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3422, ValLoss = 0.2677, Val Acc = 0.8867, Val F1 = 0.8792\n",
            "Epoch 2: TrainLoss = 0.2677, ValLoss = 0.2396, Val Acc = 0.9038, Val F1 = 0.8999\n",
            "Epoch 3: TrainLoss = 0.2516, ValLoss = 0.2265, Val Acc = 0.9012, Val F1 = 0.9012\n",
            "Epoch 4: TrainLoss = 0.2343, ValLoss = 0.2294, Val Acc = 0.9051, Val F1 = 0.9037\n",
            "Epoch 5: TrainLoss = 0.2231, ValLoss = 0.2296, Val Acc = 0.9012, Val F1 = 0.8991\n",
            "Epoch 6: TrainLoss = 0.2115, ValLoss = 0.3228, Val Acc = 0.8551, Val F1 = 0.8343\n",
            "Epoch 7: TrainLoss = 0.2008, ValLoss = 0.2339, Val Acc = 0.9091, Val F1 = 0.9074\n",
            "Epoch 8: TrainLoss = 0.1932, ValLoss = 0.2710, Val Acc = 0.8906, Val F1 = 0.8846\n",
            "Epoch 9: TrainLoss = 0.1801, ValLoss = 0.2956, Val Acc = 0.8801, Val F1 = 0.8861\n",
            "Epoch 10: TrainLoss = 0.1651, ValLoss = 0.2650, Val Acc = 0.8959, Val F1 = 0.8996\n",
            "Epoch 11: TrainLoss = 0.1561, ValLoss = 0.2519, Val Acc = 0.8999, Val F1 = 0.9013\n",
            "Epoch 12: TrainLoss = 0.1441, ValLoss = 0.2731, Val Acc = 0.8906, Val F1 = 0.8937\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Config 69/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3557, ValLoss = 0.2632, Val Acc = 0.8933, Val F1 = 0.8949\n",
            "Epoch 2: TrainLoss = 0.2680, ValLoss = 0.2465, Val Acc = 0.8972, Val F1 = 0.8952\n",
            "Epoch 3: TrainLoss = 0.2439, ValLoss = 0.2621, Val Acc = 0.8867, Val F1 = 0.8928\n",
            "Epoch 4: TrainLoss = 0.2423, ValLoss = 0.2438, Val Acc = 0.9065, Val F1 = 0.9013\n",
            "Epoch 5: TrainLoss = 0.2279, ValLoss = 0.2416, Val Acc = 0.8986, Val F1 = 0.9006\n",
            "Epoch 6: TrainLoss = 0.2153, ValLoss = 0.2332, Val Acc = 0.8972, Val F1 = 0.8979\n",
            "Epoch 7: TrainLoss = 0.2103, ValLoss = 0.2499, Val Acc = 0.8972, Val F1 = 0.8990\n",
            "Epoch 8: TrainLoss = 0.2055, ValLoss = 0.2325, Val Acc = 0.9051, Val F1 = 0.9045\n",
            "Epoch 9: TrainLoss = 0.1871, ValLoss = 0.2743, Val Acc = 0.8880, Val F1 = 0.8931\n",
            "Epoch 10: TrainLoss = 0.1830, ValLoss = 0.2427, Val Acc = 0.8986, Val F1 = 0.8972\n",
            "Epoch 11: TrainLoss = 0.1710, ValLoss = 0.2529, Val Acc = 0.8972, Val F1 = 0.8914\n",
            "Epoch 12: TrainLoss = 0.1684, ValLoss = 0.2602, Val Acc = 0.8933, Val F1 = 0.8919\n",
            "Epoch 13: TrainLoss = 0.1501, ValLoss = 0.2616, Val Acc = 0.8999, Val F1 = 0.9018\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 70/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3527, ValLoss = 0.2969, Val Acc = 0.8722, Val F1 = 0.8801\n",
            "Epoch 2: TrainLoss = 0.2753, ValLoss = 0.2967, Val Acc = 0.8709, Val F1 = 0.8550\n",
            "Epoch 3: TrainLoss = 0.2545, ValLoss = 0.2341, Val Acc = 0.9104, Val F1 = 0.9110\n",
            "Epoch 4: TrainLoss = 0.2428, ValLoss = 0.2605, Val Acc = 0.8893, Val F1 = 0.8953\n",
            "Epoch 5: TrainLoss = 0.2360, ValLoss = 0.2537, Val Acc = 0.8946, Val F1 = 0.8901\n",
            "Epoch 6: TrainLoss = 0.2201, ValLoss = 0.2908, Val Acc = 0.8880, Val F1 = 0.8784\n",
            "Epoch 7: TrainLoss = 0.2147, ValLoss = 0.2338, Val Acc = 0.9091, Val F1 = 0.9056\n",
            "Epoch 8: TrainLoss = 0.2053, ValLoss = 0.2334, Val Acc = 0.9104, Val F1 = 0.9101\n",
            "Early stopping at epoch 8\n",
            "\n",
            "Config 71/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3396, ValLoss = 0.2603, Val Acc = 0.8841, Val F1 = 0.8814\n",
            "Epoch 2: TrainLoss = 0.2729, ValLoss = 0.2694, Val Acc = 0.8880, Val F1 = 0.8925\n",
            "Epoch 3: TrainLoss = 0.2527, ValLoss = 0.2401, Val Acc = 0.9038, Val F1 = 0.9048\n",
            "Epoch 4: TrainLoss = 0.2343, ValLoss = 0.2306, Val Acc = 0.9025, Val F1 = 0.9008\n",
            "Epoch 5: TrainLoss = 0.2165, ValLoss = 0.2558, Val Acc = 0.8972, Val F1 = 0.8990\n",
            "Epoch 6: TrainLoss = 0.2180, ValLoss = 0.2283, Val Acc = 0.9065, Val F1 = 0.9057\n",
            "Epoch 7: TrainLoss = 0.2075, ValLoss = 0.2368, Val Acc = 0.8999, Val F1 = 0.8970\n",
            "Epoch 8: TrainLoss = 0.1841, ValLoss = 0.3144, Val Acc = 0.8906, Val F1 = 0.8813\n",
            "Epoch 9: TrainLoss = 0.1704, ValLoss = 0.2609, Val Acc = 0.8986, Val F1 = 0.8999\n",
            "Epoch 10: TrainLoss = 0.1610, ValLoss = 0.2416, Val Acc = 0.9051, Val F1 = 0.9022\n",
            "Epoch 11: TrainLoss = 0.1484, ValLoss = 0.2724, Val Acc = 0.9051, Val F1 = 0.8997\n",
            "Early stopping at epoch 11\n",
            "\n",
            "Config 72/81: {'hidden_dim': 512, 'dropout': 0.3, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3556, ValLoss = 0.2709, Val Acc = 0.8880, Val F1 = 0.8895\n",
            "Epoch 2: TrainLoss = 0.2630, ValLoss = 0.2708, Val Acc = 0.8880, Val F1 = 0.8947\n",
            "Epoch 3: TrainLoss = 0.2476, ValLoss = 0.2557, Val Acc = 0.8893, Val F1 = 0.8931\n",
            "Epoch 4: TrainLoss = 0.2330, ValLoss = 0.2376, Val Acc = 0.8986, Val F1 = 0.8977\n",
            "Epoch 5: TrainLoss = 0.2224, ValLoss = 0.2551, Val Acc = 0.8946, Val F1 = 0.8992\n",
            "Epoch 6: TrainLoss = 0.2027, ValLoss = 0.2475, Val Acc = 0.8920, Val F1 = 0.8951\n",
            "Epoch 7: TrainLoss = 0.1875, ValLoss = 0.2482, Val Acc = 0.9025, Val F1 = 0.8989\n",
            "Epoch 8: TrainLoss = 0.1803, ValLoss = 0.2590, Val Acc = 0.8933, Val F1 = 0.8952\n",
            "Epoch 9: TrainLoss = 0.1721, ValLoss = 0.2560, Val Acc = 0.9025, Val F1 = 0.9056\n",
            "Epoch 10: TrainLoss = 0.1526, ValLoss = 0.2637, Val Acc = 0.9051, Val F1 = 0.9070\n",
            "Epoch 11: TrainLoss = 0.1470, ValLoss = 0.3466, Val Acc = 0.8801, Val F1 = 0.8883\n",
            "Epoch 12: TrainLoss = 0.1294, ValLoss = 0.3040, Val Acc = 0.8933, Val F1 = 0.8981\n",
            "Epoch 13: TrainLoss = 0.1245, ValLoss = 0.3129, Val Acc = 0.8906, Val F1 = 0.8945\n",
            "Epoch 14: TrainLoss = 0.1194, ValLoss = 0.2647, Val Acc = 0.9078, Val F1 = 0.9093\n",
            "Epoch 15: TrainLoss = 0.1046, ValLoss = 0.2835, Val Acc = 0.9065, Val F1 = 0.9060\n",
            "Epoch 16: TrainLoss = 0.0931, ValLoss = 0.2804, Val Acc = 0.9130, Val F1 = 0.9122\n",
            "Epoch 17: TrainLoss = 0.0900, ValLoss = 0.3338, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 18: TrainLoss = 0.0796, ValLoss = 0.3512, Val Acc = 0.8986, Val F1 = 0.9014\n",
            "Epoch 19: TrainLoss = 0.0781, ValLoss = 0.3558, Val Acc = 0.9051, Val F1 = 0.9055\n",
            "Epoch 20: TrainLoss = 0.0794, ValLoss = 0.4305, Val Acc = 0.8841, Val F1 = 0.8908\n",
            "Epoch 21: TrainLoss = 0.0674, ValLoss = 0.4639, Val Acc = 0.8775, Val F1 = 0.8859\n",
            "Early stopping at epoch 21\n",
            "\n",
            "Config 73/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3601, ValLoss = 0.2713, Val Acc = 0.8920, Val F1 = 0.8949\n",
            "Epoch 2: TrainLoss = 0.2770, ValLoss = 0.2878, Val Acc = 0.8722, Val F1 = 0.8584\n",
            "Epoch 3: TrainLoss = 0.2577, ValLoss = 0.2628, Val Acc = 0.8867, Val F1 = 0.8925\n",
            "Epoch 4: TrainLoss = 0.2503, ValLoss = 0.2349, Val Acc = 0.9012, Val F1 = 0.9020\n",
            "Epoch 5: TrainLoss = 0.2419, ValLoss = 0.2502, Val Acc = 0.8920, Val F1 = 0.8954\n",
            "Epoch 6: TrainLoss = 0.2300, ValLoss = 0.2299, Val Acc = 0.9078, Val F1 = 0.9041\n",
            "Epoch 7: TrainLoss = 0.2285, ValLoss = 0.2524, Val Acc = 0.8880, Val F1 = 0.8917\n",
            "Epoch 8: TrainLoss = 0.2165, ValLoss = 0.2356, Val Acc = 0.9078, Val F1 = 0.9036\n",
            "Epoch 9: TrainLoss = 0.2139, ValLoss = 0.2352, Val Acc = 0.9065, Val F1 = 0.9037\n",
            "Epoch 10: TrainLoss = 0.1989, ValLoss = 0.2275, Val Acc = 0.9091, Val F1 = 0.9071\n",
            "Epoch 11: TrainLoss = 0.1951, ValLoss = 0.2389, Val Acc = 0.8986, Val F1 = 0.8972\n",
            "Epoch 12: TrainLoss = 0.1927, ValLoss = 0.2874, Val Acc = 0.8827, Val F1 = 0.8886\n",
            "Epoch 13: TrainLoss = 0.1837, ValLoss = 0.2823, Val Acc = 0.8841, Val F1 = 0.8903\n",
            "Epoch 14: TrainLoss = 0.1762, ValLoss = 0.2601, Val Acc = 0.8999, Val F1 = 0.8930\n",
            "Epoch 15: TrainLoss = 0.1675, ValLoss = 0.2573, Val Acc = 0.8946, Val F1 = 0.8958\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Config 74/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3684, ValLoss = 0.2726, Val Acc = 0.8867, Val F1 = 0.8825\n",
            "Epoch 2: TrainLoss = 0.2741, ValLoss = 0.2486, Val Acc = 0.8999, Val F1 = 0.9010\n",
            "Epoch 3: TrainLoss = 0.2607, ValLoss = 0.2491, Val Acc = 0.8959, Val F1 = 0.8901\n",
            "Epoch 4: TrainLoss = 0.2463, ValLoss = 0.2473, Val Acc = 0.8972, Val F1 = 0.8987\n",
            "Epoch 5: TrainLoss = 0.2374, ValLoss = 0.2318, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Epoch 6: TrainLoss = 0.2347, ValLoss = 0.2346, Val Acc = 0.8999, Val F1 = 0.8965\n",
            "Epoch 7: TrainLoss = 0.2219, ValLoss = 0.2357, Val Acc = 0.9025, Val F1 = 0.9026\n",
            "Epoch 8: TrainLoss = 0.2151, ValLoss = 0.2338, Val Acc = 0.9065, Val F1 = 0.9029\n",
            "Epoch 9: TrainLoss = 0.2144, ValLoss = 0.2258, Val Acc = 0.9065, Val F1 = 0.9072\n",
            "Epoch 10: TrainLoss = 0.2052, ValLoss = 0.2384, Val Acc = 0.8999, Val F1 = 0.9010\n",
            "Epoch 11: TrainLoss = 0.2006, ValLoss = 0.2568, Val Acc = 0.8933, Val F1 = 0.8979\n",
            "Epoch 12: TrainLoss = 0.1954, ValLoss = 0.2366, Val Acc = 0.9130, Val F1 = 0.9122\n",
            "Epoch 13: TrainLoss = 0.1918, ValLoss = 0.2376, Val Acc = 0.8986, Val F1 = 0.8986\n",
            "Epoch 14: TrainLoss = 0.1876, ValLoss = 0.2304, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Epoch 15: TrainLoss = 0.1847, ValLoss = 0.2450, Val Acc = 0.9078, Val F1 = 0.9079\n",
            "Epoch 16: TrainLoss = 0.1740, ValLoss = 0.2413, Val Acc = 0.9025, Val F1 = 0.9008\n",
            "Epoch 17: TrainLoss = 0.1692, ValLoss = 0.2502, Val Acc = 0.9025, Val F1 = 0.9019\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 75/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.0005, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.4058, ValLoss = 0.2866, Val Acc = 0.8735, Val F1 = 0.8674\n",
            "Epoch 2: TrainLoss = 0.2817, ValLoss = 0.2523, Val Acc = 0.8972, Val F1 = 0.8968\n",
            "Epoch 3: TrainLoss = 0.2600, ValLoss = 0.2420, Val Acc = 0.9025, Val F1 = 0.9005\n",
            "Epoch 4: TrainLoss = 0.2556, ValLoss = 0.2491, Val Acc = 0.8972, Val F1 = 0.8976\n",
            "Epoch 5: TrainLoss = 0.2390, ValLoss = 0.2428, Val Acc = 0.8986, Val F1 = 0.8929\n",
            "Epoch 6: TrainLoss = 0.2310, ValLoss = 0.2377, Val Acc = 0.9025, Val F1 = 0.9031\n",
            "Epoch 7: TrainLoss = 0.2280, ValLoss = 0.2338, Val Acc = 0.9012, Val F1 = 0.8991\n",
            "Epoch 8: TrainLoss = 0.2201, ValLoss = 0.2414, Val Acc = 0.8986, Val F1 = 0.8993\n",
            "Epoch 9: TrainLoss = 0.2207, ValLoss = 0.2487, Val Acc = 0.8959, Val F1 = 0.8988\n",
            "Epoch 10: TrainLoss = 0.2133, ValLoss = 0.2306, Val Acc = 0.9051, Val F1 = 0.9040\n",
            "Epoch 11: TrainLoss = 0.2090, ValLoss = 0.2455, Val Acc = 0.8972, Val F1 = 0.8987\n",
            "Epoch 12: TrainLoss = 0.2014, ValLoss = 0.2288, Val Acc = 0.9117, Val F1 = 0.9113\n",
            "Epoch 13: TrainLoss = 0.1999, ValLoss = 0.2707, Val Acc = 0.8867, Val F1 = 0.8920\n",
            "Epoch 14: TrainLoss = 0.1937, ValLoss = 0.2384, Val Acc = 0.9078, Val F1 = 0.9064\n",
            "Epoch 15: TrainLoss = 0.1897, ValLoss = 0.2464, Val Acc = 0.8933, Val F1 = 0.8958\n",
            "Epoch 16: TrainLoss = 0.1825, ValLoss = 0.2403, Val Acc = 0.9038, Val F1 = 0.9056\n",
            "Epoch 17: TrainLoss = 0.1800, ValLoss = 0.2385, Val Acc = 0.9104, Val F1 = 0.9108\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 76/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3523, ValLoss = 0.2736, Val Acc = 0.8880, Val F1 = 0.8906\n",
            "Epoch 2: TrainLoss = 0.2807, ValLoss = 0.2494, Val Acc = 0.9025, Val F1 = 0.9013\n",
            "Epoch 3: TrainLoss = 0.2686, ValLoss = 0.2953, Val Acc = 0.8748, Val F1 = 0.8834\n",
            "Epoch 4: TrainLoss = 0.2577, ValLoss = 0.2349, Val Acc = 0.9104, Val F1 = 0.9119\n",
            "Epoch 5: TrainLoss = 0.2528, ValLoss = 0.2694, Val Acc = 0.8841, Val F1 = 0.8746\n",
            "Epoch 6: TrainLoss = 0.2333, ValLoss = 0.2319, Val Acc = 0.9025, Val F1 = 0.9016\n",
            "Epoch 7: TrainLoss = 0.2200, ValLoss = 0.2834, Val Acc = 0.8854, Val F1 = 0.8919\n",
            "Epoch 8: TrainLoss = 0.2211, ValLoss = 0.3309, Val Acc = 0.8524, Val F1 = 0.8657\n",
            "Epoch 9: TrainLoss = 0.2059, ValLoss = 0.2598, Val Acc = 0.8959, Val F1 = 0.8988\n",
            "Early stopping at epoch 9\n",
            "\n",
            "Config 77/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3702, ValLoss = 0.2868, Val Acc = 0.8841, Val F1 = 0.8883\n",
            "Epoch 2: TrainLoss = 0.2740, ValLoss = 0.2463, Val Acc = 0.8999, Val F1 = 0.8967\n",
            "Epoch 3: TrainLoss = 0.2640, ValLoss = 0.2358, Val Acc = 0.9078, Val F1 = 0.9069\n",
            "Epoch 4: TrainLoss = 0.2492, ValLoss = 0.2373, Val Acc = 0.9065, Val F1 = 0.9052\n",
            "Epoch 5: TrainLoss = 0.2399, ValLoss = 0.2339, Val Acc = 0.9065, Val F1 = 0.9077\n",
            "Epoch 6: TrainLoss = 0.2284, ValLoss = 0.2320, Val Acc = 0.9091, Val F1 = 0.9084\n",
            "Epoch 7: TrainLoss = 0.2256, ValLoss = 0.2325, Val Acc = 0.8986, Val F1 = 0.8980\n",
            "Epoch 8: TrainLoss = 0.2117, ValLoss = 0.3615, Val Acc = 0.8551, Val F1 = 0.8700\n",
            "Epoch 9: TrainLoss = 0.2070, ValLoss = 0.2355, Val Acc = 0.8999, Val F1 = 0.8989\n",
            "Epoch 10: TrainLoss = 0.1981, ValLoss = 0.2624, Val Acc = 0.8893, Val F1 = 0.8934\n",
            "Epoch 11: TrainLoss = 0.1891, ValLoss = 0.2322, Val Acc = 0.9104, Val F1 = 0.9096\n",
            "Epoch 12: TrainLoss = 0.1830, ValLoss = 0.2709, Val Acc = 0.8906, Val F1 = 0.8823\n",
            "Epoch 13: TrainLoss = 0.1734, ValLoss = 0.2490, Val Acc = 0.9104, Val F1 = 0.9086\n",
            "Epoch 14: TrainLoss = 0.1641, ValLoss = 0.2964, Val Acc = 0.8920, Val F1 = 0.8975\n",
            "Epoch 15: TrainLoss = 0.1637, ValLoss = 0.2373, Val Acc = 0.9038, Val F1 = 0.9028\n",
            "Epoch 16: TrainLoss = 0.1476, ValLoss = 0.2750, Val Acc = 0.8972, Val F1 = 0.9010\n",
            "Early stopping at epoch 16\n",
            "\n",
            "Config 78/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3676, ValLoss = 0.3077, Val Acc = 0.8682, Val F1 = 0.8778\n",
            "Epoch 2: TrainLoss = 0.2762, ValLoss = 0.2541, Val Acc = 0.8933, Val F1 = 0.8947\n",
            "Epoch 3: TrainLoss = 0.2619, ValLoss = 0.2368, Val Acc = 0.9065, Val F1 = 0.9055\n",
            "Epoch 4: TrainLoss = 0.2481, ValLoss = 0.2676, Val Acc = 0.8893, Val F1 = 0.8814\n",
            "Epoch 5: TrainLoss = 0.2335, ValLoss = 0.2418, Val Acc = 0.8986, Val F1 = 0.8955\n",
            "Epoch 6: TrainLoss = 0.2265, ValLoss = 0.2597, Val Acc = 0.8920, Val F1 = 0.8855\n",
            "Epoch 7: TrainLoss = 0.2248, ValLoss = 0.2545, Val Acc = 0.8933, Val F1 = 0.8973\n",
            "Epoch 8: TrainLoss = 0.2116, ValLoss = 0.2276, Val Acc = 0.9157, Val F1 = 0.9144\n",
            "Epoch 9: TrainLoss = 0.2086, ValLoss = 0.2331, Val Acc = 0.9065, Val F1 = 0.9055\n",
            "Epoch 10: TrainLoss = 0.1946, ValLoss = 0.2271, Val Acc = 0.9078, Val F1 = 0.9054\n",
            "Epoch 11: TrainLoss = 0.1949, ValLoss = 0.2329, Val Acc = 0.9065, Val F1 = 0.9047\n",
            "Epoch 12: TrainLoss = 0.1932, ValLoss = 0.2827, Val Acc = 0.8880, Val F1 = 0.8941\n",
            "Epoch 13: TrainLoss = 0.1797, ValLoss = 0.2728, Val Acc = 0.8893, Val F1 = 0.8929\n",
            "Early stopping at epoch 13\n",
            "\n",
            "Config 79/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 16}\n",
            "Epoch 1: TrainLoss = 0.3640, ValLoss = 0.2639, Val Acc = 0.8906, Val F1 = 0.8852\n",
            "Epoch 2: TrainLoss = 0.3015, ValLoss = 0.2566, Val Acc = 0.8893, Val F1 = 0.8824\n",
            "Epoch 3: TrainLoss = 0.2829, ValLoss = 0.2487, Val Acc = 0.8972, Val F1 = 0.8954\n",
            "Epoch 4: TrainLoss = 0.2787, ValLoss = 0.2272, Val Acc = 0.8959, Val F1 = 0.8954\n",
            "Epoch 5: TrainLoss = 0.2656, ValLoss = 0.2262, Val Acc = 0.9065, Val F1 = 0.9039\n",
            "Epoch 6: TrainLoss = 0.2485, ValLoss = 0.2667, Val Acc = 0.8893, Val F1 = 0.8786\n",
            "Epoch 7: TrainLoss = 0.2372, ValLoss = 0.2325, Val Acc = 0.8959, Val F1 = 0.8889\n",
            "Epoch 8: TrainLoss = 0.2354, ValLoss = 0.2659, Val Acc = 0.8841, Val F1 = 0.8875\n",
            "Epoch 9: TrainLoss = 0.2264, ValLoss = 0.2383, Val Acc = 0.9012, Val F1 = 0.9027\n",
            "Epoch 10: TrainLoss = 0.2160, ValLoss = 0.2482, Val Acc = 0.9012, Val F1 = 0.9032\n",
            "Early stopping at epoch 10\n",
            "\n",
            "Config 80/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 32}\n",
            "Epoch 1: TrainLoss = 0.3577, ValLoss = 0.2770, Val Acc = 0.8827, Val F1 = 0.8869\n",
            "Epoch 2: TrainLoss = 0.2850, ValLoss = 0.2484, Val Acc = 0.8933, Val F1 = 0.8947\n",
            "Epoch 3: TrainLoss = 0.2724, ValLoss = 0.2398, Val Acc = 0.8999, Val F1 = 0.9018\n",
            "Epoch 4: TrainLoss = 0.2579, ValLoss = 0.2602, Val Acc = 0.8906, Val F1 = 0.8945\n",
            "Epoch 5: TrainLoss = 0.2489, ValLoss = 0.2382, Val Acc = 0.9025, Val F1 = 0.9031\n",
            "Epoch 6: TrainLoss = 0.2427, ValLoss = 0.2690, Val Acc = 0.8788, Val F1 = 0.8678\n",
            "Epoch 7: TrainLoss = 0.2313, ValLoss = 0.2291, Val Acc = 0.9025, Val F1 = 0.9003\n",
            "Epoch 8: TrainLoss = 0.2333, ValLoss = 0.2367, Val Acc = 0.9078, Val F1 = 0.9074\n",
            "Epoch 9: TrainLoss = 0.2118, ValLoss = 0.2292, Val Acc = 0.9078, Val F1 = 0.9059\n",
            "Epoch 10: TrainLoss = 0.2013, ValLoss = 0.2459, Val Acc = 0.8959, Val F1 = 0.8919\n",
            "Epoch 11: TrainLoss = 0.2005, ValLoss = 0.2312, Val Acc = 0.9078, Val F1 = 0.9054\n",
            "Epoch 12: TrainLoss = 0.1879, ValLoss = 0.2271, Val Acc = 0.9091, Val F1 = 0.9079\n",
            "Epoch 13: TrainLoss = 0.1850, ValLoss = 0.2667, Val Acc = 0.8999, Val F1 = 0.8956\n",
            "Epoch 14: TrainLoss = 0.1774, ValLoss = 0.3366, Val Acc = 0.8722, Val F1 = 0.8824\n",
            "Epoch 15: TrainLoss = 0.1642, ValLoss = 0.2519, Val Acc = 0.9065, Val F1 = 0.9072\n",
            "Epoch 16: TrainLoss = 0.1565, ValLoss = 0.2529, Val Acc = 0.8999, Val F1 = 0.9010\n",
            "Epoch 17: TrainLoss = 0.1553, ValLoss = 0.2551, Val Acc = 0.8986, Val F1 = 0.8991\n",
            "Early stopping at epoch 17\n",
            "\n",
            "Config 81/81: {'hidden_dim': 512, 'dropout': 0.5, 'lr': 0.002, 'batch_size': 64}\n",
            "Epoch 1: TrainLoss = 0.3622, ValLoss = 0.2815, Val Acc = 0.8880, Val F1 = 0.8917\n",
            "Epoch 2: TrainLoss = 0.2840, ValLoss = 0.2495, Val Acc = 0.8999, Val F1 = 0.8973\n",
            "Epoch 3: TrainLoss = 0.2562, ValLoss = 0.2384, Val Acc = 0.9038, Val F1 = 0.9031\n",
            "Epoch 4: TrainLoss = 0.2584, ValLoss = 0.2538, Val Acc = 0.9025, Val F1 = 0.8966\n",
            "Epoch 5: TrainLoss = 0.2326, ValLoss = 0.2485, Val Acc = 0.9051, Val F1 = 0.9008\n",
            "Epoch 6: TrainLoss = 0.2333, ValLoss = 0.2266, Val Acc = 0.9104, Val F1 = 0.9101\n",
            "Epoch 7: TrainLoss = 0.2164, ValLoss = 0.2529, Val Acc = 0.8946, Val F1 = 0.8987\n",
            "Epoch 8: TrainLoss = 0.2077, ValLoss = 0.2495, Val Acc = 0.8986, Val F1 = 0.9006\n",
            "Epoch 9: TrainLoss = 0.2012, ValLoss = 0.2386, Val Acc = 0.9025, Val F1 = 0.8984\n",
            "Epoch 10: TrainLoss = 0.1957, ValLoss = 0.2421, Val Acc = 0.9012, Val F1 = 0.8977\n",
            "Epoch 11: TrainLoss = 0.1903, ValLoss = 0.2295, Val Acc = 0.9144, Val F1 = 0.9137\n",
            "Epoch 12: TrainLoss = 0.1777, ValLoss = 0.2938, Val Acc = 0.8841, Val F1 = 0.8919\n",
            "Epoch 13: TrainLoss = 0.1808, ValLoss = 0.2428, Val Acc = 0.9065, Val F1 = 0.9062\n",
            "Epoch 14: TrainLoss = 0.1624, ValLoss = 0.2416, Val Acc = 0.9130, Val F1 = 0.9127\n",
            "Epoch 15: TrainLoss = 0.1536, ValLoss = 0.2409, Val Acc = 0.9117, Val F1 = 0.9124\n",
            "Epoch 16: TrainLoss = 0.1476, ValLoss = 0.2342, Val Acc = 0.9117, Val F1 = 0.9122\n",
            "Early stopping at epoch 16\n",
            "\n",
            "Best uni Config: {'hidden_dim': 128, 'dropout': 0.5, 'lr': 0.001, 'batch_size': 16, 'best_val_f1': 0.9177718832891246, 'train_losses': [0.35513860587095336, 0.27823322875104983, 0.2625855946998545, 0.24540296959305602, 0.23591330794876728, 0.22829610244529291, 0.21843723622969527, 0.21300483637906867, 0.1994345574766146, 0.1905026521859884, 0.18752158093763852, 0.18283209038862364], 'val_losses': [0.2866982142680247, 0.2543446770691275, 0.2591770257560318, 0.2464305233107254, 0.24224153918868155, 0.22493938718859857, 0.22770815734335556, 0.23726581093979132, 0.26131193011959863, 0.22790327998018076, 0.2525639451932216, 0.2416376612089054]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Models\n",
        "Retrain model with best Hyperparameter combined Train + Val set"
      ],
      "metadata": {
        "id": "ISeEA9wBoOsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and validation data\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "X_pdb_full = np.concatenate([x_pdb_train, x_pdb_val], axis=0)\n",
        "y_pdb_full = np.concatenate([y_pdb_train, y_pdb_val], axis=0)\n",
        "\n",
        "X_train_diag, X_val_diag, y_train_diag, y_val_diag = train_test_split(\n",
        "    X_pdb_full, y_pdb_full, test_size=0.1, stratify=y_pdb_full, random_state=42\n",
        ")\n",
        "\n",
        "train_diag_dataset = TensorDataset(\n",
        "    torch.tensor(X_train_diag, dtype=torch.float32),\n",
        "    torch.tensor(y_train_diag, dtype=torch.long)\n",
        ")\n",
        "val_diag_dataset = TensorDataset(\n",
        "    torch.tensor(X_val_diag, dtype=torch.float32),\n",
        "    torch.tensor(y_val_diag, dtype=torch.long)\n",
        ")\n",
        "train_diag_loader = DataLoader(\n",
        "    train_diag_dataset, batch_size=best_pdb_config['batch_size'], shuffle=True\n",
        ")\n",
        "val_diag_loader = DataLoader(\n",
        "    val_diag_dataset, batch_size=best_pdb_config['batch_size'], shuffle=False\n",
        ")\n",
        "\n",
        "# Model for final PDB\n",
        "model_pdb = BiLSTMModel(\n",
        "    input_dim=1280,\n",
        "    hidden_dim=best_pdb_config['hidden_dim'],\n",
        "    dropout=best_pdb_config['dropout'],\n",
        "    output_dim=2\n",
        ").to(device)\n",
        "optimizer_pdb = torch.optim.Adam(model_pdb.parameters(), lr=best_pdb_config['lr'])\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    # --- Train ---\n",
        "    model_pdb.train()\n",
        "    train_loss_epoch = 0.0\n",
        "    for xb, yb in train_diag_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer_pdb.zero_grad()\n",
        "        out = model_pdb(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer_pdb.step()\n",
        "        train_loss_epoch += loss.item() * xb.size(0)\n",
        "    train_loss_epoch = train_loss_epoch / len(train_diag_loader.dataset)\n",
        "    train_losses.append(train_loss_epoch)\n",
        "\n",
        "    # --- Val ---\n",
        "    model_pdb.eval()\n",
        "    val_loss_epoch = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_diag_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            out = model_pdb(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            val_loss_epoch += loss.item() * xb.size(0)\n",
        "            preds = torch.argmax(out, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_targets.extend(yb.cpu().numpy())\n",
        "    val_loss_epoch = val_loss_epoch / len(val_diag_loader.dataset)\n",
        "    val_losses.append(val_loss_epoch)\n",
        "\n",
        "    val_f1 = f1_score(all_targets, all_preds, average='binary')\n",
        "    print(f\"Epoch {epoch}: TrainLoss={train_loss_epoch:.4f}, ValLoss={val_loss_epoch:.4f}, ValF1={val_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9xYUrhHwWRxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2713de63-0541-4028-cf78-da7071bdc740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: TrainLoss=0.6009, ValLoss=0.4211, ValF1=0.7179\n",
            "Epoch 2: TrainLoss=0.3645, ValLoss=0.3845, ValF1=0.7595\n",
            "Epoch 3: TrainLoss=0.2700, ValLoss=0.4222, ValF1=0.7368\n",
            "Epoch 4: TrainLoss=0.2306, ValLoss=0.4886, ValF1=0.7848\n",
            "Epoch 5: TrainLoss=0.2343, ValLoss=0.4615, ValF1=0.8095\n",
            "Epoch 6: TrainLoss=0.1737, ValLoss=0.4850, ValF1=0.7765\n",
            "Epoch 7: TrainLoss=0.1413, ValLoss=0.4967, ValF1=0.8421\n",
            "Epoch 8: TrainLoss=0.1854, ValLoss=0.4848, ValF1=0.8444\n",
            "Epoch 9: TrainLoss=0.1096, ValLoss=0.8589, ValF1=0.7467\n",
            "Epoch 10: TrainLoss=0.1245, ValLoss=0.5412, ValF1=0.8222\n",
            "Epoch 11: TrainLoss=0.0812, ValLoss=0.5947, ValF1=0.8235\n",
            "Epoch 12: TrainLoss=0.0688, ValLoss=0.7087, ValF1=0.8095\n",
            "Epoch 13: TrainLoss=0.0612, ValLoss=0.7010, ValF1=0.8352\n",
            "Epoch 14: TrainLoss=0.0591, ValLoss=0.7143, ValF1=0.8298\n",
            "Epoch 15: TrainLoss=0.0352, ValLoss=0.7821, ValF1=0.8090\n",
            "Epoch 16: TrainLoss=0.0315, ValLoss=0.7734, ValF1=0.8261\n",
            "Epoch 17: TrainLoss=0.0440, ValLoss=0.8248, ValF1=0.7901\n",
            "Epoch 18: TrainLoss=0.0321, ValLoss=0.8195, ValF1=0.8140\n",
            "Epoch 19: TrainLoss=0.0459, ValLoss=0.8301, ValF1=0.8095\n",
            "Epoch 20: TrainLoss=0.0567, ValLoss=0.7400, ValF1=0.7952\n",
            "Epoch 21: TrainLoss=0.0305, ValLoss=0.8549, ValF1=0.8132\n",
            "Epoch 22: TrainLoss=0.0144, ValLoss=0.8575, ValF1=0.7816\n",
            "Epoch 23: TrainLoss=0.0113, ValLoss=0.9735, ValF1=0.8095\n",
            "Epoch 24: TrainLoss=0.0153, ValLoss=1.0399, ValF1=0.7901\n",
            "Epoch 25: TrainLoss=0.0145, ValLoss=1.0119, ValF1=0.8387\n",
            "Epoch 26: TrainLoss=0.0096, ValLoss=1.1707, ValF1=0.7901\n",
            "Epoch 27: TrainLoss=0.0496, ValLoss=0.8788, ValF1=0.7857\n",
            "Epoch 28: TrainLoss=0.0201, ValLoss=1.0103, ValF1=0.8000\n",
            "Epoch 29: TrainLoss=0.0068, ValLoss=1.1760, ValF1=0.7750\n",
            "Epoch 30: TrainLoss=0.0046, ValLoss=1.0670, ValF1=0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and validation data\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "X_uni_full = np.concatenate([x_uni_train, x_uni_val], axis=0)\n",
        "y_uni_full = np.concatenate([y_uni_train, y_uni_val], axis=0)\n",
        "\n",
        "X_train_diag, X_val_diag, y_train_diag, y_val_diag = train_test_split(\n",
        "    X_uni_full, y_uni_full, test_size=0.1, stratify=y_uni_full, random_state=42\n",
        ")\n",
        "\n",
        "train_diag_dataset = TensorDataset(\n",
        "    torch.tensor(X_train_diag, dtype=torch.float32),\n",
        "    torch.tensor(y_train_diag, dtype=torch.long)\n",
        ")\n",
        "val_diag_dataset = TensorDataset(\n",
        "    torch.tensor(X_val_diag, dtype=torch.float32),\n",
        "    torch.tensor(y_val_diag, dtype=torch.long)\n",
        ")\n",
        "train_diag_loader = DataLoader(\n",
        "    train_diag_dataset, batch_size=best_uni_config['batch_size'], shuffle=True\n",
        ")\n",
        "val_diag_loader = DataLoader(\n",
        "    val_diag_dataset, batch_size=best_uni_config['batch_size'], shuffle=False\n",
        ")\n",
        "\n",
        "# Model for final uni\n",
        "model_uni = BiLSTMModel(\n",
        "    input_dim=1280,\n",
        "    hidden_dim=best_uni_config['hidden_dim'],\n",
        "    dropout=best_uni_config['dropout'],\n",
        "    output_dim=2\n",
        ").to(device)\n",
        "optimizer_uni = torch.optim.Adam(model_uni.parameters(), lr=best_uni_config['lr'])\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    # --- Train ---\n",
        "    model_uni.train()\n",
        "    train_loss_epoch = 0.0\n",
        "    for xb, yb in train_diag_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer_uni.zero_grad()\n",
        "        out = model_uni(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer_uni.step()\n",
        "        train_loss_epoch += loss.item() * xb.size(0)\n",
        "    train_loss_epoch = train_loss_epoch / len(train_diag_loader.dataset)\n",
        "    train_losses.append(train_loss_epoch)\n",
        "\n",
        "    # --- Val ---\n",
        "    model_uni.eval()\n",
        "    val_loss_epoch = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_diag_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            out = model_uni(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            val_loss_epoch += loss.item() * xb.size(0)\n",
        "            preds = torch.argmax(out, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_targets.extend(yb.cpu().numpy())\n",
        "    val_loss_epoch = val_loss_epoch / len(val_diag_loader.dataset)\n",
        "    val_losses.append(val_loss_epoch)\n",
        "\n",
        "    val_f1 = f1_score(all_targets, all_preds, average='binary')\n",
        "    print(f\"Epoch {epoch}: TrainLoss={train_loss_epoch:.4f}, ValLoss={val_loss_epoch:.4f}, ValF1={val_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DgYn2Xfn0IW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2ed5ef-8eac-4b07-9888-bd8956a1efab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: TrainLoss=0.3548, ValLoss=0.2850, ValF1=0.8896\n",
            "Epoch 2: TrainLoss=0.2758, ValLoss=0.3178, ValF1=0.8635\n",
            "Epoch 3: TrainLoss=0.2604, ValLoss=0.2844, ValF1=0.8884\n",
            "Epoch 4: TrainLoss=0.2435, ValLoss=0.2730, ValF1=0.8899\n",
            "Epoch 5: TrainLoss=0.2320, ValLoss=0.3014, ValF1=0.8875\n",
            "Epoch 6: TrainLoss=0.2235, ValLoss=0.2709, ValF1=0.9023\n",
            "Epoch 7: TrainLoss=0.2134, ValLoss=0.2647, ValF1=0.8984\n",
            "Epoch 8: TrainLoss=0.2076, ValLoss=0.2641, ValF1=0.9027\n",
            "Epoch 9: TrainLoss=0.2004, ValLoss=0.2699, ValF1=0.9024\n",
            "Epoch 10: TrainLoss=0.1820, ValLoss=0.2687, ValF1=0.9014\n",
            "Epoch 11: TrainLoss=0.1836, ValLoss=0.2639, ValF1=0.9051\n",
            "Epoch 12: TrainLoss=0.1768, ValLoss=0.2983, ValF1=0.8872\n",
            "Epoch 13: TrainLoss=0.1724, ValLoss=0.2769, ValF1=0.8975\n",
            "Epoch 14: TrainLoss=0.1591, ValLoss=0.3180, ValF1=0.8839\n",
            "Epoch 15: TrainLoss=0.1547, ValLoss=0.2946, ValF1=0.9051\n",
            "Epoch 16: TrainLoss=0.1455, ValLoss=0.2923, ValF1=0.8969\n",
            "Epoch 17: TrainLoss=0.1361, ValLoss=0.3100, ValF1=0.9019\n",
            "Epoch 18: TrainLoss=0.1298, ValLoss=0.3085, ValF1=0.9027\n",
            "Epoch 19: TrainLoss=0.1265, ValLoss=0.3050, ValF1=0.8956\n",
            "Epoch 20: TrainLoss=0.1188, ValLoss=0.3395, ValF1=0.8858\n",
            "Epoch 21: TrainLoss=0.1115, ValLoss=0.3324, ValF1=0.8886\n",
            "Epoch 22: TrainLoss=0.1135, ValLoss=0.3226, ValF1=0.9097\n",
            "Epoch 23: TrainLoss=0.1039, ValLoss=0.3383, ValF1=0.9001\n",
            "Epoch 24: TrainLoss=0.1033, ValLoss=0.3436, ValF1=0.8966\n",
            "Epoch 25: TrainLoss=0.0940, ValLoss=0.3346, ValF1=0.9006\n",
            "Epoch 26: TrainLoss=0.0880, ValLoss=0.3796, ValF1=0.8918\n",
            "Epoch 27: TrainLoss=0.0834, ValLoss=0.3370, ValF1=0.8990\n",
            "Epoch 28: TrainLoss=0.0849, ValLoss=0.3600, ValF1=0.9040\n",
            "Epoch 29: TrainLoss=0.0809, ValLoss=0.3616, ValF1=0.8992\n",
            "Epoch 30: TrainLoss=0.0728, ValLoss=0.3659, ValF1=0.8965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_report(model, loader, name, return_probs=False):\n",
        "    model.eval()\n",
        "    all_preds, all_targets = [], []\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            outputs = model(xb)\n",
        "            probs = torch.softmax(outputs, dim=1)[:,1].cpu().numpy()  # For binary\n",
        "            preds = np.round(probs)\n",
        "            all_probs.extend(probs)\n",
        "            all_preds.extend(preds)\n",
        "            all_targets.extend(yb.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    prec = precision_score(all_targets, all_preds)\n",
        "    rec = recall_score(all_targets, all_preds)\n",
        "    f1 = f1_score(all_targets, all_preds)\n",
        "    mcc = matthews_corrcoef(all_targets, all_preds)\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    # Sensitivity == Recall; Specificity == True Negative Rate\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = rec\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # ROC/AUC\n",
        "    roc_auc = roc_auc_score(all_targets, all_probs)\n",
        "    fpr, tpr, thresholds = roc_curve(all_targets, all_probs)\n",
        "\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(f\"  Accuracy     : {acc:.4f}\")\n",
        "    print(f\"  Precision    : {prec:.4f}\")\n",
        "    print(f\"  Recall/Sens. : {sensitivity:.4f}\")\n",
        "    print(f\"  Specificity  : {specificity:.4f}\")\n",
        "    print(f\"  F1-score     : {f1:.4f}\")\n",
        "    print(f\"  MCC          : {mcc:.4f}\")\n",
        "    print(f\"  ROC_AUC      : {roc_auc:.4f}\")\n",
        "    print(f\"  Confusion Matrix:\\n{cm}\\n\")\n",
        "    print(f\"{name} Classification Report:\")\n",
        "    print(classification_report(all_targets, all_preds, digits=4))\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ROC Curve\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate (Recall)')\n",
        "    plt.title(f'{name} ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot val loss\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Train & Val Loss Curves (Best Model Retrain)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Optionally return probabilities for further analysis\n",
        "    if return_probs:\n",
        "        return all_preds, all_targets, all_probs\n",
        "\n",
        "    # For report table (like image): print markdown or as pandas.DataFrame\n",
        "    metrics = {\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision_macro\": prec,\n",
        "        \"Recall_macro\": rec,\n",
        "        \"F1_macro\": f1,\n",
        "        \"MCC\": mcc,\n",
        "        \"Specificity\": specificity,\n",
        "        \"ROC_AUC\": roc_auc\n",
        "    }\n",
        "# Run evaluation ONLY on test set for final results\n",
        "pdb_test_dataset = TensorDataset(torch.tensor(x_pdb_test_emb, dtype=torch.float32), torch.tensor(y_pdb_test, dtype=torch.long))\n",
        "pdb_test_loader = DataLoader(pdb_test_dataset, batch_size=best_pdb_config['batch_size'], shuffle=False)\n",
        "\n",
        "evaluate_and_report(model_pdb, pdb_test_loader, \"PDB Test\")\n",
        "\n",
        "uni_test_dataset = TensorDataset(torch.tensor(x_uni_test_emb, dtype=torch.float32), torch.tensor(y_uni_test, dtype=torch.long))\n",
        "uni_test_loader = DataLoader(uni_test_dataset, batch_size=best_uni_config['batch_size'], shuffle=False)\n",
        "\n",
        "evaluate_and_report(model_uni, uni_test_loader, \"UniSwiss Test\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eWPgS-ZtmU8S",
        "outputId": "53077174-a1c3-4ad5-ab2f-05bc5993817b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PDB Test Metrics:\n",
            "  Accuracy     : 0.8172\n",
            "  Precision    : 0.8391\n",
            "  Recall/Sens. : 0.7849\n",
            "  Specificity  : 0.8495\n",
            "  F1-score     : 0.8111\n",
            "  MCC          : 0.6357\n",
            "  ROC_AUC      : 0.9106\n",
            "  Confusion Matrix:\n",
            "[[79 14]\n",
            " [20 73]]\n",
            "\n",
            "PDB Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7980    0.8495    0.8229        93\n",
            "           1     0.8391    0.7849    0.8111        93\n",
            "\n",
            "    accuracy                         0.8172       186\n",
            "   macro avg     0.8185    0.8172    0.8170       186\n",
            "weighted avg     0.8185    0.8172    0.8170       186\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAb/1JREFUeJzt3XdYU9f/B/B3GAkbXIAoirg3Cu5VFYW6W/2K4sBdB2q11q24R92tuPcGZ7WuqgWrVq2KWBUX7gWIypBNcn5/+DMtBS3BhAvh/XqePDUn9968c6Xmw7nnniMTQggQERER6QkDqQMQERERaROLGyIiItIrLG6IiIhIr7C4ISIiIr3C4oaIiIj0CosbIiIi0issboiIiEivsLghIiIivcLihoiIiPQKixsiIiLSKyxuiPKATZs2QSaTqR8mJiaoUKECfH19ERkZqd4uODg4w3YKhQJ2dnb44osvMGfOHLx69eo/jy2TyWBra4vmzZvj6NGjGuX62MPJyUkr5+GPP/7AtGnTEBMTk63t+/Tpk+l8VKhQAVOnTkVycnKW+yQkJGDmzJmoUaMGzMzMYG1tjSZNmmDLli342Go0ycnJWLJkCerVqwdra+sMfz93797NVtbIyEiMGTMGlSpVgpmZGczNzeHq6opZs2Zl+/MSUfYYSR2AiP42Y8YMlClTBsnJyTh79ixWrlyJI0eO4MaNGzAzM1NvN2LECNSpUwdKpRKvXr3CH3/8AT8/PyxevBiBgYFo0aLFR48thEBkZCQ2bdqENm3a4NChQ2jXrl2WeZo2bYqtW7dmaBswYADq1q2LQYMGqdssLCy08vn/+OMPTJ8+HX369IGNjU229lEoFFi3bh0AIDY2Fj///DNmzpyJ+/fvY/v27Rm2jYyMRMuWLXHr1i1069YNvr6+SE5Oxt69e+Hj44MjR45g+/btMDQ0VO8THR0NT09PXLlyBe3atYO3tzcsLCxw584d7Nq1C2vWrEFqauonM166dAlt2rTBu3fv0LNnT7i6ugIALl++jHnz5uH333/Hr7/+qsGZIqJPEkQkuY0bNwoA4tKlSxnaR48eLQCIHTt2CCGECAoKEgDE7t27Mx0jNDRU2NraChsbG/HixYv/PPabN2+EsbGx8Pb21iirubm58PHx0Wif7FqwYIEAIB4+fJit7X18fIS5uXmGNpVKJerXry9kMpmIiIjI8JqHh4cwMDAQP//8c6ZjjRkzRgAQ8+bNy9Detm1bYWBgIPbs2ZNpn+TkZPHdd999MuPbt29FiRIlhJ2dnbh161am1yMiIsTMmTM/eYzsevfunVaOQ5Tf8bIUUR72oQfm4cOH/7ltzZo1sXTpUsTExGD58uX/ub2NjQ1MTU1hZPT5HbjPnz9Hv379YGdnB4VCgapVq2LDhg2Ztvvpp59QtWpVmJmZoVChQnBzc8OOHTsAANOmTcP3338PAChTpoz6UtOjR480yiKTydC4cWMIIfDgwQN1+4ULF3D8+HH06dMHHTp0yLTf3LlzUb58ecyfPx9JSUkAgIsXL+Lw4cPo378/OnfunGkfhUKBhQsXfjLP6tWr8fz5cyxevBiVKlXK9LqdnR0mT56cIf+0adMybefk5IQ+ffqon3+4ZHj69GkMHToUtra2KFmyJPbs2aNuzyqLTCbDjRs31G23b99Gly5dULhwYZiYmMDNzQ0HDx785GciyutY3BDlYffv3wcAFClSJFvbd+nSBaamplle4oiNjUV0dDRevXqFmzdvYsiQIerLJJ8jMjIS9evXx8mTJ+Hr64tly5ahXLly6N+/P5YuXarebu3atRgxYgSqVKmCpUuXYvr06XBxccHFixcBAF9//TW6d+8OAFiyZAm2bt2KrVu3olixYhpn+lAQFSpUSN126NAhAEDv3r2z3MfIyAje3t54+/Ytzp07BwDqL/levXppnOGDgwcPwtTUFF26dMnxMT5l6NChCAsLw9SpUzF+/Hi0bdsWFhYWCAwMzLRtQEAAqlatimrVqgEAbt68ifr16+PWrVsYP348Fi1aBHNzc3Tq1An79+/XSV6i3MAxN0R5yIcCJDk5GefOncOMGTNgamr60TEx/2ZsbIwKFSqoi6J/cnd3z/BcoVBgw4YNaNWq1WdlnjRpEpRKJa5fv64uwgYPHozu3btj2rRp+Oabb2BqaorDhw+jatWq2L17d5bHqVGjBmrXro2dO3eiU6dOGg1Sjo6OBvD+/B04cAB79+5FtWrVULFiRfU2YWFhAN73cH3Mh9du3boFd3d33Lp1CwBQvXr1bGf5t1u3bqFChQqQy+U5PsanFC5cGKdOncowTqh9+/bYs2cPfvzxR3V7REQETp8+naFXaOTIkShVqhQuXboEhUIB4H2x1LhxY4wbNw5fffWVTjIT6Rp7bojyEHd3dxQrVgyOjo7o1q0bLCwssH//fpQoUSLbx7CwsEB8fHymdn9/f5w4cQInTpzAtm3b0Lx5cwwYMAD79u3LcV4hBPbu3Yv27dtDCIHo6Gj1w8PDA7GxsQgJCQHw/jLYs2fPcOnSpRy/X1YSEhJQrFgxFCtWDOXKlcOYMWPQqFEj/Pzzz5DJZOrtPpwTS0vLjx7rw2txcXEZ/vupff5LXFzcZ+3/XwYOHJihsAEALy8vREVFITg4WN22Z88eqFQqeHl5AQDevHmD3377DV27dkV8fLz67+3169fw8PDAvXv38Pz5c53lJtIl9twQ5SH+/v6oUKECjIyMYGdnh4oVK8LAQLPfQd69e5fll2ndunXh5uamft69e3fUqlULvr6+aNeuXY56Fl69eoWYmBisWbMGa9asyXKbqKgoAMC4ceNw8uRJ1K1bF+XKlUPr1q3h7e2NRo0aafy+/2RiYqK+5PTs2TP88MMPiIqKgqmpaYbtPpyT+Pj4j96J9e8CyMrK6j/3+S9WVlZZFpvaUqZMmUxtnp6esLa2RkBAAFq2bAng/SUpFxcXVKhQAQAQHh4OIQSmTJmCKVOmZHnsqKgojQproryCxQ1RHvLvAkRTaWlpuHv3rnpMxacYGBigefPmWLZsGe7du4eqVatq/H4qlQoA0LNnT/j4+GS5TY0aNQAAlStXxp07d/DLL7/g2LFj2Lt3L1asWIGpU6di+vTpGr/3B4aGhhkuuXl4eKBSpUr45ptvMgyMrVy5Mg4cOIC//voLTZs2zfJYf/31FwCgSpUqAKAeAHz9+nU0adIkR/kqVaqE0NBQpKamftalKaVSmWX7v4s44P0lxw/jZlasWIHIyEicO3cOc+bMUW/z4e9uzJgx8PDwyPLY5cqVy3FeIinxshSRHtmzZw+SkpI++mX1b+np6QDe9/bkRLFixWBpaQmlUgl3d/csH7a2turtzc3N4eXlhY0bN+LJkydo27YtZs+erZ5w75+XkXKqePHiGDVqFA4dOoQLFy6o2z+MW9qyZUuW+ymVSuzYsQOFChVS9ya1b98eALBt27Yc52nfvj2SkpKwd+/ebG1fqFChTJP6paam4uXLlxq9r5eXF6Kjo3Hq1Cns3r0bQgj1JSkAcHZ2BvB+nNbH/u50eTmNSJdY3BDpiWvXruHbb79FoUKFMGzYsP/cPi0tDb/++ivkcjkqV66co/c0NDRE586dsXfv3gy3F3/wzxmTX79+neE1uVyOKlWqQAiBtLQ0AO+LHwCfPWPv8OHDYWZmhnnz5qnbGjZsCHd3d2zcuBG//PJLpn0mTZqEu3fvYuzYserekAYNGsDT0xPr1q3DgQMHMu2TmpqKMWPGfDLL4MGDUbx4cXz33XdZzmYcFRWFWbNmqZ+XLVsWv//+e4Zt1qxZ89Gem49xd3dH4cKFERAQgICAANStWzfDJSxbW1t88cUXWL16dZaFU1azXRPlF7wsRZQPnTlzBsnJyVAqlXj9+jXOnTuHgwcPwtraGvv374e9vX2mfY4ePYrbt28DeP+FumPHDty7dw/jx49Xjy3JiXnz5iEoKAj16tXDwIEDUaVKFbx58wYhISE4efIk3rx5AwBo3bo17O3t0ahRI9jZ2eHWrVtYvnw52rZtq+4h+DBz76RJk9CtWzcYGxujffv26qInu4oUKYK+fftixYoVuHXrlrp427JlC1q2bImOHTvC29sbTZo0QUpKCvbt24fg4GB4eXmp59r5YMuWLWjdujW+/vprtG/fHi1btoS5uTnu3buHXbt24eXLl5+c66ZQoULYv38/2rRpAxcXlwwzFIeEhGDnzp1o0KCBevsBAwZg8ODB6Ny5M1q1aoVr167h+PHjKFq0qEbnwNjYGF9//TV27dqFhISELDP6+/ujcePGqF69OgYOHAhnZ2dERkbi/PnzePbsGa5du6bRexLlGVLOIEhE731sFuF/+zBD8YeHsbGxKFasmGjatKmYPXu2iIqK+uix//kwMTERLi4uYuXKlUKlUmmUNasZiiMjI8WwYcOEo6OjMDY2Fvb29qJly5ZizZo16m1Wr14tmjZtKooUKSIUCoUoW7as+P7770VsbGyGY82cOVOUKFFCGBgY/OdsxVnNUPzB/fv3haGhYaas8fHxYtq0aaJq1arC1NRUWFpaikaNGolNmzZ99FwkJiaKhQsXijp16ggLCwshl8tF+fLlxfDhw0V4ePjHT9Y/vHjxQowaNUpUqFBBmJiYCDMzM+Hq6ipmz56d4RwolUoxbtw4UbRoUWFmZiY8PDxEeHi4KF26dIbPkp2fmRMnTggAQiaTiadPn370PPXu3VvY29sLY2NjUaJECdGuXbssZ2Qmyi9kQnxkpTgiIiKifIhjboiIiEivsLghIiIivcLihoiIiPQKixsiIiLSKyxuiIiISK+wuCEiIiK9UuAm8VOpVHjx4gUsLS21MtU7ERER6Z4QAvHx8XBwcPjPBYULXHHz4sULODo6Sh2DiIiIcuDp06coWbLkJ7cpcMXNh2nenz59+llTzhMREVHuiYuLg6OjY7YWdC1wxc2HS1FWVlYsboiIiPKZ7Awp4YBiIiIi0issboiIiEivsLghIiIivVLgxtxkl1KpRFpamtQxSALGxsYwNDSUOgYREeUQi5t/EUIgIiICMTExUkchCdnY2MDe3p5zIRER5UMsbv7lQ2Fja2sLMzMzfrkVMEIIJCYmIioqCgBQvHhxiRMREZGmWNz8g1KpVBc2RYoUkToOScTU1BQAEBUVBVtbW16iIiLKZzig+B8+jLExMzOTOAlJ7cPPAMddERHlPyxussBLUcSfASKi/IvFDREREekVSYub33//He3bt4eDgwNkMhkOHDjwn/sEBwejdu3aUCgUKFeuHDZt2qTznERERJR/SFrcJCQkoGbNmvD398/W9g8fPkTbtm3RvHlzhIaG4ttvv8WAAQNw/PhxHSfNP86fPw9DQ0O0bds202vBwcGQyWRZ3ubu5OSEpUuXZmgLCgpCmzZtUKRIEZiZmaFKlSr47rvv8Pz5cx2lB5KTkzFs2DAUKVIEFhYW6Ny5MyIjIz+5T2RkJPr06QMHBweYmZnB09MT9+7dy7DNmjVr8MUXX8DKyuqj54CIiPSDpHdLffnll/jyyy+zvf2qVatQpkwZLFq0CABQuXJlnD17FkuWLIGHh4euYuYr69evx/Dhw7F+/Xq8ePECDg4OOTrO6tWrMXToUPj4+GDv3r1wcnLCkydPsGXLFixatAiLFy/WcvL3Ro0ahcOHD2P37t2wtraGr68vvv76a5w7dy7L7YUQ6NSpE4yNjfHzzz/DysoKixcvhru7O8LCwmBubg4ASExMhKenJzw9PTFhwgSdZCfNRL9LQXKaUuoYRKQDciMD2FqaSPb++epW8PPnz8Pd3T1Dm4eHB7799tuP7pOSkoKUlBT187i4OF3Fk9y7d+8QEBCAy5cvIyIiAps2bcLEiRM1Ps6zZ88wYsQIjBgxAkuWLFG3Ozk5oWnTpjrr9YiNjcX69euxY8cOtGjRAgCwceNGVK5cGRcuXED9+vUz7XPv3j1cuHABN27cQNWqVQEAK1euhL29PXbu3IkBAwYAgPpnJDg4WCfZSTOBl59i7J6/pI5BRDpSu5QN9g1tJNn756viJiIiAnZ2dhna7OzsEBcXh6SkJPX8JP80d+5cTJ8+PcfvKYRAkkS/XZoaG2p0105gYCAqVaqEihUromfPnvj2228xYcIEje/82b17N1JTUzF27NgsX7exsfnovl9++SXOnDnz0ddLly6NmzdvZvnalStXkJaWlqGArVSpEkqVKoXz589nWdx8KFxNTP7+DcHAwAAKhQJnz55VFzeUt1x/FgsAMDSQwciAd6YR5XfKxFgIIWBkbgMAMDaU9n6lfFXc5MSECRMwevRo9fO4uDg4Ojpme/+kNCWqTJVmTE/YDA+YybP/V7R+/Xr07NkTAODp6YnY2FicPn0aX3zxhUbve+/ePVhZWeVodt5169YhKSnpo68bGxt/9LWIiAjI5fJMxZOdnR0iIiKy3OdD8TNhwgSsXr0a5ubmWLJkCZ49e4aXL19qnJ9yl2/zchjVqoLUMYjoM/z+++/o3n0AKleujOPHj+eJiU/zVXFjb2+faXBpZGQkrKyssuy1AQCFQgGFQpEb8SR1584d/Pnnn9i/fz8AwMjICF5eXli/fr3GxY0QIsfzvJQoUSJH++WUsbEx9u3bh/79+6Nw4cIwNDSEu7s7vvzySwghcjWLvrv44DXOhUdr5VihT2O0chwiko5KpcLcuXMxdepUqFQqWFlZISoqKk8sW5OvipsGDRrgyJEjGdpOnDiBBg0a6Ow9TY0NETZDmsHKpsbZr37Xr1+P9PT0DAOIhRBQKBRYvnw5rK2tYWVlBeD92JZ/947ExMTA2toaAFChQgXExsbi5cuXGv+Qfs5lKXt7e6SmpiImJiZDvsjISNjb23/0mK6urggNDUVsbCxSU1NRrFgx1KtXD25ubhplp08bvO0K3iZqd8ZmM7n0v+ERkeYiIyPRq1cvnDhxAgDQu3dv+Pv7w8LCQuJk70la3Lx79w7h4eHq5w8fPkRoaCgKFy6svtTw/PlzbNmyBQAwePBgLF++HGPHjkW/fv3w22+/ITAwEIcPH9ZZRplMptGlISmkp6er72Jq3bp1htc6deqEnTt3YvDgwShfvjwMDAxw5coVlC5dWr3NgwcPEBsbiwoV3l8e6NKlC8aPH48ffvghw4DiD/5dfPzT51yWcnV1hbGxMU6dOoXOnTsDeN8j9eTJk2wVsB+Ks3v37uHy5cuYOXPmf+5D2fcuJR0A0Ll2SZgrPr8osTQxwv/csn+JmIjyht9++w09evRAREQEzMzMsGLFCvj4+EgdKyMhoaCgIAEg08PHx0cIIYSPj49o1qxZpn1cXFyEXC4Xzs7OYuPGjRq9Z2xsrAAgYmNjM72WlJQkwsLCRFJSUg4/kTT2798v5HK5iImJyfTa2LFjhZubm/r5oEGDhJOTk/j555/FgwcPxOnTp0X9+vVF/fr1hUqlUm/n7+8vZDKZ6NevnwgODhaPHj0SZ8+eFYMGDRKjR4/W2WcZPHiwKFWqlPjtt9/E5cuXRYMGDUSDBg0ybFOxYkWxb98+9fPAwEARFBQk7t+/Lw4cOCBKly4tvv766wz7vHz5Uly9elWsXbtWABC///67uHr1qnj9+nWWOfLrz4IulZt4WJQe94t4GcNzQlRQpaWlicqVKwsAomrVquLmzZu59t6f+v7+N0mLGynoY3HTrl070aZNmyxfu3jxogAgrl27JoR4/xn9/PxEpUqVhKmpqShTpowYNGiQePXqVaZ9T5w4ITw8PEShQoWEiYmJqFSpkhgzZox48eKFzj5LUlKSGDp0qChUqJAwMzMTX331lXj58mWGbQBkKGqXLVsmSpYsKYyNjUWpUqXE5MmTRUpKSoZ9/Pz8siykP1Yc59efBW1Zd+aBqD/npKg7+4T6UXrcLyxuiEiEhoaKwYMHi4SEhFx9X02KG5kQBWvUZVxcHKytrREbG6seg/JBcnIyHj58iDJlymS4tZgKnoL+s+C59HfcjojP1F7EXI5z41vARIPxYESUv/366694/PgxBg4cKGmOT31//1veHkxCRJL48CvP7K+qoWZJG3V7qSJmLGyICoj09HT4+flh7ty5MDIygqurK2rXri11rGxhcUNUgKhUAlefvkV8cvont/sweLhMEXNUK2GdG9GIKA959uwZunfvjrNnzwIA+vfvjypVqkicKvtY3BAVIDsvPcGk/Teyvb0BZw8mKnCOHDmC3r174/Xr17C0tMS6devQtWtXqWNphMUNUQHyIub9bfpFzOUobvPpsUSOhczg4miTC6mIKK+YNGkS5syZAwCoXbs2AgMDUbZsWYlTaY7FTRYK2BhryoK+/wx0cHGAX/uqUscgojymcOHCAIDhw4djwYIF+XaGfxY3//BhgrnExMSPLudABUNiYiKAT086qIlX8SlYfOIOYpO0O8OvprK6A4qICraEhASYm5sDAEaPHo169eqhcePGEqf6PCxu/sHQ0BA2NjaIiooCAJiZmeV4jSXKn4QQSExMRFRUFGxsbLS2ANyhay+w88+nWjmWNhQ2k0sdgYgklpqairFjx+L48eO4dOkSLCwsIJPJ8n1hA7C4yeTDGkYfChwqmGxsbD65npWmUpUqAICLow06187dxUX/zUxuBM9q2vtsRJT/PHjwAF5eXrh8+TIA4NChQ+jevbvEqbSHxc2/yGQyFC9eHLa2tkhLk/YSAknD2NhYaz02/1bO1gK9Gjjp5NhERNmxd+9e9OvXD3FxcShUqBA2b96M9u3bSx1Lq1jcfIShoaHOvuCIiIhyW3JyMsaMGQN/f38AQMOGDbFz506UKlVK4mTaZyB1ACIiItK977//Xl3YjBs3DsHBwXpZ2AAsboiIiAqESZMmoVq1ajh69CjmzZuntbtB8yIWN0RERHooKSkJO3bsUD+3t7fHtWvX4OnpKWGq3MExN0RERHrm9u3b6Nq1K65fvw4jIyP18gkGBgWjT6NgfEoiIqICYsuWLXB1dcX169dha2urnnW4IGFxQ0REpAcSEhLQr18/+Pj4IDExES1atEBoaCjc3d2ljpbrWNwQERHlczdv3kTdunWxceNGGBgYYPr06fj1119RvHhxqaNJgmNuiIiI8rn79+8jLCwMxYsXx44dO/DFF19IHUlSLG6IiIjyISGEev3DDh06YN26dWjfvj1sbW0lTiY9XpYi0oHnMUm4+uSt+vEiJknqSESkR65du4bGjRvj6dO/F+Tt378/C5v/x54bIi27ExEPz2W/Q4jMr3GNeSL6HEIIrFmzBiNHjkRKSgq+++47BAYGSh0rz2FxQ6Rlj18nQAhAbmgAO2uFut3EyBAdXaRdEZyI8q+4uDgMGjQIAQEBAIC2bdtixYoVEqfKm1jcEOlItRJW2De0kdQxiEgPhISEwMvLC+Hh4TAyMsLcuXMxevToAjMpn6ZY3BB9ps1/PMLtiDj182dvOb6GiLQnKCgInp6eSE1NRalSpRAQEID69etLHStPY3FD9BmevU2E38GbWb5mZaq/i9IRUe6pX78+KlasCGdnZ2zYsKFAzjisKRY3RJ8hOU0FAFAYGWB4i3LqdgMDGdpWL5iTZxHR57t58yYqVaoEQ0NDmJqaIigoCIULF1bf+k2fxuKGSAtM5YbwbVFe6hhElM8JIbB06VKMGzcOU6dOxeTJkwEARYoUkThZ/sLihoiIKA948+YN+vTpg0OHDgEAbty4kWGiPso+DrMmIiKS2B9//AEXFxccOnQIcrkc/v7+2LlzJwubHGJxQ0REJBGVSoUffvgBTZs2xdOnT1GuXDlcuHABQ4cOZWHzGXhZikgD4VHxCHkSo37+Kj5FujBElO/dv38fU6dOhVKpRPfu3bF69WpYWlpKHSvfY3FDlE1CCHRdfQFvElIzvWZsyE5QItJc+fLlsXz5cgghMGDAAPbWaAmLG6JsEgLqwqZxuaIwNvz7H6H2NR2kikVE+YhKpcK8efPg7u6OunXrAgAGDBggcSr9w+KGKAd+7F4Lhc3lUscgonwkMjISvXr1wokTJ7B27VrcuHED5ubmUsfSSyxuiD5iX8gz7PzziXp17ywW+SYiypbffvsNPXr0QEREBExNTeHn58fCRodY3BB9hH9QOO6/SsjUbqkwgpncUIJERJTfKJVKzJw5EzNmzIAQAlWrVkVgYCCqVKkidTS9xuKG6COUqvd9NWNaV0A5Wwt1e+XiVjAxZnFDRJ8WFxeHjh07Ijg4GADQr18//PTTTzAzM5M2WAHA4oYI7++EevomCWkqlbotTfm+uKnvXARuTlyojog0Y2FhAXNzc5ibm2PVqlXo2bOn1JEKDBY3RAAW/noH/kH3pY5BRPlceno60tLSYGpqCgMDA2zevBnR0dGoWLGi1NEKFBY3RABuvYwHAJgaG0Ju9PecNU5FzFDFwUqqWESUjzx79gze3t4oU6YMNm/eDOD9gpdc9DL3sbgh+ofpHauiq5uj1DGIKJ85cuQIevfujdevXyM0NBTTp0+Hk5OT1LEKLBY3VOBEv0vB9gtPkJiarm4Lj3onYSIiyq/S0tIwadIkLFiwAABQu3ZtBAQEsLCRGIsbKnC2nn+MZafuZfmahYL/SxBR9jx58gTdunXD+fPnAQDDhw/HggULoFAoJE5G/JecCpyElPc9NjVLWqOe89/XwotayNGikq1UsYgoH1GpVPD09MStW7dgbW2NDRs24Ouvv5Y6Fv0/FjdUYDUoWxTjv6wkdQwiyocMDAywbNkyTJ06FTt27ECZMmWkjkT/wKWMiYiIsuHBgwc4ceKE+nmrVq1w7tw5FjZ5EIsbIiKi/7B3717UqlULXbp0wf37f8+JZWDAr9G8iH8rREREH5GcnAxfX1906dIFcXFxqFq1KoyNjaWORf+BY24oX4iKT8bVJzFaOdaj14laOQ4R6bd79+7By8sLV69eBQCMHTsWs2bNYnGTD7C4oXzBe+1Frc9FY8h+SyL6iF27dmHQoEGIj49HkSJFsGXLFrRp00bqWJRNLG4oX4iITQYAVHXQzorcFgojfFWrxGcfh4j008WLFxEfH48mTZpgx44dKFmypNSRSAMsbihfWdGjNkoXMZc6BhHpISEEZDIZAGD+/PkoV64cvvnmGxgZ8asyv+HfGOU5p+++wrYLj6FSCXVbUppSwkREpO+2bduGHTt24ODBgzAyMoJcLsewYcOkjkU5xOKG8pwfT93DlcdvM7UbGchgbcqBfESkPQkJCRg+fDg2btwIANi4cSMGDhwocSr6XCxuKM9JU6oAAH0bOaGyvZW6vYK9JWzM5FLFIiI9c/PmTXTt2hVhYWGQyWTw8/NDv379pI5FWiD5/SL+/v5wcnKCiYkJ6tWrhz///POT2y9duhQVK1aEqakpHB0dMWrUKCQnJ+dSWspNTcsXQ9c6juqHi6ON1JGISA8IIbBx40bUqVMHYWFhsLe3x6lTp+Dn5wdDw8+/YYGkJ2lxExAQgNGjR8PPzw8hISGoWbMmPDw8EBUVleX2O3bswPjx4+Hn54dbt25h/fr1CAgIwMSJE3M5ORER5VfTp09Hv379kJSUhFatWuHatWto3ry51LFIiyQtbhYvXoyBAweib9++qFKlClatWgUzMzNs2LAhy+3/+OMPNGrUCN7e3nByckLr1q3RvXv3/+ztISIi+sDLywtWVlaYPXs2jh07BltbW6kjkZZJVtykpqbiypUrcHd3/zuMgQHc3d1x/vz5LPdp2LAhrly5oi5mHjx4gCNHjnxyYqWUlBTExcVleBARUcEhhEBoaKj6eeXKlfHw4UNMnDiRa0PpKckGFEdHR0OpVMLOzi5Du52dHW7fvp3lPt7e3oiOjkbjxo0hhEB6ejoGDx78yctSc+fOxfTp07WanXImISUd+0KeIS45/ZPbRcZxDBURaUdcXBy++eYbBAYGIjg4GE2aNAEAFC5cWOJkpEv56m6p4OBgzJkzBytWrEC9evUQHh6OkSNHYubMmZgyZUqW+0yYMAGjR49WP4+Li4Ojo2NuRaZ/CLz8FNMPhWV7e4Uxf6Miopy7evUqunbtivDwcBgaGuLWrVvq4ob0m2TFTdGiRWFoaIjIyMgM7ZGRkbC3t89ynylTpqBXr14YMGAAAKB69epISEjAoEGDMGnSpCy7FxUKBRQKhfY/AGksLul9j41zMXPUKf3p35ocbExR14m/WRGR5oQQWLFiBUaPHo3U1FSUKlUKu3btQoMGDaSORrlEsuJGLpfD1dUVp06dQqdOnQAAKpUKp06dgq+vb5b7JCYmZipgPty2J4TIahfKg+o7F8Gcr6pLHYOI9FBMTAwGDBiAvXv3AgA6dOiAjRs38jJUASPpZanRo0fDx8cHbm5uqFu3LpYuXYqEhAT07dsXANC7d2+UKFECc+fOBQC0b98eixcvRq1atdSXpaZMmYL27dtzboI8JvpdCoZsu4LIuBR1W0xiqoSJiKggOHDgAPbu3QtjY2P88MMPGDlypHq9KCo4JC1uvLy88OrVK0ydOhURERFwcXHBsWPH1IOMnzx5kqGnZvLkyZDJZJg8eTKeP3+OYsWKoX379pg9e7ZUH4E+4sKD17j0KPMSCgBQhgtfEpGO+Pj44K+//kL37t1Rp04dqeOQRGSigF3PiYuLg7W1NWJjY2FlZfXfO1COHLr2AsN3XkW1ElaY3qGaut3U2BCVi1vyNyki0oo3b95g8uTJmDt3LqytraWOQzqkyfd3vrpbivKuFzFJePw6Uf38XmQ8AMBSYQzX0oWkikVEeuz8+fPo1q0bnjx5gtjYWGzfvl3qSJRHsLihz/b6XQqaLQhCmjJzJyDnxyIibVOpVFi0aBEmTpyI9PR0lC1bFt99953UsSgPYXFDny0iLhlpSgFDAxnKFP17PI2RgQzedUtLmIyI9E10dDR8fHxw5MgRAO/Hbq5Zs4bDDCgDFjekNUUt5Dg5upnUMYhIT4WGhqJdu3Z4/vw5FAoFfvzxRwwcOJBj+CgTFjekscDLT3H+/mv1c97iTUS5oWTJkgCAihUrIjAwEDVq1JA4EeVVOSpunjx5gsePHyMxMRHFihVD1apVOQtwAZGarsLEfdeRrso8vsbGVC5BIiLSZ3FxcepLTkWLFsXx48dRunRpWFhYSJyM8rJsFzePHj3CypUrsWvXLjx79izDjMByuRxNmjTBoEGD0LlzZ66yqsdUQqgLm+89KkJu+P7vWiYDmlUoJmU0ItIzQUFB8Pb2xrx58+Dj4wMAqFq1qsSpKD/IVhUyYsQI1KxZEw8fPsSsWbMQFhaG2NhYpKamIiIiAkeOHEHjxo0xdepU1KhRA5cuXdJ1bsoD+jR0wsCmzhjY1BkDmjijvJ2l1JGISA8olUpMnz4d7u7uiIiIgL+/P1QqldSxKB/JVs+Nubk5Hjx4gCJFimR6zdbWFi1atECLFi3g5+eHY8eO4enTp5wZkoiINPby5Uv07NkTv/32GwCgb9+++Omnn3hFgDSSreLmw9pO2eHp6ZnjMEREVHCdOHECPXv2RFRUFMzNzbFy5Ur06tVL6liUD/FuKSIiktyDBw/w5ZdfQqlUonr16ggMDESlSpWkjkX5VLaKm1q1amV7HoGQkJDPCkRERAWPs7Mzxo0bh9evX2PJkiUwNTWVOhLlY9kqbjp16qTjGEREVNAcPXoUFStWhLOzMwBg1qxZnJCPtCJbxY2fn5+ucxARUQGRlpaGSZMmYcGCBahTpw7Onj0LuVzOwoa0hmNuiIgo1zx58gTdunXD+fPnAQB169bNMG8akTZkq7gpVKhQtivqN2/efFYgyh1/PYvBrMO3kJSq1Gg/Ff8RIqIcOnjwIPr06YO3b9/C2toa69evR+fOnaWORXooW8XN0qVLdRyDctu+kOf482HOC9Ei5nIojDjvBBH9t9TUVIwfPx5LliwBANSpUwe7du1Sj7Uh0rZsFTcfpr0m/aH8/yUUOro4oFOtEhrvX6W4FYwMWdwQ0X8TQuD3338HAHz77beYP38+5HKuRUe681ljbpKTk5GamnFF6A8LnFH+4FTEHM0r2kodg4j0kBACMpkMCoUCgYGBuH79Ojp27Ch1LCoANC5uEhISMG7cOAQGBuL169eZXlcqNRvDQURE+iUlJQVjxoyBjY0NZs6cCeD9PDa8DEW5RePrCmPHjsVvv/2GlStXQqFQYN26dZg+fTocHBywZcsWXWQkIqJ8Ijw8HA0bNsTy5csxZ84chIeHSx2JCiCNi5tDhw5hxYoV6Ny5M4yMjNCkSRNMnjwZc+bMwfbt23WRkYiI8oHAwEDUrl0bISEhKFKkCA4ePIhy5cpJHYsKII2Lmzdv3qi7Fq2srNS3fjdu3Fg9YIyIiAqOpKQkDB48GF5eXoiPj0fjxo0RGhqKtm3bSh2NCiiNixtnZ2c8fPgQAFCpUiUEBgYCeN+jY2Njo9VwRESUtwkh4O7ujtWrV0Mmk2HixIkICgpCyZIlpY5GBZjGxU3fvn1x7do1AMD48ePh7+8PExMTjBo1Ct9//73WAxIRUd4lk8kwcOBAFCtWDMeOHcPs2bNhZMTJ70laGv8Ejho1Sv1nd3d33L59G1euXEG5cuVQo0YNrYYjIqK8JzExEY8fP0blypUBAH369EHHjh1RqFAhiZMRvffZ5XXp0qVRunRpbWQhHbkdEYd+Gy/hbWKaui1VqZIwERHlV2FhYejatStiY2MRGhqKIkWKAAALG8pTNL4sNWLECPz444+Z2pcvX45vv/1WG5lIy87ff40XsclISlOqH0qVgIEMqOrASReJKHs2bdoENzc33Lx5E+np6Xj06JHUkYiypHHPzd69e3Hw4MFM7Q0bNsS8efO4DlUe1rKSLaZ1qKp+bq4wQmFzToFORJ/27t07DBs2TD2Xmbu7O7Zt2wY7OzuJkxFlTePi5vXr17C2ts7UbmVlhejoaK2EIt0wUxjBsbCZ1DGIKB+5fv06unbtitu3b8PAwAAzZszAhAkTYGDAteUo79L4p7NcuXI4duxYpvajR49yam0iIj0zf/583L59Gw4ODggKCsKkSZNY2FCep3HPzejRo+Hr64tXr16hRYsWAIBTp05h0aJFvCRFRKRn/P39YWpqijlz5qBYsWJSxyHKFo2Lm379+iElJQWzZ89WL4jm5OSElStXonfv3loPSEREuefq1avYsWMHfvjhB8hkMlhbW2Pt2rVSxyLSSI5uBR8yZAiGDBmCV69ewdTUFBYWFtrORUREuUgIgZUrV2LUqFFITU1FlSpV0LdvX6ljEeVIji6cpqen4+TJk9i3bx+EEACAFy9e4N27d1oNR0REuhcbG4uuXbti2LBhSE1NRfv27dGxY0epYxHlmMY9N48fP4anpyeePHmClJQUtGrVCpaWlpg/fz5SUlKwatUqXeQkIiIduHTpEry8vPDw4UMYGxtj/vz5+PbbbyGTyaSORpRjGvfcjBw5Em5ubnj79i1MTU3V7V999RVOnTql1XCUMwkp6Xj2NlH9iPnHzMRERB9s2LABjRo1wsOHD+Hk5ISzZ89i1KhRLGwo39O45+bMmTP4448/IJdnnPzNyckJz58/11owypnnMUlotfg0ElOVUkchojyuXLlyUCqV+Prrr7F+/XrY2NhIHYlIKzQublQqFZTKzF+cz549g6WlpVZCUc6FR71TFzYKo7875hRGBmhVhbOJEhV0MTEx6iKmadOmuHjxIlxdXdlbQ3pF4+KmdevWWLp0KdasWQPg/XL37969g5+fH9q0aaP1gJQzVR2scHhEE6ljEFEeoVKpsHjxYsyePRvnz59HpUqVAABubm4SJyPSPo3H3CxatAjnzp1DlSpVkJycDG9vb/Ulqfnz5+siIxERfYbo6Gh06NAB33//PWJiYrB161apIxHplMY9NyVLlsS1a9cQEBCAa9eu4d27d+jfvz969OiRYYAxERFJ7+zZs+jevTuePXsGhUKBZcuWYdCgQVLHItKpHE3iZ2RkhB49eqBHjx7qtpcvX+L777/H8uXLtRaOiIhyRqVSYf78+ZgyZQqUSiUqVKiAwMBA1KxZU+poRDqn0WWpmzdvYvny5VizZg1iYmIAvO/uHDVqFJydnREUFKSLjEREpKFNmzZh4sSJUCqV6NmzJ65cucLChgqMbBc3Bw8eRK1atTBixAgMHjwYbm5uCAoKQuXKlXHr1i3s378fN2/e1GVWIiLKpt69e6NVq1ZYv349tmzZwmVyqEDJdnEza9YsDBs2DHFxcVi8eDEePHiAESNG4MiRIzh27Bg8PT11mZOIiD5BqVRizZo1SE1NBfB++MDx48fRr18/3uZNBU62i5s7d+5g2LBhsLCwwPDhw2FgYIAlS5agTp06usxHRET/ISIiAq1bt8Y333yD8ePHq9tZ1FBBle0BxfHx8bCysgIAGBoawtTUFM7OzjoLRtnz7G0iwqP+XrD0+rNYCdMQUW47efIkevbsicjISJiZmaFWrVpSRyKSnEZ3Sx0/fhzW1tYA3o/EP3XqFG7cuJFhmw4dOmgvHX1SfHIa3BefRnKaKtNrhgb8jY1In6Wnp2P69OmYPXs2hBCoXr06AgMD1ZPzERVkGhU3Pj4+GZ5/8803GZ7LZLIsl2Yg3YhJTENymgoy2fsZiT8wlMnQr3EZCZMRkS49f/4c3t7e+P333wEAAwcOxLJlyzjXGNH/y3Zxo1Jl7h2gvMHEyBC/DOdSC0QFRVJSEq5evQoLCwusWbMG3bt3lzoSUZ6So0n8SBp7rzzDqduR6udc+Zuo4BBCqAcIlytXDoGBgShbtizKly8vcTKivCdbd0tduHAh2wdMTEzkfDc6MvXnGzhyPUL9CL7zCgBQ2FwucTIi0qWnT5+iWbNmOHnypLrN09OThQ3RR2Sr56ZXr15wdnbGgAED0KZNG5ibm2faJiwsDNu2bcPGjRsxf/58VK1aVethC7pU5ftLg997VISVyd9/dfWdi0gViYh07NChQ+jTpw/evHmDYcOGISwsDIaGhlLHIsrTslXchIWFYeXKlZg8eTK8vb1RoUIFODg4wMTEBG/fvsXt27fx7t07fPXVV/j1119RvXp1XecuEBJS0qESQv38wx871y4Je2sTiVIRUW5ITU3FhAkTsHjxYgCAm5sbAgICWNgQZYNMiH98e2bD5cuXcfbsWTx+/BhJSUkoWrQoatWqhebNm6Nw4cK6yqk1cXFxsLa2RmxsrHrenrxo+qGb2HjuUZavXZjQksUNkR579OgRvLy88OeffwIARo4cifnz50OhUEicjEg6mnx/azyg2M3NDW5ubjkO92/+/v5YsGABIiIiULNmTfz000+oW7fuR7ePiYnBpEmTsG/fPrx58walS5fG0qVL0aZNG61lygv+CH+dZXtVBysUs+Q/cET66unTp6hVqxZiYmJgY2ODjRs3olOnTlLHIspXJL1bKiAgAKNHj8aqVatQr149LF26FB4eHrhz5w5sbW0zbZ+amopWrVrB1tYWe/bsQYkSJfD48WPY2NjkfvhcsqlvHTQo+/eYGrmhAadUJ9JjJUuWRPv27XHv3j3s2rULpUuXljoSUb4jaXGzePFiDBw4EH379gUArFq1CocPH8aGDRsyrI/ywYYNG/DmzRv88ccfMDY2BgA4OTnlZuRcJzc0gMKI19iJ9Nn9+/dhY2ODIkWKQCaTYdWqVTA2Nlb/O0dEmsn2wpnalpqaiitXrsDd3f3vMAYGcHd3x/nz57Pc5+DBg2jQoAGGDRsGOzs7VKtWDXPmzPnkrMgpKSmIi4vL8CAiyisCAwNRq1Yt9O3bFx+GQJqZmbGwIfoMkhU30dHRUCqVsLOzy9BuZ2eHiIiILPd58OAB9uzZA6VSiSNHjmDKlClYtGgRZs2a9dH3mTt3LqytrdUPR0dHrX4OIqKcSE5OxpAhQ+Dl5YX4+Hi8efOGv3wRaclnFTfJycnaypEtKpUKtra2WLNmDVxdXeHl5YVJkyZh1apVH91nwoQJiI2NVT+ePn2ai4mJiDK7e/cu6tevr/63a8KECQgODlYvTExEn0fj4kalUmHmzJkoUaIELCws8ODBAwDAlClTsH79+mwfp2jRojA0NERkZGSG9sjISNjb22e5T/HixVGhQoUM8zxUrlwZERERSE1NzXIfhUIBKyurDA8iIqls374dtWvXxrVr11CsWDEcO3YMc+bMgZERV8Mh0haNi5tZs2Zh06ZN+OGHHyCX/z3tf7Vq1bBu3bpsH0cul8PV1RWnTp1St6lUKpw6dQoNGjTIcp9GjRohPDw8wyKed+/eRfHixTNkISLKixITEzF58mQkJCTgiy++QGhoKDw8PKSORaR3NC5utmzZgjVr1qBHjx4ZelBq1qyJ27dva3Ss0aNHY+3atdi8eTNu3bqFIUOGICEhQX33VO/evTFhwgT19kOGDMGbN28wcuRI3L17F4cPH8acOXMwbNgwTT8GEVGuMzMzQ0BAAPz8/HDy5Ek4ODhIHYlIL2ncD/r8+XOUK1cuU7tKpUJaWppGx/Ly8sKrV68wdepUREREwMXFBceOHVMPMn7y5AkMDP6uvxwdHXH8+HGMGjUKNWrUQIkSJTBy5EiMGzdO049BRJQrNm/eDKVSiX79+gEA6tat+8mJSono82lc3FSpUgVnzpzJNLHUnj17UKtWLY0D+Pr6wtfXN8vXgoODM7U1aNBAo1XKiYik8O7dOwwbNgxbtmyBQqFA48aNUaFCBaljERUIGhc3U6dOhY+PD54/fw6VSoV9+/bhzp072LJlC3755RddZCQiyleuX7+Orl274vbt2zAwMMDkyZNRtmxZqWMRFRgaj7np2LEjDh06hJMnT8Lc3BxTp07FrVu3cOjQIbRq1UoXGYmI8gUhBNatW4e6devi9u3bcHBwwG+//YbJkydzNW+iXJSjew+bNGmCEydOaDsLEVG+JYSAj48Ptm7dCgDw9PTEli1bUKxYMYmTERU8GvfcODs74/XrzCtWx8TEwNnZWSuhiIjyG5lMhvLly8PQ0BDz5s3D4cOHWdgQSUTjnptHjx5luZZTSkoKnj9/rpVQRET5gRACMTExKFSoEABg4sSJ6NChA2rWrClxMqKCLdvFzcGDB9V/Pn78eIZpwpVKJU6dOqX3K3QTEX0QGxuLgQMH4s6dO7hw4QJMTU1haGjIwoYoD8h2cdOpUycA77tefXx8MrxmbGwMJycnLFq0SKvhiIjyosuXL8PLywsPHjyAkZERzp07B3d3d6ljEdH/y3Zx82HJgzJlyuDSpUsoWrSozkIREeVFQgj89NNPGDNmDNLS0lC6dGkEBASgXr16Ukcjon/QeMzNw4cPdZGDiChPe/v2Lfr164cDBw4AeN+bvWHDBvV4GyLKO3J0K3hCQgJOnz6NJ0+eZFqNe8SIEVoJRkSUlwwdOhQHDhyAXC7HwoUL4evrC5lMJnUsIsqCxsXN1atX0aZNGyQmJiIhIQGFCxdGdHQ0zMzMYGtry+KGiPTS/Pnzcf/+faxcuRKurq5SxyGiT9B4nptRo0ahffv2ePv2LUxNTXHhwgU8fvwYrq6uWLhwoS4yEhHlutevX2PTpk3q56VKlcLFixdZ2BDlAxoXN6Ghofjuu+9gYGAAQ0NDpKSkwNHRET/88AMmTpyoi4xERLnq3LlzcHFxQd++fXHo0CF1Oy9DEeUPGhc3xsbGMDB4v5utrS2ePHkCALC2tsbTp0+1m46IKBepVCrMmzcPzZo1w7Nnz1C+fHk4OjpKHYuINKTxmJtatWrh0qVLKF++PJo1a4apU6ciOjoaW7duRbVq1XSRkYhI56KiotC7d28cP34cAODt7Y1Vq1bB0tJS4mREpCmNe27mzJmD4sWLAwBmz56NQoUKYciQIXj16hVWr16t9YBERLp2+vRpuLi44Pjx4zAxMcG6deuwbds2FjZE+ZTGPTdubm7qP9va2uLYsWNaDURElNtevnyJly9fonLlyggMDGQvNFE+p3HPzceEhISgXbt22jocEZFOCSHUf+7WrRs2b96MS5cusbAh0gMaFTfHjx/HmDFjMHHiRDx48AAAcPv2bXTq1Al16tRRL9FARJSXnTp1CrVr10ZERIS6rXfv3jA3N5cwFRFpS7aLm/Xr1+PLL7/Epk2bMH/+fNSvXx/btm1DgwYNYG9vjxs3buDIkSO6zEpE9FmUSiWmTp2KVq1aITQ0FNOnT5c6EhHpQLaLm2XLlmH+/PmIjo5GYGAgoqOjsWLFCly/fh2rVq1C5cqVdZmTiOizvHjxAi1btsTMmTMhhMCAAQOwaNEiqWMRkQ5ke0Dx/fv38b///Q8A8PXXX8PIyAgLFixAyZIldRaOiEgbjh8/jp49eyI6OhoWFhZYvXo1vL29pY5FRDqS7eImKSkJZmZmAN7P0qlQKNS3hBMR5VW7d+9G165dAQA1a9ZEYGAgKlSoIHEqItIljW4FX7duHSwsLAAA6enp2LRpE4oWLZphGy6cSUR5iaenJypUqAB3d3csWrQIJiYmUkciIh3LdnFTqlQprF27Vv3c3t4eW7duzbCNTCZjcUNEkrtw4QLq1asHmUwGS0tLXLp0CVZWVlLHIqJcku3i5tGjRzqMQUT0+VJTUzFx4kQsWrQIixcvxqhRowCAhQ1RAaPxDMVERHnRo0eP0K1bN1y8eBEA8Pz5c4kTEZFUWNzkAclpSpx/8Bqp6X9PghifnCZhIqL85cCBA+jbty9iYmJgY2ODjRs3olOnTlLHIiKJsLjJA+Yfu42N5x5l+ZqBgSx3wxDlIykpKRg7dix+/PFHAEC9evWwa9cuODk5SRuMiCTF4iYPiIhNBgA4FjaFreXfd3I4FjJFrVI2EqUiyvvCwsKwYsUKAMB3332HOXPmQC6XS5yKiKTG4iYPGdS0LHrVLy11DKJ8o1atWvjpp59QsmRJLtxLRGo5WhX8/v37mDx5Mrp3746oqCgAwNGjR3Hz5k2thiMi+qfk5GSMHDkSf/31l7pt8ODBLGyIKAONi5vTp0+jevXquHjxIvbt24d3794BAK5duwY/Pz+tByQiAoC7d++ifv36+PHHH+Hl5YX09HSpIxFRHqVxcTN+/HjMmjULJ06cyHBtu0WLFrhw4YJWwxERAcCOHTvg6uqKa9euoVixYli6dCmMjHhVnYiypnFxc/36dXz11VeZ2m1tbREdHa2VUEREAJCYmIiBAweiR48eePfuHZo1a4bQ0FB4eHhIHY2I8jCNixsbGxu8fPkyU/vVq1dRokQJrYQiIoqIiEC9evWwbt06yGQyTJ06FSdPnoSDg4PU0Ygoj9O4uOnWrRvGjRuHiIgIyGQyqFQqnDt3DmPGjEHv3r11kZGICqBixYrB1tYWdnZ2OHHiBKZPn85LUUSULRr/SzFnzhwMGzYMjo6OUCqVqFKlCpRKJby9vTF58mRdZCSiAiIhIQGGhoYwMTGBoaEhtm/fDuD9Qr1ERNmlcXEjl8uxdu1aTJkyBTdu3MC7d+9Qq1YtlC9fXhf5iKiAuHHjBrp27YpmzZph5cqVAFjUEFHOaFzcnD17Fo0bN0apUqVQqlQpXWQiogJECIENGzbA19cXycnJiI2NxaxZs1CkSBGpoxFRPqXxmJsWLVqgTJkymDhxIsLCwnSRiYgKiPj4ePTq1QsDBgxAcnIyPDw8EBoaysKGiD6LxsXNixcv8N133+H06dOoVq0aXFxcsGDBAjx79kwX+YhIT127dg1ubm7Yvn07DA0NMXfuXBw5cgTFihWTOhoR5XMaFzdFixaFr68vzp07h/v37+N///sfNm/eDCcnJ7Ro0UIXGYlIz6SkpKBNmza4e/cuSpYsidOnT2P8+PEwMMjRijBERBl81r8kZcqUwfjx4zFv3jxUr14dp0+f1lYuItJjCoUCK1euRLt27RAaGopGjRpJHYmI9EiOi5tz585h6NChKF68OLy9vVGtWjUcPnxYm9mISI9cuXIFJ0+eVD/v0KEDDh48yPE1RKR1Gt8tNWHCBOzatQsvXrxAq1atsGzZMnTs2BFmZma6yEdE+ZwQAsuXL8eYMWNgYWGB0NBQODo6AgBkMpnE6YhIH2lc3Pz+++/4/vvv0bVrVxQtWlQXmYhIT7x9+xb9+/fH/v37AQBNmzaFhYWFxKmISN9pXNycO3dOFzmISM9cvHgR3bp1w6NHjyCXy7Fw4UL4+vqyt4aIdC5bxc3Bgwfx5ZdfwtjYGAcPHvzkth06dNBKMCLKn4QQWLJkCcaNG4f09HQ4OzsjMDAQrq6uUkcjogIiW8VNp06dEBERAVtbW3Tq1Omj28lkMiiVSm1lI6J8SCaT4fbt20hPT8f//vc/rF27FtbW1lLHIqICJFvFjUqlyvLPREQfqFQq9Tw1y5YtQ7NmzeDt7c3LUESU6zS+FXzLli1ISUnJ1J6amootW7ZoJRQR5R8qlQrz589Hu3bt1L/8mJqaokePHixsiEgSGhc3ffv2RWxsbKb2+Ph49O3bVyuh9F26UoXU9L8fKiGkjkSUI69evULbtm0xfvx4HD16FD///LPUkYiINL9bSgiR5W9jz54943X1bPj97it8s/UKktI4Nonyt99//x3du3fHixcvYGJiguXLl39yTB4RUW7JdnFTq1YtyGQyyGQytGzZEkZGf++qVCrx8OFDeHp66iSkPrn48HWWhY2Z3BA1S7I4pLxPqVRi7ty58PPzg0qlQuXKlREYGIhq1apJHY2ICIAGxc2H38hCQ0Ph4eGRYSIuuVwOJycndO7cWesB9VWPeqUw1rOS+rnCyAAmxoYSJiLKnqFDh2LNmjUAgD59+mD58uUwNzeXOBUR0d+yXdz4+fkBAJycnODl5QUTExOthfD398eCBQsQERGBmjVr4qeffkLdunX/c79du3ahe/fu6NixIw4cOKC1PLlBbmQAa1NjqWMQaWzIkCHYs2cPlixZgt69e0sdh4goE40HFPv4+Gi1sAkICMDo0aPh5+eHkJAQ1KxZEx4eHoiKivrkfo8ePcKYMWPQpEkTrWUhosyUSiXOnz+vfu7i4oLHjx+zsCGiPCtbxU3hwoURHR0NAChUqBAKFy780YemFi9ejIEDB6Jv376oUqUKVq1aBTMzM2zYsOGj+yiVSvTo0QPTp0+Hs7Ozxu9JRNnz4sULtGzZEs2aNcOlS5fU7VwfiojysmxdllqyZAksLS3Vf9bW3BWpqam4cuUKJkyYoG4zMDCAu7t7ht8U/23GjBmwtbVF//79cebMGa1kIaKMjh8/jl69euHVq1ewsLDAixcvpI5ERJQt2SpufHx81H/u06eP1t48OjoaSqUSdnZ2Gdrt7Oxw+/btLPc5e/Ys1q9fj9DQ0Gy9R0pKSoZJB+Pi4nKcl6ggSE9Px5QpUzBv3jwAQM2aNREYGIgKFSpInIyIKHs0HnMTEhKC69evq5///PPP6NSpEyZOnIjU1FSthvu3+Ph49OrVC2vXrkXRokWztc/cuXNhbW2tfjg6Ouo0I1F+9vTpU3zxxRfqwmbo0KG4cOECCxsiylc0Lm6++eYb3L17FwDw4MEDeHl5wczMDLt378bYsWM1OlbRokVhaGiIyMjIDO2RkZGwt7fPtP39+/fx6NEjtG/fHkZGRjAyMsKWLVtw8OBBGBkZ4f79+5n2mTBhAmJjY9WPp0+fapSRqCDZt28fzp07BysrKwQGBsLf31+rNxAQEeUGjWcovnv3LlxcXAAAu3fvRrNmzbBjxw6cO3cO3bp1w9KlS7N9LLlcDldXV5w6dUo9j45KpcKpU6fg6+ubaftKlSpl6DUCgMmTJyM+Ph7Lli3LsldGoVBAoVBkOxNRQTZ8+HC8ePECgwYNQtmyZaWOQ0SUIzlafuHD4ngnT55Eu3btAACOjo7qO6o0MXr0aPj4+MDNzQ1169bF0qVLkZCQoF6nqnfv3ihRogTmzp0LExOTTLOg2tjYAABnRyXKgcePH2PKlClYsWIFLCwsYGBggPnz50sdi4jos2hc3Li5uWHWrFlwd3fH6dOnsXLlSgDAw4cPMw0Mzg4vLy+8evUKU6dORUREBFxcXHDs2DH1sZ48eQIDA42vnhHRf/j555/Rp08fxMTEwMLCAitWrJA6EhGRVmhc3CxduhQ9evTAgQMHMGnSJJQrVw4AsGfPHjRs2DBHIXx9fbO8DAUAwcHBn9x306ZNOXpPooIqNTUVY8eOxbJlywAAdevW1Xi8HBFRXqZxcVOjRo1M414AYMGCBTA05NpIRHnZh5sALl++DAD47rvvMGfOHMjlcomTERFpj8bFzQdXrlzBrVu3AABVqlRB7dq1tRaKiLQvODgYHTt2RFxcHAoXLozNmzerx8wREekTjYubqKgoeHl54fTp0+rBvDExMWjevDl27dqFYsWKaTsjEWlBxYoVYWJigurVq2Pnzp2c84mI9JbGI3WHDx+Od+/e4ebNm3jz5g3evHmDGzduIC4uDiNGjNBFRiLKoX/ewVi8eHGcPn0aQUFBLGyISK9pXNwcO3YMK1asQOXKldVtVapUgb+/P44eParVcESUczt37oSzszP27NmjbqtUqRKMjY0lTEVEpHsaFzcqlSrLfxyNjY3V898QkXSSkpIwaNAgeHt7Iz4+Hlu2bJE6EhFRrtK4uGnRogVGjhyZYYXg58+fY9SoUWjZsqVWwxGRZm7fvo169eph7dq1kMlkmDJlCvbt2yd1LCKiXKVxcbN8+XLExcXByckJZcuWRdmyZVGmTBnExcXhp59+0kVGIsqGLVu2wNXVFdevX4ednR1+/fVXzJgxA0ZGOb4pkogoX9L4Xz1HR0eEhITg1KlT6lvBK1euDHd3d62HI6LsCQkJgY+PD4D3vavbt2/PcvFZIqKCQKPiJiAgAAcPHkRqaipatmyJ4cOH6yoXEWmgdu3a+O6772BtbY2JEydyQk0iKtCyXdysXLkSw4YNQ/ny5WFqaop9+/bh/v37WLBggS7zEVEWhBDYsmULWrZsiZIlSwIAFi5cKHEqIqK8IdtjbpYvXw4/Pz/cuXMHoaGh2Lx5MxfaI5JAfHw8evXqhT59+qB79+5IT0+XOhIRUZ6S7eLmwYMH6mv6AODt7Y309HS8fPlSJ8GIKLNr167Bzc0N27dvh6GhIdq2bQsDA43vCyAi0mvZviyVkpICc3Nz9XMDAwPI5XIkJSXpJBgR/U0IgTVr1mDkyJFISUlByZIlsWvXLjRq1EjqaEREeY5GA4qnTJkCMzMz9fPU1FTMnj0b1tbW6rbFixdrLx0RIT4+HgMGDEBgYCAAoF27dti0aROKFCkicTIiorwp28VN06ZNcefOnQxtDRs2xIMHD9TPZTKZ9pIREQDA0NAQYWFhMDIywrx58zB69Gj+v0ZE9AnZLm6Cg4N1GIOI/kkIASEEDAwMYGZmhsDAQMTGxqJ+/fpSRyMiyvM4EpEoj4mJiUGXLl0wf/58dVvlypVZ2BARZROLG6I85M8//0StWrWwb98+zJw5E5GRkVJHIiLKd1jcEOUBQggsWbIEjRs3xqNHj+Ds7Izff/8ddnZ2UkcjIsp3uKIekcTevHmDPn364NChQwCALl26YN26dRnuQiQiouxjcUMkodTUVNSvXx/37t2DQqHAkiVLMHjwYN4NRUT0GXJ0WerMmTPo2bMnGjRogOfPnwMAtm7dirNnz2o1HJG+k8vl+Pbbb1G+fHlcuHABQ4YMYWFDRPSZNC5u9u7dCw8PD5iamuLq1atISUkBAMTGxmLOnDlaD0ikb6KjoxEWFqZ+PmTIEISGhsLFxUW6UEREekTj4mbWrFlYtWoV1q5dC2NjY3V7o0aNEBISotVwRPrmzJkzqFmzJtq3b4/Y2FgA7ye//OfM30RE9Hk0Lm7u3LmDpk2bZmq3trZGTEyMNjIR6R2VSoXZs2fjiy++wIsXLyCXy/Hq1SupYxER6SWNixt7e3uEh4dnaj979iycnZ21EopIn0RGRsLT0xOTJ0+GSqWCj48PLl++jHLlykkdjYhIL2lc3AwcOBAjR47ExYsXIZPJ8OLFC2zfvh1jxozBkCFDdJGRKN/67bff4OLighMnTsDMzAybNm3Cpk2bYG5uLnU0IiK9pfGt4OPHj4dKpULLli2RmJiIpk2bQqFQYMyYMRg+fLguMhLlW0uWLEFERASqVq2KwMBAVKlSRepIRER6T+PiRiaTYdKkSfj+++8RHh6Od+/eoUqVKrCwsNBFPqJ8bePGjZg/fz6mT5/OQcNERLkkx5P4yeVy/hZK9C+//vorfv31VyxcuBAAULRoUSxYsEDiVEREBYvGxU3z5s0/OcnYb7/99lmBiPKj9PR0+Pn5Ye7cuRBCoGHDhvj666+ljkVEVCBpXNz8e6KxtLQ0hIaG4saNG/Dx8dFWLqJ849mzZ/D29saZM2cAAIMHD8aXX34pcSoiooJL4+JmyZIlWbZPmzYN7969++xARPnJkSNH0Lt3b7x+/RqWlpZYt24dunbtKnUsIqICLUdrS2WlZ8+e2LBhg7YOR5TnzZkzB23btsXr16/h6uqKq1evsrAhIsoDtFbcnD9/HiYmJto6HFGe5+rqCplMhuHDh+PcuXMoW7as1JGIiAg5uCz170GSQgi8fPkSly9fxpQpU7QWjCgvioqKgq2tLQDAw8MDN2/eROXKlSVORURE/6Rxz421tXWGR+HChfHFF1/gyJEj8PPz00VGIsmlpqZi1KhRqFixIh48eKBuZ2FDRJT3aNRzo1Qq0bdvX1SvXh2FChXSVSaiPOXhw4fw8vLCpUuXAABHjx7FsGHDJE5FREQfo1HPjaGhIVq3bs3Vv6nA2Lt3L2rVqoVLly6hcOHCOHjwIAsbIqI8TuPLUtWqVcvQLU+kj5KTk+Hr64suXbogNjYWDRs2xNWrV9G+fXupoxER0X/QuLiZNWsWxowZg19++QUvX75EXFxchgeRPvjxxx/h7+8PABg3bhyCg4NRqlQpiVMREVF2ZHvMzYwZM/Ddd9+hTZs2AIAOHTpkWIZBCAGZTAalUqn9lES5bOTIkQgKCsKIESM42zARUT6T7eJm+vTpGDx4MIKCgnSZh0gSSUlJ8Pf3x7fffgsjIyMoFAocPXpU6lhERJQD2S5uhBAAgGbNmuksDJEUbt++ja5du+L69euIiYnBrFmzpI5ERESfQaMxN59aDZwoP9q6dSvc3Nxw/fp12NnZ4YsvvpA6EhERfSaN5rmpUKHCfxY4b968+axARLkhISEBw4cPx8aNGwEALVq0wPbt22Fvby9xMiIi+lwaFTfTp0+HtbW1rrLoncTUdKwMvo/odynqtmtPYyVMRABw69YtdOnSBWFhYTAwMICfnx8mTZoEQ0NDqaMREZEWaFTcdOvWTb2uDv23oNuv8NNv4Vm+ZmVinMtp6AOVSoWHDx+iePHi2LFjBy9FERHpmWwXNxxvo7mktPe3xTsVMUMX15LqdjO5ETrXLvmx3UgHlEqlumematWq2L9/P2rVqsVinYhID2l8txRprnQRc/i2KC91jALr2rVr8Pb2xurVq9G4cWMA71f0JiIi/ZTtu6VUKhV/y6V8RQiB1atXo169eggLC8P333/PIp2IqADQePkFovwgLi4O3bt3x+DBg5GSkoI2bdrg0KFDvLxKRFQAsLghvRMSEgJXV1cEBATAyMgICxYswKFDh1C0aFGpoxERUS7Q6G4porzuxo0baNCgAVJTU1GqVCns2rULDRo0kDoWERHlIhY3OhIRm4xdfz4BAMiN2EGWW6pWrYp27dohPT0dGzduROHChaWOREREuSxPfOv6+/vDyckJJiYmqFevHv7888+Pbrt27Vo0adIEhQoVQqFCheDu7v7J7aUQfCcKbX48g8uP38JcbogBjctIHUmvXb58GbGx7ydHlMlk2LZtGw4cOMDChoiogJK8uAkICMDo0aPh5+eHkJAQ1KxZEx4eHoiKispy++DgYHTv3h1BQUE4f/48HB0d0bp1azx//jyXk2eWplRh3tHb6LPxEt4kpKJKcSv8MqIJ6jkXkTqaXhJCYMmSJWjYsCEGDRqkvhPK1NSUA4eJiAowmZD43th69eqhTp06WL58OYD3t5w7Ojpi+PDhGD9+/H/ur1QqUahQISxfvhy9e/f+z+3j4uJgbW2N2NhYWFlZfXb+D1QqAe91F3Dhwfu1tXo3KI2JbSrDxJhT+uvCmzdv0LdvXxw8eBAA0KVLF2zbtg0KhULiZEREpAuafH9L2nOTmpqKK1euwN3dXd1mYGAAd3d3nD9/PlvHSExMRFpamuSXIG68iMWFB28gNzLAih61MaNjNRY2OnL+/Hm4uLjg4MGDkMvl8Pf3R2BgIAsbIiICIPGA4ujoaCiVStjZ2WVot7Ozw+3bt7N1jHHjxsHBwSFDgfRPKSkpSEn5e+HKuLi4nAf+hHTV+w4weysTtKleXCfvUdCpVCosXLgQEydOhFKpRLly5RAYGIhatWpJHY2IiPIQycfcfI558+Zh165d2L9/P0xMTLLcZu7cubC2tlY/HB0dczklaUtMTAyWLVsGpVKJ7t27IyQkhIUNERFlImlxU7RoURgaGiIyMjJDe2RkJOzt7T+578KFCzFv3jz8+uuvqFGjxke3mzBhAmJjY9WPp0+faiU75b7ChQtj586dWLNmDbZv3w5LS0upIxERUR4kaXEjl8vh6uqKU6dOqdtUKhVOnTr1yYnXfvjhB8ycORPHjh2Dm5vbJ99DoVDAysoqw4PyB5VKhdmzZ2Pbtm3qtqZNm2LgwIG8G4qIiD5K8kn8Ro8eDR8fH7i5uaFu3bpYunQpEhIS0LdvXwBA7969UaJECcydOxcAMH/+fEydOhU7duyAk5MTIiIiAAAWFhawsLCQ7HOQdkVGRqJXr144ceIEzMzM0Lx5c5QoUULqWERElA9IXtx4eXnh1atXmDp1KiIiIuDi4oJjx46pBxk/efIEBgZ/dzCtXLkSqamp6NKlS4bj+Pn5Ydq0abkZnXQkKCgI3t7eiIiIgKmpKZYvXw4HBwepYxERUT4heXEDAL6+vvD19c3yteDg4AzPHz16pPtAJAmlUolZs2ZhxowZUKlUqFq1KgIDA1GlShWpoxERUT6SJ4obovT0dHh6eqrHX/Xv3x8//vgjzMzMJE5GRET5Tb6+FZz0h5GREerUqQNzc3Ns27YN69atY2FDREQ5wuKGJJOeno5Xr16pn8+YMQPXrl1Djx49JExFRET5HYsbksSzZ8/QvHlztG3bFqmpqQAAY2NjlC1bVuJkRESU37G4oVx35MgRuLi44OzZs7h9+zZu3LghdSQiItIjLG4o16SlpWHs2LFo27YtXr9+jdq1ayMkJAS1a9eWOhoREekR3i1FueLx48fo1q0bLly4AAAYPnw4FixYwJW8iYhI61jcUK4YMGAALly4AGtra2zYsAFff/211JGIiEhP8bIU5YqVK1fC3d0dV69eZWFDREQ6xeKGdOLhw4dYt26d+nm5cuVw4sQJlClTRsJURERUEPCyFGnd3r170b9/f8TFxcHJyQnu7u5SRyIiogKEPTekNcnJyfD19UWXLl0QGxuL+vXro3z58lLHIiKiAobFDWlFeHg4GjZsCH9/fwDA2LFjcfr0aZQuXVriZEREVNDwshR9tt27d6N///6Ij49HkSJFsGXLFrRp00bqWEREVECxuKHP9u7dO8THx6NJkybYsWMHSpYsKXUkIiIqwFjcUI6kp6fDyOj9j0+fPn1gYWGBr776St1GREQkFY65IY1t3boVNWrUwOvXrwEAMpkM//vf/1jYEBFRnsDihrItISEB/fr1Q+/evXHr1i38+OOPUkciIiLKhL9qU7bcvHkTXbt2RVhYGGQyGfz8/DB58mSpYxEREWXC4oY+SQiBTZs2YdiwYUhKSoK9vT127NiB5s2bSx2NiIgoS7wsRZ+0YsUK9OvXD0lJSWjVqhVCQ0NZ2BARUZ7G4oY+qUePHihXrhxmz56NY8eOwc7OTupIREREn8TLUpSBEAInT56Eu7s7ZDIZbGxscP36dZiYmEgdjYiIKFvYc0NqcXFx8Pb2RuvWrbF27Vp1OwsbIiLKT9hzQwCAq1evomvXrggPD4eRkRGSkpKkjkRERJQjLG4KOCEEVqxYgdGjRyM1NRWlSpXCrl270KBBA6mjERER5QiLmwIsJiYGAwYMwN69ewEAHTp0wMaNG1G4cGGJkxEREeUcx9wUYNevX8f+/fthbGyMJUuW4MCBAyxsiIgo32PPTQHWpEkTLF++HG5ubqhTp47UcYiIiLSCPTcFyJs3b+Dt7Y07d+6o24YMGcLChoiI9Ap7bgqI8+fPo1u3bnjy5AnCw8Nx8eJFyGQyqWMRERFpHXtu9JxKpcKCBQvQtGlTPHnyBGXLlsWqVatY2BARkd5iz40ei46Oho+PD44cOQIA8PLywpo1a2BlZSVxMiIiIt1hcaOnwsPD8cUXX+D58+cwMTHBsmXLMHDgQPbYEBGR3mNxo6dKly6N0qVLw8LCAoGBgahRo4bUkYiIiHIFixs98urVK1hbW0Mul8PY2Bh79uyBpaUlLCwspI5GRESUazigWE8EBQWhRo0amDhxorqtePHiLGyIiKjAYXGTzymVSkyfPh3u7u6IiIjAsWPHkJiYKHUsIiIiybC4ycdevnyJ1q1bY9q0aVCpVOjXrx/+/PNPmJmZSR2NiIhIMhxzk0+dOHECPXv2RFRUFMzNzbFy5Ur06tVL6lhERESSY3GTD8XExOB///sfYmNjUb16dQQGBqJSpUpSxyIiIsoTWNzkQzY2Nli1ahWCgoKwdOlSmJqaSh2JiIgoz2Bxk08cPXoUJiYmaN68OQCgW7du6Natm8SpiIiI8h4OKM7j0tLSMG7cOLRp0wbdu3dHZGSk1JGIiIjyNPbc5GFPnjxBt27dcP78eQBAly5dYG1tLXEqIiKivI3FTR518OBB9OnTB2/fvoW1tTXWr1+Pzp07Sx2LiIgoz+NlqTxGqVRi9OjR6NixI96+fYs6deogJCSEhQ0REVE2sbjJYwwMDBAVFQUA+Pbbb3H27Fk4OztLnIqIiCj/4GWpPCI9PR1GRkaQyWRYuXIlevTogS+//FLqWERERPkOe24klpKSguHDh6Nz584QQgAALC0tWdgQERHlEHtuJBQeHg4vLy+EhIQAAM6ePYsmTZpInIqIiCh/Y8+NRAICAlC7dm2EhISgSJEi+OWXX1jYEBERaQGLm1yWlJSEwYMHo1u3boiPj0fjxo0RGhqKtm3bSh2NiIhIL7C4yWXdunXD6tWrIZPJMHHiRAQFBaFkyZJSxyIiItIbHHOTyyZOnIgrV65gw4YNaN26tdRxiIiI9A6LGx1LTEzEpUuX0KxZMwBAvXr1cP/+fSgUComTERER6SdeltKhsLAw1K1bF56envjrr7/U7SxsiIiIdCdPFDf+/v5wcnKCiYkJ6tWrhz///POT2+/evRuVKlWCiYkJqlevjiNHjuRS0uwRQmDjxo1wc3PDzZs3YWNjg7i4OKljERERFQiSFzcBAQEYPXo0/Pz8EBISgpo1a8LDw0O9BMG//fHHH+jevTv69++Pq1evolOnTujUqRNu3LiRy8mzpkxJgo+PD/r164ekpCS0atUKoaGhaNy4sdTRiIiICgSZ+DAtrkTq1auHOnXqYPny5QAAlUoFR0dHDB8+HOPHj8+0vZeXFxISEvDLL7+o2+rXrw8XFxesWrXqP98vLi4O1tbWiI2NhZWVldY+R8iTt2g3bTtiflmApFdPYGBggBkzZmDChAkwMJC8hiQiIsrXNPn+lvRbNzU1FVeuXIG7u7u6zcDAAO7u7jh//nyW+5w/fz7D9gDg4eHx0e1TUlIQFxeX4aErifcuIOnVEzg4OCAoKAiTJk1iYUNERJTLJP3mjY6OhlKphJ2dXYZ2Ozs7REREZLlPRESERtvPnTsX1tbW6oejo6N2wv+LDIBtk25wcu+F0NBQNG3aVCfvQ0RERJ+m990KEyZMQGxsrPrx9OlTnbxPrVKFcHdOOzw8sQXFihXTyXsQERHRf5N0npuiRYvC0NAQkZGRGdojIyNhb2+f5T729vYaba9QKHjrNRERUQEiac+NXC6Hq6srTp06pW5TqVQ4deoUGjRokOU+DRo0yLA9AJw4ceKj2xMREVHBIvkMxaNHj4aPjw/c3NxQt25dLF26FAkJCejbty8AoHfv3ihRogTmzp0LABg5ciSaNWuGRYsWoW3btti1axcuX76MNWvWSPkxiIiIKI+QvLjx8vLCq1evMHXqVERERMDFxQXHjh1TDxp+8uRJhjuOGjZsiB07dmDy5MmYOHEiypcvjwMHDqBatWpSfQQiIiLKQySf5ya36WqeGyIiItKdfDPPDREREZG2sbghIiIivcLihoiIiPQKixsiIiLSKyxuiIiISK+wuCEiIiK9wuKGiIiI9AqLGyIiItIrLG6IiIhIr0i+/EJu+zAhc1xcnMRJiIiIKLs+fG9nZ2GFAlfcxMfHAwAcHR0lTkJERESaio+Ph7W19Se3KXBrS6lUKrx48QKWlpaQyWRaPXZcXBwcHR3x9OlTrlulQzzPuYPnOXfwPOcenuvcoavzLIRAfHw8HBwcMiyonZUC13NjYGCAkiVL6vQ9rKys+D9OLuB5zh08z7mD5zn38FznDl2c5//qsfmAA4qJiIhIr7C4ISIiIr3C4kaLFAoF/Pz8oFAopI6i13iecwfPc+7gec49PNe5Iy+c5wI3oJiIiIj0G3tuiIiISK+wuCEiIiK9wuKGiIiI9AqLGyIiItIrLG405O/vDycnJ5iYmKBevXr4888/P7n97t27UalSJZiYmKB69eo4cuRILiXN3zQ5z2vXrkWTJk1QqFAhFCpUCO7u7v/590Lvafrz/MGuXbsgk8nQqVMn3QbUE5qe55iYGAwbNgzFixeHQqFAhQoV+G9HNmh6npcuXYqKFSvC1NQUjo6OGDVqFJKTk3Mpbf70+++/o3379nBwcIBMJsOBAwf+c5/g4GDUrl0bCoUC5cqVw6ZNm3SeE4KybdeuXUIul4sNGzaImzdvioEDBwobGxsRGRmZ5fbnzp0ThoaG4ocffhBhYWFi8uTJwtjYWFy/fj2Xk+cvmp5nb29v4e/vL65evSpu3bol+vTpI6ytrcWzZ89yOXn+oul5/uDhw4eiRIkSokmTJqJjx465EzYf0/Q8p6SkCDc3N9GmTRtx9uxZ8fDhQxEcHCxCQ0NzOXn+oul53r59u1AoFGL79u3i4cOH4vjx46J48eJi1KhRuZw8fzly5IiYNGmS2LdvnwAg9u/f/8ntHzx4IMzMzMTo0aNFWFiY+Omnn4ShoaE4duyYTnOyuNFA3bp1xbBhw9TPlUqlcHBwEHPnzs1y+65du4q2bdtmaKtXr5745ptvdJozv9P0PP9benq6sLS0FJs3b9ZVRL2Qk/Ocnp4uGjZsKNatWyd8fHxY3GSDpud55cqVwtnZWaSmpuZWRL2g6XkeNmyYaNGiRYa20aNHi0aNGuk0pz7JTnEzduxYUbVq1QxtXl5ewsPDQ4fJhOBlqWxKTU3FlStX4O7urm4zMDCAu7s7zp8/n+U+58+fz7A9AHh4eHx0e8rZef63xMREpKWloXDhwrqKme/l9DzPmDEDtra26N+/f27EzPdycp4PHjyIBg0aYNiwYbCzs0O1atUwZ84cKJXK3Iqd7+TkPDds2BBXrlxRX7p68OABjhw5gjZt2uRK5oJCqu/BArdwZk5FR0dDqVTCzs4uQ7udnR1u376d5T4RERFZbh8REaGznPldTs7zv40bNw4ODg6Z/oeiv+XkPJ89exbr169HaGhoLiTUDzk5zw8ePMBvv/2GHj164MiRIwgPD8fQoUORlpYGPz+/3Iid7+TkPHt7eyM6OhqNGzeGEALp6ekYPHgwJk6cmBuRC4yPfQ/GxcUhKSkJpqamOnlf9tyQXpk3bx527dqF/fv3w8TEROo4eiM+Ph69evXC2rVrUbRoUanj6DWVSgVbW1usWbMGrq6u8PLywqRJk7Bq1Sqpo+mV4OBgzJkzBytWrEBISAj27duHw4cPY+bMmVJHIy1gz002FS1aFIaGhoiMjMzQHhkZCXt7+yz3sbe312h7ytl5/mDhwoWYN28eTp48iRo1augyZr6n6Xm+f/8+Hj16hPbt26vbVCoVAMDIyAh37txB2bJldRs6H8rJz3Px4sVhbGwMQ0NDdVvlypURERGB1NRUyOVynWbOj3JynqdMmYJevXphwIABAIDq1asjISEBgwYNwqRJk2BgwN/9teFj34NWVlY667UB2HOTbXK5HK6urjh16pS6TaVS4dSpU2jQoEGW+zRo0CDD9gBw4sSJj25POTvPAPDDDz9g5syZOHbsGNzc3HIjar6m6XmuVKkSrl+/jtDQUPWjQ4cOaN68OUJDQ+Ho6Jib8fONnPw8N2rUCOHh4eriEQDu3r2L4sWLs7D5iJyc58TExEwFzIeCUnDJRa2R7HtQp8OV9cyuXbuEQqEQmzZtEmFhYWLQoEHCxsZGRERECCGE6NWrlxg/frx6+3PnzgkjIyOxcOFCcevWLeHn58dbwbNB0/M8b948IZfLxZ49e8TLly/Vj/j4eKk+Qr6g6Xn+N94tlT2anucnT54IS0tL4evrK+7cuSN++eUXYWtrK2bNmiXVR8gXND3Pfn5+wtLSUuzcuVM8ePBA/Prrr6Js2bKia9euUn2EfCE+Pl5cvXpVXL16VQAQixcvFlevXhWPHz8WQggxfvx40atXL/X2H24F//7778WtW7eEv78/bwXPi3766SdRqlQpIZfLRd26dcWFCxfUrzVr1kz4+Phk2D4wMFBUqFBByOVyUbVqVXH48OFcTpw/aXKeS5cuLQBkevj5+eV+8HxG05/nf2Jxk32anuc//vhD1KtXTygUCuHs7Cxmz54t0tPTczl1/qPJeU5LSxPTpk0TZcuWFSYmJsLR0VEMHTpUvH37NveD5yNBQUFZ/nv74dz6+PiIZs2aZdrHxcVFyOVy4ezsLDZu3KjznDIh2P9GRERE+oNjboiIiEivsLghIiIivcLihoiIiPQKixsiIiLSKyxuiIiISK+wuCEiIiK9wuKGiIiI9AqLGyLKYNOmTbCxsZE6Ro7JZDIcOHDgk9v06dMHnTp1ypU8RJT7WNwQ6aE+ffpAJpNleoSHh0sdDZs2bVLnMTAwQMmSJdG3b19ERUVp5fgvX77El19+CQB49OgRZDIZQkNDM2yzbNkybNq0SSvv9zHTpk1Tf05DQ0M4Ojpi0KBBePPmjUbHYSFGpDmuCk6kpzw9PbFx48YMbcWKFZMoTUZWVla4c+cOVCoVrl27hr59++LFixc4fvz4Zx/7v1aPBwBra+vPfp/sqFq1Kk6ePAmlUolbt26hX79+iI2NRUBAQK68P1FBxZ4bIj2lUChgb2+f4WFoaIjFixejevXqMDc3h6OjI4YOHYp379599DjXrl1D8+bNYWlpCSsrK7i6uuLy5cvq18+ePYsmTZrA1NQUjo6OGDFiBBISEj6ZTSaTwd7eHg4ODvjyyy8xYsQInDx5EklJSVCpVJgxYwZKliwJhUIBFxcXHDt2TL1vamoqfH19Ubx4cZiYmKB06dKYO3duhmN/uCxVpkwZAECtWrUgk8nwxRdfAMjYG7JmzRo4ODhkWIUbADp27Ih+/fqpn//888+oXbs2TExM4OzsjOnTpyM9Pf2Tn9PIyAj29vYoUaIE3N3d8b///Q8nTpxQv65UKtG/f3+UKVMGpqamqFixIpYtW6Z+fdq0adi8eTN+/vlndS9QcHAwAODp06fo2rUrbGxsULhwYXTs2BGPHj36ZB6igoLFDVEBY2BggB9//BE3b97E5s2b8dtvv2Hs2LEf3b5Hjx4oWbIkLl26hCtXrmD8+PEwNjYGANy/fx+enp7o3Lkz/vrrLwQEBODs2bPw9fXVKJOpqSlUKhXS09OxbNkyLFq0CAsXLsRff/0FDw8PdOjQAffu3QMA/Pjjjzh48CACAwNx584dbN++HU5OTlke988//wQAnDx5Ei9fvsS+ffsybfO///0Pr1+/RlBQkLrtzZs3OHbsGHr06AEAOHPmDHr37o2RI0ciLCwMq1evxqZNmzB79uxsf8ZHjx7h+PHjkMvl6jaVSoWSJUti9+7dCAsLw9SpUzFx4kQEBgYCAMaMGYOuXbvC09MTL1++xMuXL9GwYUOkpaXBw8MDlpaWOHPmDM6dOwcLCwt4enoiNTU125mI9JbOl+Ykolzn4+MjDA0Nhbm5ufrRpUuXLLfdvXu3KFKkiPr5xo0bhbW1tfq5paWl2LRpU5b79u/fXwwaNChD25kzZ4SBgYFISkrKcp9/H//u3buiQoUKws3NTQghhIODg5g9e3aGferUqSOGDh0qhBBi+PDhokWLFkKlUmV5fABi//79QgghHj58KACIq1evZtjm3yuad+zYUfTr10/9fPXq1cLBwUEolUohhBAtW7YUc+bMyXCMrVu3iuLFi2eZQQgh/Pz8hIGBgTA3NxcmJibq1ZMXL1780X2EEGLYsGGic+fOH8364b0rVqyY4RykpKQIU1NTcfz48U8en6gg4JgbIj3VvHlzrFy5Uv3c3NwcwPtejLlz5+L27duIi4tDeno6kpOTkZiYCDMzs0zHGT16NAYMGICtW7eqL62ULVsWwPtLVn/99Re2b9+u3l4IAZVKhYcPH6Jy5cpZZouNjYWFhQVUKhWSk5PRuHFjrFu3DnFxcXjx4gUaNWqUYftGjRrh2rVrAN5fUmrVqhUqVqwIT09PtGvXDq1bt/6sc9WjRw8MHDgQK1asgEKhwPbt29GtWzcYGBioP+e5c+cy9NQolcpPnjcAqFixIg4ePIjk5GRs27YNoaGhGD58eIZt/P39sWHDBjx58gRJSUlITU2Fi4vLJ/Neu3YN4eHhsLS0zNCenJyM+/fv5+AMEOkXFjdEesrc3BzlypXL0Pbo0SO0a9cOQ4YMwezZs1G4cGGcPXsW/fv3R2pqapZf0tOmTYO3tzcOHz6Mo0ePws/PD7t27cJXX32Fd+/e4ZtvvsGIESMy7VeqVKmPZrO0tERISAgMDAxQvHhxmJqaAgDi4uL+83PVrl0bDx8+xNGjR3Hy5El07doV7u7u2LNnz3/u+zHt27eHEAKHDx9GnTp1cObMGSxZskT9+rt37zB9+nR8/fXXmfY1MTH56HHlcrn672DevHlo27Ytpk+fjpkzZwIAdu3ahTFjxmDRokVo0KABLC0tsWDBAly8ePGTed+9ewdXV9cMReUHeWXQOJGUWNwQFSBXrlyBSqXCokWL1L0SH8Z3fEqFChVQoUIFjBo1Ct27d8fGjRvx1VdfoXbt2ggLC8tURP0XAwODLPexsrKCg4MDzp07h2bNmqnbz507h7p162bYzsvLC15eXujSpQs8PT3x5s0bFC5cOMPxPoxvUSqVn8xjYmKCr7/+Gtu3b0d4eDgqVqyI2rVrq1+vXbs27ty5o/Hn/LfJkyejRYsWGDJkiPpzNmzYEEOHDlVv8++eF7lcnil/7dq1ERAQAFtbW1hZWX1WJiJ9xAHFRAVIuXLlkJaWhp9++gkPHjzA1q1bsWrVqo9un5SUBF9fXwQHB+Px48c4d+4cLl26pL7cNG7cOPzxxx/w9fVFaGgo7t27h59//lnjAcX/9P3332P+/PkICAjAnTt3MH78eISGhmLkyJEAgMWLF2Pnzp24ffs27t69i927d8Pe3j7LiQdtbW1hamqKY8eOITIyErGxsR993x49euDw4cPYsGGDeiDxB1OnTsWWLVswffp03Lx5E7du3cKuXbswefJkjT5bgwYNUKNGDcyZMwcAUL58eVy+fBnHjx/H3bt3MWXKFFy6dCnDPk5OTvjrr79w584dREdHIy0tDT169EDRokXRsWNHnDlzBg8fPkRwcDBGjBiBZ8+eaZSJSC9JPeiHiLQvq0GoHyxevFgUL15cmJqaCg8PD7FlyxYBQLx9+1YIkXHAb0pKiujWrZtwdHQUcrlcODg4CF9f3wyDhf/880/RqlUrYWFhIczNzUWNGjUyDQj+p38PKP43pVIppk2bJkqUKCGMjY1FzZo1xdGjR9Wvr1mzRri4uAhzc3NhZWUlWrZsKUJCQtSv4x8DioUQYu3atcLR0VEYGBiIZs2affT8KJVKUbx4cQFA3L9/P1OuY8eOiYYNGwpTU1NhZWUl6tatK9asWfPRz+Hn5ydq1qyZqX3nzp1CoVCIJ0+eiOTkZNGnTx9hbW0tbGxsxJAhQ8T48eMz7BcVFaU+vwBEUFCQEEKIly9fit69e4uiRYsKhUIhnJ2dxcCBA0VsbOxHMxEVFDIhhJC2vCIiIiLSHl6WIiIiIr3C4oaIiIj0CosbIiIi0issboiIiEivsLghIiIivcLihoiIiPQKixsiIiLSKyxuiIiISK+wuCEiIiK9wuKGiIiI9AqLGyIiItIrLG6IiIhIr/wfH7hGygqmXhYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_uni_config' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2014995199.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0muni_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_uni_test_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_uni_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0muni_test_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muni_test_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_uni_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mevaluate_and_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muni_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"UniSwiss Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_uni_config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# Save PDB model\n",
        "torch.save({\n",
        "    'model_state_dict': model_pdb.state_dict(),\n",
        "    'config': {\n",
        "        'input_dim': 1280,\n",
        "        'hidden_dim': best_pdb_config['hidden_dim'],\n",
        "        'dropout': best_pdb_config['dropout'],\n",
        "        'output_dim': 2\n",
        "    },\n",
        "    'hyperparameters': {\n",
        "        'learning_rate': best_pdb_config['lr'],\n",
        "        'batch_size': best_pdb_config['batch_size']\n",
        "    },\n",
        "    'best_val_f1': best_pdb_config['best_val_f1']\n",
        "}, 'saved_models/bilstm_pdb.pt')\n",
        "\n",
        "print(\"✓ PDB BiLSTM model saved!\")\n",
        "\n",
        "\n",
        "# Save UniSwiss model\n",
        "# torch.save({\n",
        "#     'model_state_dict': model_uni.state_dict(),\n",
        "#     'config': {\n",
        "#         'input_dim': 1280,\n",
        "#         'hidden_dim': bestuni_config['hiddendim'],\n",
        "#         'dropout': bestuni_config['dropout'],\n",
        "#         'output_dim': 2\n",
        "#     },\n",
        "#     'hyperparameters': {\n",
        "#         'learning_rate': bestuni_config['lr'],\n",
        "#         'batch_size': bestuni_config['batchsize']\n",
        "#     },\n",
        "#     'best_val_f1': bestuni_config['bestvalf1']\n",
        "# }, 'saved_models/bilstm_uniswiss.pt')\n",
        "\n",
        "# print(\"✓ UniSwiss BiLSTM model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNP_HCqIdlBW",
        "outputId": "542b0f57-f8b9-4efe-9324-4e61c0586469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ PDB BiLSTM model saved!\n"
          ]
        }
      ]
    }
  ]
}